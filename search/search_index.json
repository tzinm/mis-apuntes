{"config":{"indexing":"full","lang":["es"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home # Este es m\u00ed rinconcito, el lugar donde ir\u00e9 dejando los apuntes sobre algunos de los temas que voy aprendiendo/descubriendo. Cualquier sugerencia es bienvenida , en la parte derecha de las notas de pie de p\u00e1gina se encuentran mis medios de contacto. - Docker - Git - Kubernetes - OpenMediaVault - MacOS - Router Asus","title":"Home"},{"location":"#home","text":"Este es m\u00ed rinconcito, el lugar donde ir\u00e9 dejando los apuntes sobre algunos de los temas que voy aprendiendo/descubriendo. Cualquier sugerencia es bienvenida , en la parte derecha de las notas de pie de p\u00e1gina se encuentran mis medios de contacto. - Docker - Git - Kubernetes - OpenMediaVault - MacOS - Router Asus","title":"Home"},{"location":"Asus/Custom-DDNS/","text":"Dinamyc DNS # Seg\u00fan la wikipedia, el DNS din\u00e1mico \" es un servicio que permite la actualizaci\u00f3n en tiempo real de la informaci\u00f3n sobre nombres de dominio situada en un servidor de nombres. El uso m\u00e1s com\u00fan que se le da es permitir la asignaci\u00f3n de un nombre de dominio de Internet a un dispositivo con direcci\u00f3n IP variable. \" Habitualmente, el proveedor de internet que tenemos contratado no nos ofrece una direcci\u00f3n ip p\u00fablica fija. Esto quiere decir, que la direcci\u00f3n ip de acceso desde el exterior a nuestra red es variable, y aunque es habitual que esta no var\u00ede en un largo periodo de tiempo, una alternativa es el uso de alg\u00fan servicio de DNS din\u00e1mico. Servicios DNS+ # Hay una larga lista de servicios, hasta hace poco he estado utilizando no-ip , el cual tiene un servicio gratuito de hasta tres nombres de dominio. El inconveniente que tiene es que hay que verificar cada dominio una vez al mes. Por este motivo he comenzado a utilizar Duck DNS , un servicio gratuito que una vez lo hayamos configurado no tenemos que realizar ninguna acci\u00f3n. La configuraci\u00f3n de DuckDNS en el firmware Merlin de Asus no es tan simple como si que lo es el servicio no-ip , es necesario realizar varios pasos que veremos a continuaci\u00f3n para tenerlo configurado correctamente. Habilitar scripts personalizados, esta opci\u00f3n se encuentra en Administraci\u00f3n > Sistema > Enable JFFS custom scripts and configs. Conectarnos v\u00eda ssh (debemos tener habilitada esta opci\u00f3n en el router) y en la ruta /jffs/scripts crear un fichero llamado ddns-start . Este fichero tendr\u00e1 el siguiente contenido: #!/bin/sh # register a subdomain at https://www.duckdns.org/ to get your token SUBDOMAIN = \"subdominio\" #Cambiar por el dominio elegido sin \"duckdns.org\" TOKEN = \"token_duckdns.org\" #Cambiar por el token que nos otorga duckdns # no modification below needed curl --silent \"https://www.duckdns.org/update?domains= $SUBDOMAIN &token= $TOKEN &ip= $1 \" >/dev/null 2 > & 1 if [ $? -eq 0 ] ; then /sbin/ddns_custom_updated 1 else /sbin/ddns_custom_updated 0 fi Cambiar los permisos del fichero para que este se pueda ejecutar chmod +x /jffs/scripts/ddns-start Establecer los par\u00e1metros adecuados en la pesta\u00f1a DDNS del men\u00fa WAN . Aqu\u00ed podemos ver una captura de ejemplo: En la parte inferior tendremos un bot\u00f3n para aplicar cambios . Con esto ya habr\u00edamos configurado duckdns como nuestro servicio de DNS din\u00e1mico. Informaci\u00f3n adicional # En la red disponemos de diversos scripts para utilizar como ddns-start . Dos de los scripts que he probado y funcionan correctamente son los siguientes: Wiki Asuswrt-Merlin - Es el que utilizo puesto que es el que se encuentra en la wiki oficial. Kevinxw","title":"Configurando DuckDNS"},{"location":"Asus/Custom-DDNS/#dinamyc-dns","text":"Seg\u00fan la wikipedia, el DNS din\u00e1mico \" es un servicio que permite la actualizaci\u00f3n en tiempo real de la informaci\u00f3n sobre nombres de dominio situada en un servidor de nombres. El uso m\u00e1s com\u00fan que se le da es permitir la asignaci\u00f3n de un nombre de dominio de Internet a un dispositivo con direcci\u00f3n IP variable. \" Habitualmente, el proveedor de internet que tenemos contratado no nos ofrece una direcci\u00f3n ip p\u00fablica fija. Esto quiere decir, que la direcci\u00f3n ip de acceso desde el exterior a nuestra red es variable, y aunque es habitual que esta no var\u00ede en un largo periodo de tiempo, una alternativa es el uso de alg\u00fan servicio de DNS din\u00e1mico.","title":"Dinamyc DNS"},{"location":"Asus/Custom-DDNS/#servicios-dns","text":"Hay una larga lista de servicios, hasta hace poco he estado utilizando no-ip , el cual tiene un servicio gratuito de hasta tres nombres de dominio. El inconveniente que tiene es que hay que verificar cada dominio una vez al mes. Por este motivo he comenzado a utilizar Duck DNS , un servicio gratuito que una vez lo hayamos configurado no tenemos que realizar ninguna acci\u00f3n. La configuraci\u00f3n de DuckDNS en el firmware Merlin de Asus no es tan simple como si que lo es el servicio no-ip , es necesario realizar varios pasos que veremos a continuaci\u00f3n para tenerlo configurado correctamente. Habilitar scripts personalizados, esta opci\u00f3n se encuentra en Administraci\u00f3n > Sistema > Enable JFFS custom scripts and configs. Conectarnos v\u00eda ssh (debemos tener habilitada esta opci\u00f3n en el router) y en la ruta /jffs/scripts crear un fichero llamado ddns-start . Este fichero tendr\u00e1 el siguiente contenido: #!/bin/sh # register a subdomain at https://www.duckdns.org/ to get your token SUBDOMAIN = \"subdominio\" #Cambiar por el dominio elegido sin \"duckdns.org\" TOKEN = \"token_duckdns.org\" #Cambiar por el token que nos otorga duckdns # no modification below needed curl --silent \"https://www.duckdns.org/update?domains= $SUBDOMAIN &token= $TOKEN &ip= $1 \" >/dev/null 2 > & 1 if [ $? -eq 0 ] ; then /sbin/ddns_custom_updated 1 else /sbin/ddns_custom_updated 0 fi Cambiar los permisos del fichero para que este se pueda ejecutar chmod +x /jffs/scripts/ddns-start Establecer los par\u00e1metros adecuados en la pesta\u00f1a DDNS del men\u00fa WAN . Aqu\u00ed podemos ver una captura de ejemplo: En la parte inferior tendremos un bot\u00f3n para aplicar cambios . Con esto ya habr\u00edamos configurado duckdns como nuestro servicio de DNS din\u00e1mico.","title":"Servicios DNS+"},{"location":"Asus/Custom-DDNS/#informacion-adicional","text":"En la red disponemos de diversos scripts para utilizar como ddns-start . Dos de los scripts que he probado y funcionan correctamente son los siguientes: Wiki Asuswrt-Merlin - Es el que utilizo puesto que es el que se encuentra en la wiki oficial. Kevinxw","title":"Informaci\u00f3n adicional"},{"location":"Docker/Contenedores/","text":"En este apartado veremos diferentes im\u00e1genes con las que podremos poner en marcha diferentes contenedores. Docker nos ofrece un repositorio donde podemos encontrar una gran cantidad de imagenes, Docker Hub . Dentro de Docker Hub podemos encontrarnos con una comunidad ( Linuxserver )que se dedica a desarrollar diferentes im\u00e1genes de una gran variedad de servicios. El c\u00f3digo de sus imagenes podemos revisarlo en GitHub . Desde hace alg\u00fan tiempo, la comunidad de Linuxserver ha implementado una forma sencilla de realizar modificaciones a sus imagenes, sin que estas modificaciones alteren la imagen base. Esta funcionalidad la han denominado Docker Mod . En GitHub han dejado una peque\u00f1a gu\u00eda de como realizar dichos mods y adem\u00e1s varios ejemplos, desde una modificaci\u00f3n sencilla hasta modificaciones m\u00e1s complejas. He aprovechado esta nueva funcionalidad y he desarrollado un mod para transmission. https://github.com/tzinm/remove-finished https://hub.docker.com/r/tzinm/remove-finished Im\u00e1genes interesantes # Watchtower # El objetivo de este contenedor es mantener los contenedores actualizados (incluido \u00e9l mismo). Autom\u00e1ticamente ejecutar\u00e1 docker pull para la descarga de la imagen m\u00e1s actual, parar\u00e1 el contenedor en ejecuci\u00f3n y lo iniciar\u00e1 de nuevo con las mismas opciones con las que se hab\u00eda creado inicialmente. Algunas de las opciones que podemos utilizar: Notificaciones: este contenedor permite el env\u00edo de notificaciones a trav\u00e9s de slack y v\u00eda email . He seleccionado el env\u00edo de notificaciones a trav\u00e9s de email, para ello es necesario a\u00f1adir una serie de variables que veremos en el ejemplo m\u00e1s adelante. Respecto a las notificaciones, el nivel de notificaciones por defecto es info , en caso de querer modificarlo es necesario a\u00f1adir la variable WATCHTOWER_NOTIFICATIONS_LEVEL . Contenedores: si no indicamos lo contrario se comprobar\u00e1 y actualizar\u00e1n todos los contenedores. Puesto que mi inter\u00e9s es actualizar \u00fanicamente una serie de contenedores, es necesario indicarle el nombre estos (importante escribirlo correctamente, teniendo en cuenta may\u00fasculas y min\u00fasculas) como argumentos. Programaci\u00f3n: para programar las actualizaciones tenemos dos opciones --interval y --schedule . Interval: se establece un valor en segundos (por defecto son 300 segundos). Schedule: es similar a las expresiones de cron pero con un 6 campos. Por ejemplo --schedule \"0 0 5 * * *\" ejecutar\u00eda las comprobaciones todos los d\u00edas a las 5 de la ma\u00f1ana. Debug mode: estableciendo esta opci\u00f3n el log recoge m\u00e1s informaci\u00f3n. Cleanup : elimina las imagenes antiguas. Ejemplo # docker run -d \\ --name watchtower \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -e WATCHTOWER_NOTIFICATIONS = email \\ -e WATCHTOWER_NOTIFICATION_EMAIL_FROM = fromaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_TO = toaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER = smtp.gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT = 587 \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER = fromaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD = app_password \\ v2tec/watchtower tautulli plex transmission heimdall syncthing watchtower --schedule \"0 0 5 * * *\" --cleanup --debug Note Muchos de los usuarios que utilizamos Docker, utilizamos los contenedores desarrollado por la comunidad LinuxServer. Estos no recomiendan el uso de watchtower par actualizar los contenedores (al menos los desarrollado por ellos), sino que recomiendan varios scripts que podemos encontrar aqu\u00ed para actualizar y realizar backups del estado de los contenedores.","title":"Contenedores de ejemplo"},{"location":"Docker/Contenedores/#imagenes-interesantes","text":"","title":"Im\u00e1genes interesantes"},{"location":"Docker/Contenedores/#watchtower","text":"El objetivo de este contenedor es mantener los contenedores actualizados (incluido \u00e9l mismo). Autom\u00e1ticamente ejecutar\u00e1 docker pull para la descarga de la imagen m\u00e1s actual, parar\u00e1 el contenedor en ejecuci\u00f3n y lo iniciar\u00e1 de nuevo con las mismas opciones con las que se hab\u00eda creado inicialmente. Algunas de las opciones que podemos utilizar: Notificaciones: este contenedor permite el env\u00edo de notificaciones a trav\u00e9s de slack y v\u00eda email . He seleccionado el env\u00edo de notificaciones a trav\u00e9s de email, para ello es necesario a\u00f1adir una serie de variables que veremos en el ejemplo m\u00e1s adelante. Respecto a las notificaciones, el nivel de notificaciones por defecto es info , en caso de querer modificarlo es necesario a\u00f1adir la variable WATCHTOWER_NOTIFICATIONS_LEVEL . Contenedores: si no indicamos lo contrario se comprobar\u00e1 y actualizar\u00e1n todos los contenedores. Puesto que mi inter\u00e9s es actualizar \u00fanicamente una serie de contenedores, es necesario indicarle el nombre estos (importante escribirlo correctamente, teniendo en cuenta may\u00fasculas y min\u00fasculas) como argumentos. Programaci\u00f3n: para programar las actualizaciones tenemos dos opciones --interval y --schedule . Interval: se establece un valor en segundos (por defecto son 300 segundos). Schedule: es similar a las expresiones de cron pero con un 6 campos. Por ejemplo --schedule \"0 0 5 * * *\" ejecutar\u00eda las comprobaciones todos los d\u00edas a las 5 de la ma\u00f1ana. Debug mode: estableciendo esta opci\u00f3n el log recoge m\u00e1s informaci\u00f3n. Cleanup : elimina las imagenes antiguas.","title":"Watchtower"},{"location":"Docker/Contenedores/#ejemplo","text":"docker run -d \\ --name watchtower \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -e WATCHTOWER_NOTIFICATIONS = email \\ -e WATCHTOWER_NOTIFICATION_EMAIL_FROM = fromaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_TO = toaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER = smtp.gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT = 587 \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER = fromaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD = app_password \\ v2tec/watchtower tautulli plex transmission heimdall syncthing watchtower --schedule \"0 0 5 * * *\" --cleanup --debug Note Muchos de los usuarios que utilizamos Docker, utilizamos los contenedores desarrollado por la comunidad LinuxServer. Estos no recomiendan el uso de watchtower par actualizar los contenedores (al menos los desarrollado por ellos), sino que recomiendan varios scripts que podemos encontrar aqu\u00ed para actualizar y realizar backups del estado de los contenedores.","title":"Ejemplo"},{"location":"Docker/Docker/","text":"\u00bfQu\u00e9 es Docker? # Es una herramienta que permite desplegar aplicaciones en contenedores de forma r\u00e1pida y portable. Los t\u00e9rminos que m\u00e1s escucharemos cuando hablamos de Docker ser\u00e1n \" contenedores \" e \" im\u00e1genes \". Docker se encuentra disponible para las principales plataformas, como Windows, Linux o MacOS. La m\u00e1quina que aloja el servicio \" Docker \" se denomina Docker Host . Dentro de Docker podemos destacar tres conceptos. Docker Daemon: representa el servidor de Docker. Rest API: utilizado para la comunicaci\u00f3n bidireccional entre cliente y servidor. Docker CLI (Command Line Interface): representa el cliente de Docker. * A pesar de que se haya mencionado la l\u00ednea de comandos como cliente Docker, tambi\u00e9n existe entorno gr\u00e1fico para interactuar con el servidor Docker. Cuando interactuamos con contenedores o im\u00e1genes, lo hacemos a trav\u00e9s del cliente de Docker, con lo cual nos interesa saber que es lo que podemos gestionar. Docker Compose # Es una herramienta que nos ayuda a orquestar contenedores en Docker, gestionar los diferentes contenedores de los que depende una aplicaci\u00f3n. Existen aplicaciones que para su correcto funcionamiento dependen de varios servicios, para seguir con la simplicidad de \" un servicio = un contenedor \", Docker Compose nos permitir\u00e1 administrar los diferentes contenedores de forma grupal. Docker Compose trabaja con ficheros de tipo yaml , en los que se definen los contenedores, vol\u00famenes, redes, etc. Despu\u00e9s de completar el fichero, docker-compose como comando se encarga de la lectura del fichero y lanzar todos los contenedores definidos en dichero fichero. Durante la instalaci\u00f3n de Docker-CE esta herramienta no se instala, por lo que ser\u00e1 necesaria la instalaci\u00f3n de forma independiente. En la documentaci\u00f3n oficial se encuentran diferentes gu\u00edas para la instalaci\u00f3n en los diferentes Sistemas Operativos. En la m\u00e1quina actual, en la que estamos trabajando bajo Linux, la instalaci\u00f3n se har\u00eda del siguiente modo: Descargamos Docker-Compose. sudo curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose Aplicar permisos de ejecuci\u00f3n al ejecutable que hemos descargado. sudo chmod +x /usr/local/bin/docker-compose Comenzando con Docker Compose # El nombre del fichero que debemos utilizar es docker-compose.yml , donde definiremos los diferentes contenedores. Este fichero cuenta con cuatro grandes partes: Version (obligatorio): para saber que n\u00famero de versi\u00f3n (Docker-Compose) debemos establecer, buscamos en la documentaci\u00f3n cual es la \u00faltima versi\u00f3n, suele ser la que se recomienda utilizar. Services (obligatorio): los servicios hacen referencia a los contenedores. En primera instancia definimos los nombres de cada servicio (podemos elegir el que queramos), y debajo de ellos ir\u00e1n los par\u00e1metros que hacen referencia al propio contenedor, como el nombre del contenedor, la imagen a la que hace referencia, puertos, variables de entorno, etc. Volumes (opcional): Vol\u00famenes nombrados : funcionan del mismo modo que ejecutando docker run . Lo que hacemos es definir en primer lugar el volumen que crear\u00edamos con la instrucci\u00f3n docker volume create en \"volumes\" con el nombre que queramos. A continuaci\u00f3n lo definimos dentro del servicio. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"html:/usr/share/nginx/html\" volumes : html : Vol\u00famenes host : no necesitamos la parte volumes dentro del fichero docker-compose.yml sino que directamente en el contenedorlo podemos parametrizar. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"/home/miusuario/html:/usr/share/nginx/html\" Networks (opcional): Red Host : es importante establecer la versi\u00f3n 3.4 para que funcione correctamente . Para que funcione es necesario a\u00f1adir build , y adem\u00e1s a\u00f1adir el contexto , que hace referencia a un directorio que contenga un Dockerfile o una url a un repositorio git. Si establecemos la ruta relativa hace referencia a la ubicaci\u00f3n del archivo de composici\u00f3n. version : '3.4' services : web : build : context : . network : host image : nginx container_name : nginx-prueba ports : - \"8181:80\" Creaci\u00f3n de una nueva red con subnet. A\u00fan no se permite establecer gateway . version : '3' services : web : image : nginx container_name : nginx-prueba ports : - \"8181:80\" networks : red-prueba : - ipv4_address : 192.168.50.10 networks : red-prueba : ipam : driver : default config : - subnet : \"192.168.50.0/24\" En cuanto a las redes, cuando ejecutamos el comando docker-compose up -d se genera una red espec\u00edfica para docker-compose . Si no definimos una red, la red utilizada ser\u00e1 la red por defecto (docker-compose_default). Cuando se crea la red, el nombre que es otorgado \" directorioactual_nombredelared \". Es posible modificar la parte del nombre que hace referencia al \"directorioactual\", pasando el par\u00e1metro -p . Por lo tanto si nuestro directorio actual se denomina docker-compose y queremos que el prefijo sea por ejemplo dcprueba ejecutar\u00edamos el siguiente comando: #Modificar el nombre de red a \"dcprueba_default\" docker-compose -p dcprueba up -d Por otro lado, tenemos dos partes importantes que se utilizan a la hora de crear contenedores. Variables de entorno: estas se pueden definir de dos modos. Fichero docker-compose.yml environment : - \"VARIABLES1=docker\" Fichero con extensi\u00f3n .env. environment : - variables.env Command: se utiliza para establecer un CMD al contenedor. commmand : mkdir /bin/bash El comando docker-compose se encarga de realizar un proceso similar que el comando docker run , pero en este caso los diferentes par\u00e1metros se encuentran definidos en un fichero. Por lo tanto, las pol\u00edticas de reinicio o la limitaci\u00f3n de recursos tambi\u00e9n se pueden definir. Pol\u00edticas de reinicio: #Reinicio siempre restart : always #Reinicio hasta que lo detengamos de forma manual restart : unless-stopped #\u00danicamente se reinicia el contenedor en caso de que haya habido un fallo restart : on-failure Limitar recursos: #Limitar memoria mem_limit : 20m #Cpu cpuset : \"0\" Otras de las directivas relevantes de este fichero es depends_on , la cual hace referencia a las dependencias que tiene se contenedor respecto a los que se incluyan en esta directiva. version : '3' services : web : image : nginx container_name : nginx-prueba depends_on : db db : image : postgres container_name : nginx-database El \u00faltimo paso ser\u00e1 conocer como podemos eliminar un contenedor creado con la herramienta Docker-Compose. Para ello debemos ejecutar el siguiente comando, situados en el directorio donde se encuentra el fichero yaml . docker-compose down El comando anterior sigue el siguiente proceso: Detiene el contenedor. Elimina el contenedor. Elimina la red que ha creado por defecto. Docker-compose build # Ya conocemos el comando docker build , es el encargado de crear im\u00e1genes. El comando docker-compose build tiene un funcionamiento similar, se encarga de generar una imagen a partir de la definici\u00f3n de build en el fichero yaml . Esta imagen ser\u00e1 utilizada como imagen base en la creaci\u00f3n del contenedor. Para que se construya una imagen, sabemos que necesitamos un fichero Dockerfile , en el cual se encuentran las capas para la construcci\u00f3n de una imagen. En la sentencia build nos encontramos con dos par\u00e1metros importantes. Context: se indica la ruta donde se encuentra el Dockerfile que utilizaremos para crear la imagen. Si se encuentra en el mismo directorio se utilizar\u00e1 el punto ( . ). Dockerfile: el nombre del fichero si este es diferente al nombre por defecto (Dockerfile). version : '3' services : web : container_name : web image : web-test build : context : . dockerfile : Dockerfile1 *Si el nombre que hace referencia al Dockerfile no se ha modificado, podemos obviar estos dos par\u00e1metros. version : '3' services : web : container_name : web image : web-test build : . Otros conceptos # Fuentes #","title":"Docker"},{"location":"Docker/Docker/#que-es-docker","text":"Es una herramienta que permite desplegar aplicaciones en contenedores de forma r\u00e1pida y portable. Los t\u00e9rminos que m\u00e1s escucharemos cuando hablamos de Docker ser\u00e1n \" contenedores \" e \" im\u00e1genes \". Docker se encuentra disponible para las principales plataformas, como Windows, Linux o MacOS. La m\u00e1quina que aloja el servicio \" Docker \" se denomina Docker Host . Dentro de Docker podemos destacar tres conceptos. Docker Daemon: representa el servidor de Docker. Rest API: utilizado para la comunicaci\u00f3n bidireccional entre cliente y servidor. Docker CLI (Command Line Interface): representa el cliente de Docker. * A pesar de que se haya mencionado la l\u00ednea de comandos como cliente Docker, tambi\u00e9n existe entorno gr\u00e1fico para interactuar con el servidor Docker. Cuando interactuamos con contenedores o im\u00e1genes, lo hacemos a trav\u00e9s del cliente de Docker, con lo cual nos interesa saber que es lo que podemos gestionar.","title":"\u00bfQu\u00e9 es Docker?"},{"location":"Docker/Docker/#docker-compose","text":"Es una herramienta que nos ayuda a orquestar contenedores en Docker, gestionar los diferentes contenedores de los que depende una aplicaci\u00f3n. Existen aplicaciones que para su correcto funcionamiento dependen de varios servicios, para seguir con la simplicidad de \" un servicio = un contenedor \", Docker Compose nos permitir\u00e1 administrar los diferentes contenedores de forma grupal. Docker Compose trabaja con ficheros de tipo yaml , en los que se definen los contenedores, vol\u00famenes, redes, etc. Despu\u00e9s de completar el fichero, docker-compose como comando se encarga de la lectura del fichero y lanzar todos los contenedores definidos en dichero fichero. Durante la instalaci\u00f3n de Docker-CE esta herramienta no se instala, por lo que ser\u00e1 necesaria la instalaci\u00f3n de forma independiente. En la documentaci\u00f3n oficial se encuentran diferentes gu\u00edas para la instalaci\u00f3n en los diferentes Sistemas Operativos. En la m\u00e1quina actual, en la que estamos trabajando bajo Linux, la instalaci\u00f3n se har\u00eda del siguiente modo: Descargamos Docker-Compose. sudo curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose Aplicar permisos de ejecuci\u00f3n al ejecutable que hemos descargado. sudo chmod +x /usr/local/bin/docker-compose","title":"Docker Compose"},{"location":"Docker/Docker/#comenzando-con-docker-compose","text":"El nombre del fichero que debemos utilizar es docker-compose.yml , donde definiremos los diferentes contenedores. Este fichero cuenta con cuatro grandes partes: Version (obligatorio): para saber que n\u00famero de versi\u00f3n (Docker-Compose) debemos establecer, buscamos en la documentaci\u00f3n cual es la \u00faltima versi\u00f3n, suele ser la que se recomienda utilizar. Services (obligatorio): los servicios hacen referencia a los contenedores. En primera instancia definimos los nombres de cada servicio (podemos elegir el que queramos), y debajo de ellos ir\u00e1n los par\u00e1metros que hacen referencia al propio contenedor, como el nombre del contenedor, la imagen a la que hace referencia, puertos, variables de entorno, etc. Volumes (opcional): Vol\u00famenes nombrados : funcionan del mismo modo que ejecutando docker run . Lo que hacemos es definir en primer lugar el volumen que crear\u00edamos con la instrucci\u00f3n docker volume create en \"volumes\" con el nombre que queramos. A continuaci\u00f3n lo definimos dentro del servicio. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"html:/usr/share/nginx/html\" volumes : html : Vol\u00famenes host : no necesitamos la parte volumes dentro del fichero docker-compose.yml sino que directamente en el contenedorlo podemos parametrizar. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"/home/miusuario/html:/usr/share/nginx/html\" Networks (opcional): Red Host : es importante establecer la versi\u00f3n 3.4 para que funcione correctamente . Para que funcione es necesario a\u00f1adir build , y adem\u00e1s a\u00f1adir el contexto , que hace referencia a un directorio que contenga un Dockerfile o una url a un repositorio git. Si establecemos la ruta relativa hace referencia a la ubicaci\u00f3n del archivo de composici\u00f3n. version : '3.4' services : web : build : context : . network : host image : nginx container_name : nginx-prueba ports : - \"8181:80\" Creaci\u00f3n de una nueva red con subnet. A\u00fan no se permite establecer gateway . version : '3' services : web : image : nginx container_name : nginx-prueba ports : - \"8181:80\" networks : red-prueba : - ipv4_address : 192.168.50.10 networks : red-prueba : ipam : driver : default config : - subnet : \"192.168.50.0/24\" En cuanto a las redes, cuando ejecutamos el comando docker-compose up -d se genera una red espec\u00edfica para docker-compose . Si no definimos una red, la red utilizada ser\u00e1 la red por defecto (docker-compose_default). Cuando se crea la red, el nombre que es otorgado \" directorioactual_nombredelared \". Es posible modificar la parte del nombre que hace referencia al \"directorioactual\", pasando el par\u00e1metro -p . Por lo tanto si nuestro directorio actual se denomina docker-compose y queremos que el prefijo sea por ejemplo dcprueba ejecutar\u00edamos el siguiente comando: #Modificar el nombre de red a \"dcprueba_default\" docker-compose -p dcprueba up -d Por otro lado, tenemos dos partes importantes que se utilizan a la hora de crear contenedores. Variables de entorno: estas se pueden definir de dos modos. Fichero docker-compose.yml environment : - \"VARIABLES1=docker\" Fichero con extensi\u00f3n .env. environment : - variables.env Command: se utiliza para establecer un CMD al contenedor. commmand : mkdir /bin/bash El comando docker-compose se encarga de realizar un proceso similar que el comando docker run , pero en este caso los diferentes par\u00e1metros se encuentran definidos en un fichero. Por lo tanto, las pol\u00edticas de reinicio o la limitaci\u00f3n de recursos tambi\u00e9n se pueden definir. Pol\u00edticas de reinicio: #Reinicio siempre restart : always #Reinicio hasta que lo detengamos de forma manual restart : unless-stopped #\u00danicamente se reinicia el contenedor en caso de que haya habido un fallo restart : on-failure Limitar recursos: #Limitar memoria mem_limit : 20m #Cpu cpuset : \"0\" Otras de las directivas relevantes de este fichero es depends_on , la cual hace referencia a las dependencias que tiene se contenedor respecto a los que se incluyan en esta directiva. version : '3' services : web : image : nginx container_name : nginx-prueba depends_on : db db : image : postgres container_name : nginx-database El \u00faltimo paso ser\u00e1 conocer como podemos eliminar un contenedor creado con la herramienta Docker-Compose. Para ello debemos ejecutar el siguiente comando, situados en el directorio donde se encuentra el fichero yaml . docker-compose down El comando anterior sigue el siguiente proceso: Detiene el contenedor. Elimina el contenedor. Elimina la red que ha creado por defecto.","title":"Comenzando con Docker Compose"},{"location":"Docker/Docker/#docker-compose-build","text":"Ya conocemos el comando docker build , es el encargado de crear im\u00e1genes. El comando docker-compose build tiene un funcionamiento similar, se encarga de generar una imagen a partir de la definici\u00f3n de build en el fichero yaml . Esta imagen ser\u00e1 utilizada como imagen base en la creaci\u00f3n del contenedor. Para que se construya una imagen, sabemos que necesitamos un fichero Dockerfile , en el cual se encuentran las capas para la construcci\u00f3n de una imagen. En la sentencia build nos encontramos con dos par\u00e1metros importantes. Context: se indica la ruta donde se encuentra el Dockerfile que utilizaremos para crear la imagen. Si se encuentra en el mismo directorio se utilizar\u00e1 el punto ( . ). Dockerfile: el nombre del fichero si este es diferente al nombre por defecto (Dockerfile). version : '3' services : web : container_name : web image : web-test build : context : . dockerfile : Dockerfile1 *Si el nombre que hace referencia al Dockerfile no se ha modificado, podemos obviar estos dos par\u00e1metros. version : '3' services : web : container_name : web image : web-test build : .","title":"Docker-compose build"},{"location":"Docker/Docker/#otros-conceptos","text":"","title":"Otros conceptos"},{"location":"Docker/Docker/#fuentes","text":"","title":"Fuentes"},{"location":"Docker/contenedores-docker/","text":"Un contenedor se entiende como una capa adicional que mantiene en ejecuci\u00f3n las capas que se han definido en el fichero Dockerfile, por este motivo es posible crear tantos contenedores como se deseen a partir de la misma imagen. A diferencia del resto de capas, esta capa es de lectura y escritura ( rw ), por lo tanto nos permite realizar modificaciones sobre las capas anteriores cuando el contenedor se encuentra en ejecuci\u00f3n. Todas estas modificaciones son temporales puesto que no sobrescriben el fichero Dockerfile, por lo tanto una vez que eliminemos el contenedor esas modificaciones se perder\u00e1n (algunas modificaciones pueden ser persistentes mediante el uso de vol\u00famenes que veremos m\u00e1s adelante). \u00bfQu\u00e9 nos encontramos dentro de un contenedor? Imagen Vol\u00famenes (se utilizan para mantener persistente cierto contenido) Redes (\u00fatil para comunicar contenedores entre s\u00ed) Contenedor VS M\u00e1quina Virtual # El contenedor es un proceso aislado m\u00e1s del sistema, por lo tanto compartir\u00e1 el mismo hardware que est\u00e9 utilizando el sistema operativo anfitri\u00f3n, es decir, no necesitamos asignarle recursos espec\u00edficamente (aunque es posible limitar los recursos utilizados por un contenedor). En cambio, cuando creamos una m\u00e1quina virtual debemos asignarle una serie de recursos, como pueden ser el n\u00famero de nucleos, la memoria ram o el espacio en disco duro. En este caso obtenemos una m\u00e1quina completa dentro del propio sistema anfitri\u00f3n. La principal diferencia que nos podemos encontrar es la ligereza, un contenedor est\u00e1 destinado a ser much\u00edsimo m\u00e1s ligero que una m\u00e1quina virtual, habitualmente un contenedor se utiliza para ejecutar una \u00fanica aplicaci\u00f3n concreta. Docker run # Este comando se utiliza para iniciar los contenedores. Aunque parece evidente, no puede haber dos contenedores con el mismo nombre, aunque uno de ellos se encuentre parado. docker run -d jenkins -p 80 :8080 -d : permite correr un contenedor en segundo plano. jenkins : es el nombre de la imagen utilizada. -p : permite mapear los puertos. El puerto que se encuentra en el lado izquierdo es el que utilizar\u00e1 el sistema anfitri\u00f3n, el puerto de la derecha es el interno del contenedor. -e: asignaci\u00f3n de variables de entorno. En algunas ocasiones si no definimos la capa CMD es posible que el contenedor se muera. Si queremos evitar que esto sucede podemos utilizar los par\u00e1metros -i y -t para interactuar con el contenedor. Limitando recursos # Por defecto Docker utiliza los recursos de la m\u00e1quina anfitriona sin l\u00edmite alguno, a pesar de ello los contenedores consumen muy pocos recursos. Podemos limitar tanto el uso de CPU como de RAM . #Limitando la memoria RAM docker run -d --memory \"100mb\" --name recursos-limitados centos Cuando se muestran las estad\u00edsticas con el comando docker stats ya no mostrar\u00e1 la RAM limite de nuestra m\u00e1quina, sino que los que hayamos establecido, en este caso ser\u00e1n 100MB. Podemos pasar la limitaci\u00f3n en bytes (b), kilobytes (k), megabytes (m) o gigabytes (g). #Limitando el n\u00famero de cores de la CPU docker run -d --cpuset-cpus 0 -3 --name reclimited2 centos Los n\u00facleos (o cores) se pueden definir mediante un rango (como hemos hecho en el ejemplo anterior) o numer\u00e1ndolos y como separaci\u00f3n una coma. 0-2 \u2192 utilizar\u00edamos los n\u00facleos 0, 1 y 2. 0,2 \u2192 utilizar\u00edamos los n\u00facleos 0 y 2. Pol\u00edticas de reinicio # Establecemos que sucede cuando un contenedor se \"apaga\" de forma inesperada. Disponemos de las siguientes opciones: No (es la pol\u00edtica por defecto): el contenedor no se reiniciar\u00e1 autom\u00e1ticamente. Si hacemos una prueba deteniendo cualquier contenedor que tengamos en funcionamiento, veremos que este se detiene y ejecutando el comando docker ps no aparece. Always : con esta opci\u00f3n el contenedor siempre se reiniciar\u00e1. Unless-stopped: se reiniciar\u00e1 siempre, salvo que sea detenido manualmente. On-failure : se reiniciar\u00e1 en caso de que el contenedor se haya detenido por alg\u00fan fallo. La pol\u00edtica de reinicios se establece ejecutando el par\u00e1metro --restart . docker run --restart unless-stopped","title":"Contenedores"},{"location":"Docker/contenedores-docker/#contenedor-vs-maquina-virtual","text":"El contenedor es un proceso aislado m\u00e1s del sistema, por lo tanto compartir\u00e1 el mismo hardware que est\u00e9 utilizando el sistema operativo anfitri\u00f3n, es decir, no necesitamos asignarle recursos espec\u00edficamente (aunque es posible limitar los recursos utilizados por un contenedor). En cambio, cuando creamos una m\u00e1quina virtual debemos asignarle una serie de recursos, como pueden ser el n\u00famero de nucleos, la memoria ram o el espacio en disco duro. En este caso obtenemos una m\u00e1quina completa dentro del propio sistema anfitri\u00f3n. La principal diferencia que nos podemos encontrar es la ligereza, un contenedor est\u00e1 destinado a ser much\u00edsimo m\u00e1s ligero que una m\u00e1quina virtual, habitualmente un contenedor se utiliza para ejecutar una \u00fanica aplicaci\u00f3n concreta.","title":"Contenedor VS M\u00e1quina Virtual"},{"location":"Docker/contenedores-docker/#docker-run","text":"Este comando se utiliza para iniciar los contenedores. Aunque parece evidente, no puede haber dos contenedores con el mismo nombre, aunque uno de ellos se encuentre parado. docker run -d jenkins -p 80 :8080 -d : permite correr un contenedor en segundo plano. jenkins : es el nombre de la imagen utilizada. -p : permite mapear los puertos. El puerto que se encuentra en el lado izquierdo es el que utilizar\u00e1 el sistema anfitri\u00f3n, el puerto de la derecha es el interno del contenedor. -e: asignaci\u00f3n de variables de entorno. En algunas ocasiones si no definimos la capa CMD es posible que el contenedor se muera. Si queremos evitar que esto sucede podemos utilizar los par\u00e1metros -i y -t para interactuar con el contenedor.","title":"Docker run"},{"location":"Docker/contenedores-docker/#limitando-recursos","text":"Por defecto Docker utiliza los recursos de la m\u00e1quina anfitriona sin l\u00edmite alguno, a pesar de ello los contenedores consumen muy pocos recursos. Podemos limitar tanto el uso de CPU como de RAM . #Limitando la memoria RAM docker run -d --memory \"100mb\" --name recursos-limitados centos Cuando se muestran las estad\u00edsticas con el comando docker stats ya no mostrar\u00e1 la RAM limite de nuestra m\u00e1quina, sino que los que hayamos establecido, en este caso ser\u00e1n 100MB. Podemos pasar la limitaci\u00f3n en bytes (b), kilobytes (k), megabytes (m) o gigabytes (g). #Limitando el n\u00famero de cores de la CPU docker run -d --cpuset-cpus 0 -3 --name reclimited2 centos Los n\u00facleos (o cores) se pueden definir mediante un rango (como hemos hecho en el ejemplo anterior) o numer\u00e1ndolos y como separaci\u00f3n una coma. 0-2 \u2192 utilizar\u00edamos los n\u00facleos 0, 1 y 2. 0,2 \u2192 utilizar\u00edamos los n\u00facleos 0 y 2.","title":"Limitando recursos"},{"location":"Docker/contenedores-docker/#politicas-de-reinicio","text":"Establecemos que sucede cuando un contenedor se \"apaga\" de forma inesperada. Disponemos de las siguientes opciones: No (es la pol\u00edtica por defecto): el contenedor no se reiniciar\u00e1 autom\u00e1ticamente. Si hacemos una prueba deteniendo cualquier contenedor que tengamos en funcionamiento, veremos que este se detiene y ejecutando el comando docker ps no aparece. Always : con esta opci\u00f3n el contenedor siempre se reiniciar\u00e1. Unless-stopped: se reiniciar\u00e1 siempre, salvo que sea detenido manualmente. On-failure : se reiniciar\u00e1 en caso de que el contenedor se haya detenido por alg\u00fan fallo. La pol\u00edtica de reinicios se establece ejecutando el par\u00e1metro --restart . docker run --restart unless-stopped","title":"Pol\u00edticas de reinicio"},{"location":"Docker/docker-compose/","text":"Es una herramienta que nos ayuda a orquestar contenedores en Docker, gestionar los diferentes contenedores de los que depende una aplicaci\u00f3n. Existen aplicaciones que para su correcto funcionamiento dependen de varios servicios, para seguir con la simplicidad de \" un servicio = un contenedor \", Docker Compose nos permitir\u00e1 administrar los diferentes contenedores de forma grupal. Docker Compose trabaja con ficheros de tipo yaml , en los que se definen los contenedores, vol\u00famenes, redes, etc. Despu\u00e9s de completar el fichero, docker-compose como comando se encarga de la lectura del fichero y lanzar todos los contenedores definidos en dichero fichero. Durante la instalaci\u00f3n de Docker-CE esta herramienta no se instala, por lo que ser\u00e1 necesaria la instalaci\u00f3n de forma independiente. En la documentaci\u00f3n oficial se encuentran diferentes gu\u00edas para la instalaci\u00f3n en los diferentes Sistemas Operativos. En la m\u00e1quina actual, en la que estamos trabajando bajo Linux, la instalaci\u00f3n se har\u00eda del siguiente modo: Descargamos Docker-Compose. sudo curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose Aplicar permisos de ejecuci\u00f3n al ejecutable que hemos descargado. sudo chmod +x /usr/local/bin/docker-compose Comenzando con Docker Compose # El nombre del fichero que debemos utilizar es docker-compose.yml , donde definiremos los diferentes contenedores. Este fichero cuenta con cuatro grandes partes: Version # Para saber que n\u00famero de versi\u00f3n (Docker-Compose) debemos establecer, buscamos en la documentaci\u00f3n cual es la \u00faltima versi\u00f3n, suele ser la que se recomienda utilizar. Esta l\u00ednea dentro del fichero es obligatoria. Services # Los servicios hacen referencia a los contenedores. En primera instancia definimos los nombres de cada servicio (podemos elegir el que queramos), y debajo de ellos ir\u00e1n los par\u00e1metros que hacen referencia al propio contenedor, como el nombre del contenedor, la imagen a la que hace referencia, puertos, variables de entorno, etc. Vol\u00famenes # Vol\u00famenes nombrados : funcionan del mismo modo que ejecutando docker run . Lo que hacemos es definir en primer lugar el volumen que crear\u00edamos con la instrucci\u00f3n docker volume create en \"volumes\" con el nombre que queramos. A continuaci\u00f3n lo definimos dentro del servicio. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"html:/usr/share/nginx/html\" volumes : html : Vol\u00famenes host : no necesitamos la parte volumes dentro del fichero docker-compose.yml sino que directamente en el contenedorlo podemos parametrizar. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"/home/miusuario/html:/usr/share/nginx/html\" Networks # Red Host : es importante establecer la versi\u00f3n 3.4 para que funcione correctamente . Para que funcione es necesario a\u00f1adir build , y adem\u00e1s a\u00f1adir el contexto , que hace referencia a un directorio que contenga un Dockerfile o una url a un repositorio git. Si establecemos la ruta relativa hace referencia a la ubicaci\u00f3n del archivo de composici\u00f3n. version : '3.4' services : web : build : context : . network : host image : nginx container_name : nginx-prueba ports : - \"8181:80\" Creaci\u00f3n de una nueva red con subnet. A\u00fan no se permite establecer gateway . version : '3' services : web : image : nginx container_name : nginx-prueba ports : - \"8181:80\" networks : red-prueba : - ipv4_address : 192.168.50.10 networks : red-prueba : ipam : driver : default config : - subnet : \"192.168.50.0/24\" En cuanto a las redes, cuando ejecutamos el comando docker-compose up -d se genera una red espec\u00edfica para docker-compose . Si no definimos una red, la red utilizada ser\u00e1 la red por defecto (docker-compose_default). Cuando se crea la red, el nombre que es otorgado \" directorioactual_nombredelared \". Es posible modificar la parte del nombre que hace referencia al \"directorioactual\", pasando el par\u00e1metro -p . Por lo tanto si nuestro directorio actual se denomina docker-compose y queremos que el prefijo sea por ejemplo dcprueba ejecutar\u00edamos el siguiente comando: #Modificar el nombre de red a \"dcprueba_default\" docker-compose -p dcprueba up -d Por otro lado, tenemos dos partes importantes que se utilizan a la hora de crear contenedores. Variables de entorno: estas se pueden definir de dos modos. Fichero docker-compose.yml environment : - \"VARIABLES1=docker\" Fichero con extensi\u00f3n .env. environment : - variables.env Command: se utiliza para establecer un CMD al contenedor. commmand : mkdir /bin/bash El comando docker-compose se encarga de realizar un proceso similar que el comando docker run , pero en este caso los diferentes par\u00e1metros se encuentran definidos en un fichero. Por lo tanto, las pol\u00edticas de reinicio o la limitaci\u00f3n de recursos tambi\u00e9n se pueden definir. Pol\u00edticas de reinicio: #Reinicio siempre restart : always #Reinicio hasta que lo detengamos de forma manual restart : unless-stopped #\u00danicamente se reinicia el contenedor en caso de que haya habido un fallo restart : on-failure Limitar recursos: #Limitar memoria mem_limit : 20m #Cpu cpuset : \"0\" Otras de las directivas relevantes de este fichero es depends_on , la cual hace referencia a las dependencias que tiene se contenedor respecto a los que se incluyan en esta directiva. version : '3' services : web : image : nginx container_name : nginx-prueba depends_on : db db : image : postgres container_name : nginx-database El \u00faltimo paso ser\u00e1 conocer como podemos eliminar un contenedor creado con la herramienta Docker-Compose. Para ello debemos ejecutar el siguiente comando, situados en el directorio donde se encuentra el fichero yaml . docker-compose down El comando anterior sigue el siguiente proceso: Detiene el contenedor. Elimina el contenedor. Elimina la red que ha creado por defecto. Docker-compose build # Ya conocemos el comando docker build , es el encargado de crear im\u00e1genes. El comando docker-compose build tiene un funcionamiento similar, se encarga de generar una imagen a partir de la definici\u00f3n de build en el fichero yaml . Esta imagen ser\u00e1 utilizada como imagen base en la creaci\u00f3n del contenedor. Para que se construya una imagen, sabemos que necesitamos un fichero Dockerfile , en el cual se encuentran las capas para la construcci\u00f3n de una imagen. En la sentencia build nos encontramos con dos par\u00e1metros importantes. Context: se indica la ruta donde se encuentra el Dockerfile que utilizaremos para crear la imagen. Si se encuentra en el mismo directorio se utilizar\u00e1 el punto ( . ). Dockerfile: el nombre del fichero si este es diferente al nombre por defecto (Dockerfile). version : '3' services : web : container_name : web image : web-test build : context : . dockerfile : Dockerfile1 Note Si el nombre que hace referencia al Dockerfile no se ha modificado, podemos obviar estos dos par\u00e1metros. version : '3' services : web : container_name : web image : web-test build : .","title":"Docker Compose"},{"location":"Docker/docker-compose/#comenzando-con-docker-compose","text":"El nombre del fichero que debemos utilizar es docker-compose.yml , donde definiremos los diferentes contenedores. Este fichero cuenta con cuatro grandes partes:","title":"Comenzando con Docker Compose"},{"location":"Docker/docker-compose/#version","text":"Para saber que n\u00famero de versi\u00f3n (Docker-Compose) debemos establecer, buscamos en la documentaci\u00f3n cual es la \u00faltima versi\u00f3n, suele ser la que se recomienda utilizar. Esta l\u00ednea dentro del fichero es obligatoria.","title":"Version"},{"location":"Docker/docker-compose/#services","text":"Los servicios hacen referencia a los contenedores. En primera instancia definimos los nombres de cada servicio (podemos elegir el que queramos), y debajo de ellos ir\u00e1n los par\u00e1metros que hacen referencia al propio contenedor, como el nombre del contenedor, la imagen a la que hace referencia, puertos, variables de entorno, etc.","title":"Services"},{"location":"Docker/docker-compose/#volumenes","text":"Vol\u00famenes nombrados : funcionan del mismo modo que ejecutando docker run . Lo que hacemos es definir en primer lugar el volumen que crear\u00edamos con la instrucci\u00f3n docker volume create en \"volumes\" con el nombre que queramos. A continuaci\u00f3n lo definimos dentro del servicio. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"html:/usr/share/nginx/html\" volumes : html : Vol\u00famenes host : no necesitamos la parte volumes dentro del fichero docker-compose.yml sino que directamente en el contenedorlo podemos parametrizar. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"/home/miusuario/html:/usr/share/nginx/html\"","title":"Vol\u00famenes"},{"location":"Docker/docker-compose/#networks","text":"Red Host : es importante establecer la versi\u00f3n 3.4 para que funcione correctamente . Para que funcione es necesario a\u00f1adir build , y adem\u00e1s a\u00f1adir el contexto , que hace referencia a un directorio que contenga un Dockerfile o una url a un repositorio git. Si establecemos la ruta relativa hace referencia a la ubicaci\u00f3n del archivo de composici\u00f3n. version : '3.4' services : web : build : context : . network : host image : nginx container_name : nginx-prueba ports : - \"8181:80\" Creaci\u00f3n de una nueva red con subnet. A\u00fan no se permite establecer gateway . version : '3' services : web : image : nginx container_name : nginx-prueba ports : - \"8181:80\" networks : red-prueba : - ipv4_address : 192.168.50.10 networks : red-prueba : ipam : driver : default config : - subnet : \"192.168.50.0/24\" En cuanto a las redes, cuando ejecutamos el comando docker-compose up -d se genera una red espec\u00edfica para docker-compose . Si no definimos una red, la red utilizada ser\u00e1 la red por defecto (docker-compose_default). Cuando se crea la red, el nombre que es otorgado \" directorioactual_nombredelared \". Es posible modificar la parte del nombre que hace referencia al \"directorioactual\", pasando el par\u00e1metro -p . Por lo tanto si nuestro directorio actual se denomina docker-compose y queremos que el prefijo sea por ejemplo dcprueba ejecutar\u00edamos el siguiente comando: #Modificar el nombre de red a \"dcprueba_default\" docker-compose -p dcprueba up -d Por otro lado, tenemos dos partes importantes que se utilizan a la hora de crear contenedores. Variables de entorno: estas se pueden definir de dos modos. Fichero docker-compose.yml environment : - \"VARIABLES1=docker\" Fichero con extensi\u00f3n .env. environment : - variables.env Command: se utiliza para establecer un CMD al contenedor. commmand : mkdir /bin/bash El comando docker-compose se encarga de realizar un proceso similar que el comando docker run , pero en este caso los diferentes par\u00e1metros se encuentran definidos en un fichero. Por lo tanto, las pol\u00edticas de reinicio o la limitaci\u00f3n de recursos tambi\u00e9n se pueden definir. Pol\u00edticas de reinicio: #Reinicio siempre restart : always #Reinicio hasta que lo detengamos de forma manual restart : unless-stopped #\u00danicamente se reinicia el contenedor en caso de que haya habido un fallo restart : on-failure Limitar recursos: #Limitar memoria mem_limit : 20m #Cpu cpuset : \"0\" Otras de las directivas relevantes de este fichero es depends_on , la cual hace referencia a las dependencias que tiene se contenedor respecto a los que se incluyan en esta directiva. version : '3' services : web : image : nginx container_name : nginx-prueba depends_on : db db : image : postgres container_name : nginx-database El \u00faltimo paso ser\u00e1 conocer como podemos eliminar un contenedor creado con la herramienta Docker-Compose. Para ello debemos ejecutar el siguiente comando, situados en el directorio donde se encuentra el fichero yaml . docker-compose down El comando anterior sigue el siguiente proceso: Detiene el contenedor. Elimina el contenedor. Elimina la red que ha creado por defecto.","title":"Networks"},{"location":"Docker/docker-compose/#docker-compose-build","text":"Ya conocemos el comando docker build , es el encargado de crear im\u00e1genes. El comando docker-compose build tiene un funcionamiento similar, se encarga de generar una imagen a partir de la definici\u00f3n de build en el fichero yaml . Esta imagen ser\u00e1 utilizada como imagen base en la creaci\u00f3n del contenedor. Para que se construya una imagen, sabemos que necesitamos un fichero Dockerfile , en el cual se encuentran las capas para la construcci\u00f3n de una imagen. En la sentencia build nos encontramos con dos par\u00e1metros importantes. Context: se indica la ruta donde se encuentra el Dockerfile que utilizaremos para crear la imagen. Si se encuentra en el mismo directorio se utilizar\u00e1 el punto ( . ). Dockerfile: el nombre del fichero si este es diferente al nombre por defecto (Dockerfile). version : '3' services : web : container_name : web image : web-test build : context : . dockerfile : Dockerfile1 Note Si el nombre que hace referencia al Dockerfile no se ha modificado, podemos obviar estos dos par\u00e1metros. version : '3' services : web : container_name : web image : web-test build : .","title":"Docker-compose build"},{"location":"Docker/imagenes-docker/","text":"\u00bfQu\u00e9 es una imagen? # Una imagen en Docker es una especie de instant\u00e1nea de un contenedor. Para entenderlo de una forma m\u00e1s sencilla, desglosaremos una imagen en diferentes capas. Primera capa (FROM): se define el sistema operativo (Alpine, CentOS, Ubuntu), de aqu\u00ed partir\u00e1 el tama\u00f1o m\u00ednimo de nuestra imagen. Segunda capa (RUN): se ejecutan diferentes comandos, habitualmente para la instalaci\u00f3n de paquetes necesarios para nuestra aplicaci\u00f3n. Tercera capa (CMD): es la parte que mantendr\u00e1 en ejecuci\u00f3n el contenedor. Estas capas se definen en el fichero Dockerfile **y son de s\u00f3lo lectura (RO - Read Only). Aqu\u00ed podemos ver un ejemplo de un **Dockerfile . FROM centos:7 RUN yum -y install httpd CMD [ \"apachectl\" , \"-DFOREGROUND\" ] El par\u00e1metro CMD es el que mantiene \" vivo \" el contenedor, en el ejemplo anterior es necesario utilizar como par\u00e1metro -DFOREGROUND del comando apachectl para que el contenedor se mantenga en ejecuci\u00f3n. Note \u00danicamente podemos encontrar una instrucci\u00f3n CMD en un Dockerfile , en caso de que haya m\u00e1s de una, s\u00f3lo se tendr\u00e1 en cuenta la \u00faltima Podemos definir la instrucci\u00f3n CMD de tres modos diferentes: Execform , es la forma m\u00e1s adecuada. CMD [ \"ejecutable\" , \"par\u00e1metro1\" , \"par\u00e1metro2\" ] #Ruta completa al ejecutable. CMD [ \"/bin/echo\" , \"Hola mundo\" ] #Bash como ejecutable, pasando el par\u00e1metro \"-c\" podemos ejecutar comandos como si estuviesemos en la terminal. CMD [ \"/bin/bash\" , \"-c\" , \"echo Hola mundo\" ] Como par\u00e1metros que acompa\u00f1an a la instrucci\u00f3n ENTRYPOINT . CMD [ \"par\u00e1metro1\" , \"par\u00e1metro2\" ] En formato shell , por debajo ejecuta /bin/sh -c . CMD comando par\u00e1metro1 par\u00e1metro2 La diferencia fundamental entre CMD y ENTRYPOINT se basa en que con el primero de ellos, cuando ejecutamos docker run con un comando espec\u00edfico, este comando sobrescribir\u00e1 el comando definido en el fichero Dockerfile . CMD ser\u00e1 el que utilizaremos habitualmente porque nos permite pasar par\u00e1metros cuando iniciemos el contenedor. ENTRYPOINT en caso de querer tener un contenedor como ejecutable, sin intenci\u00f3n de pasar ning\u00fan par\u00e1metro adicional. Descargando im\u00e1genes # Para la descarga de im\u00e1genes utilizaremos el comando docker pull . Es posible pasar diferentes par\u00e1metros, uno de los m\u00e1s habituales es el tag o etiqueta . Esta etiqueta nos permite elegir entre diferentes versiones del mismo contenedor, una imagen compatible con la arquitectura de nuestro procesador o una versi\u00f3n, de la aplicaci\u00f3n empaquetada en la imagen, particular que necesitemos. Ejemplo: #Descarga la versi\u00f3n 3.6.5 de mongo docker pull mongo:3.6.5-jessie En el ejemplo anterior hemos descargado una versi\u00f3n espec\u00edfica indic\u00e1ndole el tag despu\u00e9s de los dos puntos. \u00bfQu\u00e9 es una etiqueta (tag)? # Una etiqueta o tag identifica la imagen que vamos a descargarnos. Es una forma sencilla de versionar las im\u00e1genes. Si no establecemos este par\u00e1metro, la etiqueta por defecto que utilizar\u00e1 Docker es latest . Las etiquetas disponibles por cada imagen se encuentran enumeradas en el propio repositorio, adem\u00e1s en la documentaci\u00f3n se encuentran instrucciones que facilitan la elecci\u00f3n del tag de la imagen. A continuaci\u00f3n se encuentran dos enlaces que explican de forma extendida las etiquetas de las im\u00e1genes de Docker y que formas sencillas hay para versionar una imagen. The misunderstood Docker tag: latest Using Semver for Docker Image Tags Desarrollando im\u00e1genes # La forma sencilla para comenzar ha realizar pruebas es crear un directorio de trabajo que utilizaremos para desarrollar las primeras im\u00e1genes. En este directorio es necesario contar con un fichero Dockerfile (lo podemos crear ejecutando touch Dockerfile ), el cual contendr\u00e1 las capas que hemos visto m\u00e1s arriba. Este fichero es el utilizado por el comando docker build para crear las im\u00e1genes. Note Podemos llamar al fichero Dockerfile de cualquier otro modo, pero cuando creemos el contenedor ( docker build ) deberemos indicarle con el par\u00e1metro -f el nombre del fichero. Dockerfile # \u00bfQu\u00e9 instrucciones nos podemos encontrar dentro de este fichero? COPY : permite copiar un fichero o directorio del host a la imagen. ADD : adem\u00e1s de lo que nos permite realizar la instrucci\u00f3n COPY , esta nos permite pasar una URL para que descargue el contenido en la ruta que indiquemos dentro de la imagen. ENV : se utiliza para a\u00f1adir variables de entorno. La variable se establece sin el signo = , la variable y el valor se define con un espacio entre ambos. Ejemplo: ENV nombre juan WORKDIR : define el directorio de trabajo dentro del contenedor. Si no definimos este par\u00e1metro, por defecto nos encontramos en el directorio ra\u00edz / . EXPOSE : permite exponer puertos. Realmente esta instrucci\u00f3n no realizar ninguna exposici\u00f3n, simplemente informa a la persona que va a utilizar la imagen para crear el contenedor que puertos debe configurar. Estos puertos se expondr\u00e1n utilizando la opci\u00f3n -p del comando docker run . LABEL : hace referencia a una etiqueta, que se utiliza habitualmente para a\u00f1adir metadatos (informaci\u00f3n sobre la imagen como versi\u00f3n, creador, etc.). USER : identifica al usuario que ejecuta las instrucciones definidas en el fichero Dockerfile (las instrucciones que se establezcan a partir de la instrucci\u00f3n user ). Por defecto el usuario que ejecuta las instrucciones es el usuario root . VOLUME : permite que los datos que se encuentran en estos \"vol\u00famenes\" sean persistentes, ya que despu\u00e9s de eliminar el contenedor asociado a este volumen los datos no se perder\u00e1n. CMD : se entiende como la instrucci\u00f3n que mantiene vivo el contenedor. A continuaci\u00f3n veremos un Dockerfile con todas las instrucciones vistas hasta el momento: FROM nginx LABEL version = 1 .0 RUN useradd prueba USER prueba WORKDIR /usr/share/nginx/html COPY web /usr/share/nginx/html ENV variable1 tzinm EXPOSE 90 VOLUME /var/log/nginx CMD nginx -g 'daemon off;' Las instrucciones que definimos dentro de este fichero deben ser lo m\u00e1s estrictas posibles para evitar errores, por ello es importante tener en cuenta lo siguiente: Un servicio por contenedor. Utilizar la capa Labels para a\u00f1adir metadatos. Agrupar los argumentos, evitando crear una capa por cada argumento. Forma correcta RUN \\ python3 -m pip install telegram --upgrade && \\ python3 -m pip install python-telegram-bot --upgrade && \\ chown root:root AddToQbitTorrentFolder.py && \\ chmod 644 AddToQbitTorrentFolder.py Forma incorrecta RUN python3 -m pip install telegram --upgrade RUN python3 -m pip install python-telegram-bot --upgrade RUN chown root:root AddToQbitTorrentFolder.py RUN chmod 644 AddToQbitTorrentFolder.py Evitar la instalaci\u00f3n de paquetes innecesarios, de ese modo crearemos im\u00e1genes m\u00e1s ligeras. Adem\u00e1s del fichero Dockerfile hay otro fichero importante llamado .dockerignore . El funcionamiento de este es similar al fichero .gitignore , es un fichero oculto en el que definimos que contenido del directorio no queremos que sea tenido en cuenta. Docker Build # Una vez que tenemos nuestro Dockerfile terminado debemos ejecutar el comando docker build para crear nuestra imagen. docker build -t tzinm/test . En el comando ejecutado se ha denominado a la imagen tzinm/test , al no haber especificado ning\u00fan tag ser\u00e1 el tag latest el que se haya establecido. Otro dato importante es el punto del final, que hace referencia al contexto , es decir el directorio en el cual Docker buscar\u00e1 los ficheros necesarios para crear la imagen. Multi-Stage Builds # Esta nueva funcionalidad que nos ofrece Docker se encuentra disponible a partir de la versi\u00f3n 17.05. Es una utilidad interesante ya que nos permite crear En ocasiones, algunas im\u00e1genes necesitan cierto contenido que es generado mediante la compilaci\u00f3n o ejecuci\u00f3n de una serie de instrucciones que hace que el peso de una imagen crezca y su rendimiento no est\u00e9 lo m\u00e1s optimizado posible. Es aqu\u00ed cuando esta herramienta ( multi-stage builds ) es \u00fatil, ya que nos permite en una primera instancia crear una imagen \"al vuelo\" en la que generaremos esos ficheros mediante las instrucciones que necesitemos. Despu\u00e9s esos ficheros ser\u00e1n enviados (veremos luego en un ejemplo como se realiza esto) a la segunda imagen, exclusivamente esos ficheros, desprendi\u00e9ndonos de la primera imagen y todo lo que ello conlleva. Recordamos que para hacer un uso adecuado de Docker es necesario optimizar al m\u00e1ximo las im\u00e1genes, es la base de las buenas pr\u00e1cticas. A la hora de crear el fichero Dockerfile es muy similar al que utilizamos construyendo una \u00fanica imagen, salvo que en esta ocasi\u00f3n nos encontramos con la construcci\u00f3n de dos im\u00e1genes - por lo tanto dos FROM - y en la segunda imagen a\u00f1adimos una capa - COPY - con el flag --from=primar-imagen que se encargar\u00e1 de pasar el contenido generado en la primera imagen ( primer FROM ). Se puede ver un poco m\u00e1s claro en el siguiente ejemplo. FROM centos as test RUN fallocate -l 10M /tmp/file1 && \\ fallocate -l 40M /tmp/file2 FROM alpine COPY --from = test /tmp/file1 /tmp/test1 Dangling images # Este concepto hace referencia a im\u00e1genes hu\u00e9rfanas, que no son m\u00e1s que aquellas im\u00e1genes que se encuentran sin referenciar . Esto sucede cuando una imagen es construida utilizando el mismo nombre y tag que otra creada anteriormente. La nueva imagen creada ser\u00e1 v\u00e1lida, en cambio las im\u00e1genes anteriores que existiesen no ser\u00e1n v\u00e1lidas y pasar\u00e1n a tener como nombre y tag el valor \\<none> . A pesar de que estas im\u00e1genes no son v\u00e1lidas, seguir\u00e1n estando en nuestro sistema y ocupando espacio, por ello es recomendable eliminarlas. El modo m\u00e1s r\u00e1pido de eliminar todas estas im\u00e1genes es mediante el siguiente comando: docker rmi $( docker images -f \"dangling=true\" -q ) En el comando anterior hemos utilizado el flag -f , que permite el filtrado de las im\u00e1genes siguiendo una serie de patrones .","title":"Im\u00e1genes"},{"location":"Docker/imagenes-docker/#que-es-una-imagen","text":"Una imagen en Docker es una especie de instant\u00e1nea de un contenedor. Para entenderlo de una forma m\u00e1s sencilla, desglosaremos una imagen en diferentes capas. Primera capa (FROM): se define el sistema operativo (Alpine, CentOS, Ubuntu), de aqu\u00ed partir\u00e1 el tama\u00f1o m\u00ednimo de nuestra imagen. Segunda capa (RUN): se ejecutan diferentes comandos, habitualmente para la instalaci\u00f3n de paquetes necesarios para nuestra aplicaci\u00f3n. Tercera capa (CMD): es la parte que mantendr\u00e1 en ejecuci\u00f3n el contenedor. Estas capas se definen en el fichero Dockerfile **y son de s\u00f3lo lectura (RO - Read Only). Aqu\u00ed podemos ver un ejemplo de un **Dockerfile . FROM centos:7 RUN yum -y install httpd CMD [ \"apachectl\" , \"-DFOREGROUND\" ] El par\u00e1metro CMD es el que mantiene \" vivo \" el contenedor, en el ejemplo anterior es necesario utilizar como par\u00e1metro -DFOREGROUND del comando apachectl para que el contenedor se mantenga en ejecuci\u00f3n. Note \u00danicamente podemos encontrar una instrucci\u00f3n CMD en un Dockerfile , en caso de que haya m\u00e1s de una, s\u00f3lo se tendr\u00e1 en cuenta la \u00faltima Podemos definir la instrucci\u00f3n CMD de tres modos diferentes: Execform , es la forma m\u00e1s adecuada. CMD [ \"ejecutable\" , \"par\u00e1metro1\" , \"par\u00e1metro2\" ] #Ruta completa al ejecutable. CMD [ \"/bin/echo\" , \"Hola mundo\" ] #Bash como ejecutable, pasando el par\u00e1metro \"-c\" podemos ejecutar comandos como si estuviesemos en la terminal. CMD [ \"/bin/bash\" , \"-c\" , \"echo Hola mundo\" ] Como par\u00e1metros que acompa\u00f1an a la instrucci\u00f3n ENTRYPOINT . CMD [ \"par\u00e1metro1\" , \"par\u00e1metro2\" ] En formato shell , por debajo ejecuta /bin/sh -c . CMD comando par\u00e1metro1 par\u00e1metro2 La diferencia fundamental entre CMD y ENTRYPOINT se basa en que con el primero de ellos, cuando ejecutamos docker run con un comando espec\u00edfico, este comando sobrescribir\u00e1 el comando definido en el fichero Dockerfile . CMD ser\u00e1 el que utilizaremos habitualmente porque nos permite pasar par\u00e1metros cuando iniciemos el contenedor. ENTRYPOINT en caso de querer tener un contenedor como ejecutable, sin intenci\u00f3n de pasar ning\u00fan par\u00e1metro adicional.","title":"\u00bfQu\u00e9 es una imagen?"},{"location":"Docker/imagenes-docker/#descargando-imagenes","text":"Para la descarga de im\u00e1genes utilizaremos el comando docker pull . Es posible pasar diferentes par\u00e1metros, uno de los m\u00e1s habituales es el tag o etiqueta . Esta etiqueta nos permite elegir entre diferentes versiones del mismo contenedor, una imagen compatible con la arquitectura de nuestro procesador o una versi\u00f3n, de la aplicaci\u00f3n empaquetada en la imagen, particular que necesitemos. Ejemplo: #Descarga la versi\u00f3n 3.6.5 de mongo docker pull mongo:3.6.5-jessie En el ejemplo anterior hemos descargado una versi\u00f3n espec\u00edfica indic\u00e1ndole el tag despu\u00e9s de los dos puntos.","title":"Descargando im\u00e1genes"},{"location":"Docker/imagenes-docker/#que-es-una-etiqueta-tag","text":"Una etiqueta o tag identifica la imagen que vamos a descargarnos. Es una forma sencilla de versionar las im\u00e1genes. Si no establecemos este par\u00e1metro, la etiqueta por defecto que utilizar\u00e1 Docker es latest . Las etiquetas disponibles por cada imagen se encuentran enumeradas en el propio repositorio, adem\u00e1s en la documentaci\u00f3n se encuentran instrucciones que facilitan la elecci\u00f3n del tag de la imagen. A continuaci\u00f3n se encuentran dos enlaces que explican de forma extendida las etiquetas de las im\u00e1genes de Docker y que formas sencillas hay para versionar una imagen. The misunderstood Docker tag: latest Using Semver for Docker Image Tags","title":"\u00bfQu\u00e9 es una etiqueta (tag)?"},{"location":"Docker/imagenes-docker/#desarrollando-imagenes","text":"La forma sencilla para comenzar ha realizar pruebas es crear un directorio de trabajo que utilizaremos para desarrollar las primeras im\u00e1genes. En este directorio es necesario contar con un fichero Dockerfile (lo podemos crear ejecutando touch Dockerfile ), el cual contendr\u00e1 las capas que hemos visto m\u00e1s arriba. Este fichero es el utilizado por el comando docker build para crear las im\u00e1genes. Note Podemos llamar al fichero Dockerfile de cualquier otro modo, pero cuando creemos el contenedor ( docker build ) deberemos indicarle con el par\u00e1metro -f el nombre del fichero.","title":"Desarrollando im\u00e1genes"},{"location":"Docker/imagenes-docker/#dockerfile","text":"\u00bfQu\u00e9 instrucciones nos podemos encontrar dentro de este fichero? COPY : permite copiar un fichero o directorio del host a la imagen. ADD : adem\u00e1s de lo que nos permite realizar la instrucci\u00f3n COPY , esta nos permite pasar una URL para que descargue el contenido en la ruta que indiquemos dentro de la imagen. ENV : se utiliza para a\u00f1adir variables de entorno. La variable se establece sin el signo = , la variable y el valor se define con un espacio entre ambos. Ejemplo: ENV nombre juan WORKDIR : define el directorio de trabajo dentro del contenedor. Si no definimos este par\u00e1metro, por defecto nos encontramos en el directorio ra\u00edz / . EXPOSE : permite exponer puertos. Realmente esta instrucci\u00f3n no realizar ninguna exposici\u00f3n, simplemente informa a la persona que va a utilizar la imagen para crear el contenedor que puertos debe configurar. Estos puertos se expondr\u00e1n utilizando la opci\u00f3n -p del comando docker run . LABEL : hace referencia a una etiqueta, que se utiliza habitualmente para a\u00f1adir metadatos (informaci\u00f3n sobre la imagen como versi\u00f3n, creador, etc.). USER : identifica al usuario que ejecuta las instrucciones definidas en el fichero Dockerfile (las instrucciones que se establezcan a partir de la instrucci\u00f3n user ). Por defecto el usuario que ejecuta las instrucciones es el usuario root . VOLUME : permite que los datos que se encuentran en estos \"vol\u00famenes\" sean persistentes, ya que despu\u00e9s de eliminar el contenedor asociado a este volumen los datos no se perder\u00e1n. CMD : se entiende como la instrucci\u00f3n que mantiene vivo el contenedor. A continuaci\u00f3n veremos un Dockerfile con todas las instrucciones vistas hasta el momento: FROM nginx LABEL version = 1 .0 RUN useradd prueba USER prueba WORKDIR /usr/share/nginx/html COPY web /usr/share/nginx/html ENV variable1 tzinm EXPOSE 90 VOLUME /var/log/nginx CMD nginx -g 'daemon off;' Las instrucciones que definimos dentro de este fichero deben ser lo m\u00e1s estrictas posibles para evitar errores, por ello es importante tener en cuenta lo siguiente: Un servicio por contenedor. Utilizar la capa Labels para a\u00f1adir metadatos. Agrupar los argumentos, evitando crear una capa por cada argumento. Forma correcta RUN \\ python3 -m pip install telegram --upgrade && \\ python3 -m pip install python-telegram-bot --upgrade && \\ chown root:root AddToQbitTorrentFolder.py && \\ chmod 644 AddToQbitTorrentFolder.py Forma incorrecta RUN python3 -m pip install telegram --upgrade RUN python3 -m pip install python-telegram-bot --upgrade RUN chown root:root AddToQbitTorrentFolder.py RUN chmod 644 AddToQbitTorrentFolder.py Evitar la instalaci\u00f3n de paquetes innecesarios, de ese modo crearemos im\u00e1genes m\u00e1s ligeras. Adem\u00e1s del fichero Dockerfile hay otro fichero importante llamado .dockerignore . El funcionamiento de este es similar al fichero .gitignore , es un fichero oculto en el que definimos que contenido del directorio no queremos que sea tenido en cuenta.","title":"Dockerfile"},{"location":"Docker/imagenes-docker/#docker-build","text":"Una vez que tenemos nuestro Dockerfile terminado debemos ejecutar el comando docker build para crear nuestra imagen. docker build -t tzinm/test . En el comando ejecutado se ha denominado a la imagen tzinm/test , al no haber especificado ning\u00fan tag ser\u00e1 el tag latest el que se haya establecido. Otro dato importante es el punto del final, que hace referencia al contexto , es decir el directorio en el cual Docker buscar\u00e1 los ficheros necesarios para crear la imagen.","title":"Docker Build"},{"location":"Docker/imagenes-docker/#multi-stage-builds","text":"Esta nueva funcionalidad que nos ofrece Docker se encuentra disponible a partir de la versi\u00f3n 17.05. Es una utilidad interesante ya que nos permite crear En ocasiones, algunas im\u00e1genes necesitan cierto contenido que es generado mediante la compilaci\u00f3n o ejecuci\u00f3n de una serie de instrucciones que hace que el peso de una imagen crezca y su rendimiento no est\u00e9 lo m\u00e1s optimizado posible. Es aqu\u00ed cuando esta herramienta ( multi-stage builds ) es \u00fatil, ya que nos permite en una primera instancia crear una imagen \"al vuelo\" en la que generaremos esos ficheros mediante las instrucciones que necesitemos. Despu\u00e9s esos ficheros ser\u00e1n enviados (veremos luego en un ejemplo como se realiza esto) a la segunda imagen, exclusivamente esos ficheros, desprendi\u00e9ndonos de la primera imagen y todo lo que ello conlleva. Recordamos que para hacer un uso adecuado de Docker es necesario optimizar al m\u00e1ximo las im\u00e1genes, es la base de las buenas pr\u00e1cticas. A la hora de crear el fichero Dockerfile es muy similar al que utilizamos construyendo una \u00fanica imagen, salvo que en esta ocasi\u00f3n nos encontramos con la construcci\u00f3n de dos im\u00e1genes - por lo tanto dos FROM - y en la segunda imagen a\u00f1adimos una capa - COPY - con el flag --from=primar-imagen que se encargar\u00e1 de pasar el contenido generado en la primera imagen ( primer FROM ). Se puede ver un poco m\u00e1s claro en el siguiente ejemplo. FROM centos as test RUN fallocate -l 10M /tmp/file1 && \\ fallocate -l 40M /tmp/file2 FROM alpine COPY --from = test /tmp/file1 /tmp/test1","title":"Multi-Stage Builds"},{"location":"Docker/imagenes-docker/#dangling-images","text":"Este concepto hace referencia a im\u00e1genes hu\u00e9rfanas, que no son m\u00e1s que aquellas im\u00e1genes que se encuentran sin referenciar . Esto sucede cuando una imagen es construida utilizando el mismo nombre y tag que otra creada anteriormente. La nueva imagen creada ser\u00e1 v\u00e1lida, en cambio las im\u00e1genes anteriores que existiesen no ser\u00e1n v\u00e1lidas y pasar\u00e1n a tener como nombre y tag el valor \\<none> . A pesar de que estas im\u00e1genes no son v\u00e1lidas, seguir\u00e1n estando en nuestro sistema y ocupando espacio, por ello es recomendable eliminarlas. El modo m\u00e1s r\u00e1pido de eliminar todas estas im\u00e1genes es mediante el siguiente comando: docker rmi $( docker images -f \"dangling=true\" -q ) En el comando anterior hemos utilizado el flag -f , que permite el filtrado de las im\u00e1genes siguiendo una serie de patrones .","title":"Dangling images"},{"location":"Docker/informacion-adicional/","text":"Docker Registry # Es un servicio donde se alojan las im\u00e1genes que utilizar\u00e1 Docker. A este servicio se realizan peticiones mediante los comandos docker pull (descargar im\u00e1genes) y docker push (subir im\u00e1genes). El registry que utilizamos habitualmente es el propio de Docker, conocido como Docker Hub , del que nos descargamos las im\u00e1genes desarrolladas por la comunidad. Existe la posibilidad de mantener un registry local, podemos seguir la documentaci\u00f3n oficial para tenerlo en funcionamiento. Los siguientes comandos muestran un ejemplo utilizando un registry local. #Renombramos la imagen para que coincida con el nombre del registry, como lo har\u00edamos en docker hub. docker tag hello-world:lastest localhost:5000/hello-world #Subimos la imagen. docker push localhost:5000/hello-world #Descargar la imagen. docker pull localhost:5000/hellos-world Comandos m\u00e1s utilizados # Comando Descripci\u00f3n docker images lista las im\u00e1genes que se encuentran descargadas docker build construir una imagen a partir de un fichero Dockerfile docker history listar las capas generadas en una imagen concreta docker run crear un contenedor a partir de una imagen docker rm eliminar un contenedor docker rmi eliminar una o m\u00e1s im\u00e1genes docker ps listar los contenedores docker ps -a listar todos los contenedores docker rename cambiar el nombre de un contenedor (renombrar) docker stop detener un contenedor (se puede utilizar el id o el nombre del contenedor) docker start iniciar un contenedor (se puede utilizar el id o el nombre del contenedor) docker restart reiniciar un contenedor (se puede utilizar el id o el nombre del contenedor) docker logs para mostrar los logs de un contenedor. Con el par\u00e1metro \"-f\" se actualizan los logs en tiempo real docker inspect muestra informaci\u00f3n detallada de como ha sido construido un contenedor docker stats pasando el contenedor a este comando nos muestra cuantos recursos consume dicho contenedor docker system df --verbose muestra informaci\u00f3n detallada sobre el tama\u00f1o de todo el contenido de docker docker volume ls lista los vol\u00famenes de Docker. \u00danicamente lista los que se encuentran bajo el directorio root de Docker docker exec permite ejecutar comandos dentro de un contenedor que est\u00e9 activo docker history imagen muestra como ha sido creado una imagen docker cp copiar archivos entre la m\u00e1quina anfitri\u00f3n y el contenedor, y viceversa docker prune elimina todos los contenedores que se encuentran parados. Antes de eliminarlos se muestra un aviso . Comandos adicionales # Docker build #Construir una imagen con un nombre de Dockerfile diferente al utilizado por defecto. Para ello se utiliza el par\u00e1metro \"-f\". docker build -t test -f pruebadockerfile . Docker exec #Entrar en la terminal de un contenedor. docker exec -ti nombre_del_contenedor bash #exec: ejecutar #-t: terminal #-i: interactivo #bash: la terminal seleccionada #Se puede establecer el par\u00e1metro \"-u\" para seleccionar un usuario espec\u00edfico. Docker ps #Eliminar todos los contenedores a trav\u00e9s de sus IDs. docker ps -q | xargs docker rm -f #Eliminar todos los contenedores con estados \"exited\". docker ps -a | grep Exit | cut -d ' ' -f 1 | xargs sudo docker rm Docker cp #Copiar ficheros de mi m\u00e1quina a un contenedor y viceversa. docker cp mimaquina.txt test:/home docker cp test:/home/mimaquina.txt . Docker run #Creaci\u00f3n de un contenedor con el par\u00e1metro --rm para que se autoelimine una vez que haya salido de la sesi\u00f3n del contenedor. docker run --rm -ti -name test ubuntu:latest bash Docker rmi #Eliminar imagenes hu\u00e9rfanas docker rmi $( docker images -f \"dangling=true\" -q ) #Eliminar imagenes por fecha. Since (imagenes creadas posteriormente a la imagen pasada en el filtro), Before (imagenes creadas anteriormente a la imagen pasada en el filtro). docker rmi $( docker images -f since = \"images\" -q ) Docker commit #Crear una imagen a partir de un contenedor docker commit nombre-contenedor imagen-nueva Docker history #Visualizar el CMD del contenedor docker history -h nombre-contenedor","title":"Informaci\u00f3n adicional"},{"location":"Docker/informacion-adicional/#docker-registry","text":"Es un servicio donde se alojan las im\u00e1genes que utilizar\u00e1 Docker. A este servicio se realizan peticiones mediante los comandos docker pull (descargar im\u00e1genes) y docker push (subir im\u00e1genes). El registry que utilizamos habitualmente es el propio de Docker, conocido como Docker Hub , del que nos descargamos las im\u00e1genes desarrolladas por la comunidad. Existe la posibilidad de mantener un registry local, podemos seguir la documentaci\u00f3n oficial para tenerlo en funcionamiento. Los siguientes comandos muestran un ejemplo utilizando un registry local. #Renombramos la imagen para que coincida con el nombre del registry, como lo har\u00edamos en docker hub. docker tag hello-world:lastest localhost:5000/hello-world #Subimos la imagen. docker push localhost:5000/hello-world #Descargar la imagen. docker pull localhost:5000/hellos-world","title":"Docker Registry"},{"location":"Docker/informacion-adicional/#comandos-mas-utilizados","text":"Comando Descripci\u00f3n docker images lista las im\u00e1genes que se encuentran descargadas docker build construir una imagen a partir de un fichero Dockerfile docker history listar las capas generadas en una imagen concreta docker run crear un contenedor a partir de una imagen docker rm eliminar un contenedor docker rmi eliminar una o m\u00e1s im\u00e1genes docker ps listar los contenedores docker ps -a listar todos los contenedores docker rename cambiar el nombre de un contenedor (renombrar) docker stop detener un contenedor (se puede utilizar el id o el nombre del contenedor) docker start iniciar un contenedor (se puede utilizar el id o el nombre del contenedor) docker restart reiniciar un contenedor (se puede utilizar el id o el nombre del contenedor) docker logs para mostrar los logs de un contenedor. Con el par\u00e1metro \"-f\" se actualizan los logs en tiempo real docker inspect muestra informaci\u00f3n detallada de como ha sido construido un contenedor docker stats pasando el contenedor a este comando nos muestra cuantos recursos consume dicho contenedor docker system df --verbose muestra informaci\u00f3n detallada sobre el tama\u00f1o de todo el contenido de docker docker volume ls lista los vol\u00famenes de Docker. \u00danicamente lista los que se encuentran bajo el directorio root de Docker docker exec permite ejecutar comandos dentro de un contenedor que est\u00e9 activo docker history imagen muestra como ha sido creado una imagen docker cp copiar archivos entre la m\u00e1quina anfitri\u00f3n y el contenedor, y viceversa docker prune elimina todos los contenedores que se encuentran parados. Antes de eliminarlos se muestra un aviso .","title":"Comandos m\u00e1s utilizados"},{"location":"Docker/informacion-adicional/#comandos-adicionales","text":"Docker build #Construir una imagen con un nombre de Dockerfile diferente al utilizado por defecto. Para ello se utiliza el par\u00e1metro \"-f\". docker build -t test -f pruebadockerfile . Docker exec #Entrar en la terminal de un contenedor. docker exec -ti nombre_del_contenedor bash #exec: ejecutar #-t: terminal #-i: interactivo #bash: la terminal seleccionada #Se puede establecer el par\u00e1metro \"-u\" para seleccionar un usuario espec\u00edfico. Docker ps #Eliminar todos los contenedores a trav\u00e9s de sus IDs. docker ps -q | xargs docker rm -f #Eliminar todos los contenedores con estados \"exited\". docker ps -a | grep Exit | cut -d ' ' -f 1 | xargs sudo docker rm Docker cp #Copiar ficheros de mi m\u00e1quina a un contenedor y viceversa. docker cp mimaquina.txt test:/home docker cp test:/home/mimaquina.txt . Docker run #Creaci\u00f3n de un contenedor con el par\u00e1metro --rm para que se autoelimine una vez que haya salido de la sesi\u00f3n del contenedor. docker run --rm -ti -name test ubuntu:latest bash Docker rmi #Eliminar imagenes hu\u00e9rfanas docker rmi $( docker images -f \"dangling=true\" -q ) #Eliminar imagenes por fecha. Since (imagenes creadas posteriormente a la imagen pasada en el filtro), Before (imagenes creadas anteriormente a la imagen pasada en el filtro). docker rmi $( docker images -f since = \"images\" -q ) Docker commit #Crear una imagen a partir de un contenedor docker commit nombre-contenedor imagen-nueva Docker history #Visualizar el CMD del contenedor docker history -h nombre-contenedor","title":"Comandos adicionales"},{"location":"Docker/introduccion-docker/","text":"\u00bfQu\u00e9 es Docker? # Es una herramienta que permite desplegar aplicaciones en contenedores de forma r\u00e1pida y portable. Los t\u00e9rminos que m\u00e1s escucharemos cuando hablamos de Docker ser\u00e1n \" contenedores \" e \" im\u00e1genes \". Docker se encuentra disponible para las principales plataformas, como Windows, Linux o MacOS. La m\u00e1quina que aloja el servicio \" Docker \" se denomina Docker Host . Dentro de Docker podemos destacar tres conceptos. Docker Daemon: representa el servidor de Docker. Rest API: utilizado para la comunicaci\u00f3n bidireccional entre cliente y servidor. Docker CLI (Command Line Interface): representa el cliente de Docker. Info A pesar de que se haya mencionado la l\u00ednea de comandos como cliente Docker, tambi\u00e9n existe entorno gr\u00e1fico para interactuar con el servidor Docker.","title":"Introducci\u00f3n a Docker"},{"location":"Docker/introduccion-docker/#que-es-docker","text":"Es una herramienta que permite desplegar aplicaciones en contenedores de forma r\u00e1pida y portable. Los t\u00e9rminos que m\u00e1s escucharemos cuando hablamos de Docker ser\u00e1n \" contenedores \" e \" im\u00e1genes \". Docker se encuentra disponible para las principales plataformas, como Windows, Linux o MacOS. La m\u00e1quina que aloja el servicio \" Docker \" se denomina Docker Host . Dentro de Docker podemos destacar tres conceptos. Docker Daemon: representa el servidor de Docker. Rest API: utilizado para la comunicaci\u00f3n bidireccional entre cliente y servidor. Docker CLI (Command Line Interface): representa el cliente de Docker. Info A pesar de que se haya mencionado la l\u00ednea de comandos como cliente Docker, tambi\u00e9n existe entorno gr\u00e1fico para interactuar con el servidor Docker.","title":"\u00bfQu\u00e9 es Docker?"},{"location":"Docker/redes-docker/","text":"Cuando levantamos por primera vez el servicio Docker se crea una interfaz virtual llamada docker0 a la cual se le asigna una direcci\u00f3n ip en una subred diferente a la de nuestra red local. Cuando creamos un contenedor nuevo sin pasarle el par\u00e1metro referente a la red , este le asigna una direcci\u00f3n ip correspondiente al rango que nos proporciona la interfaz virtual docker0 . Algunos de los comandos referentes a la red de Docker: Ver la redes disponibles docker network ls Obtener informaci\u00f3n sobre una red docker network inspect nombre_de_red Note Los contenedores que se encuentran en la misma red pueden hacerse ping entre ellos. Creaci\u00f3n de redes # Cuando creamos una red nueva, esta utilizar\u00e1 los drivers bridge (esto se puede cambiar pasando el par\u00e1metro --driver string cuando creamos la nueva red). El comando para la creaci\u00f3n de nuevas redes es el siguiente: docker network create nombre_de_red Docker nos permite especificar ciertas configuraciones a la hora de crear la red como puede ser la direcci\u00f3n de red o la puerta de enlace. Para ver que opciones tenemos podemos ejecutar docker network create --help . docker network create --driver bridge --subnet 172 .16.16.0/24 --gateway 172 .16.16.254 red-prueba Tambi\u00e9n existe la posibilidad de establecer una direcci\u00f3n ip espec\u00edfica a un contenedor, para ello se utiliza el flag --ip . docker run --network nombre_red --ip 192 .168.50.2 -dti --name nombre_contenedor ubuntu Conectando un contenedor a una red diferente # Sabemos que Docker asigna como red por defecto bridge , por lo que si queremos elegir otra red deberemos hacerlo manualmente. La instrucci\u00f3n necesaria para elegir una red diferente a la red por defecto es la siguiente: docker run --network nombre_de_red -dti --name prueba-red ubuntu Note Podemos ejecutar docker inspecto prueba-red para ver las propiedades del contenedor, en las que aparecer\u00e1 la secci\u00f3n NetworkSetting y se podr\u00e1 ver la red asignada a este contenedor. Conectar contenedores a la misma red # En la red por defecto de Docker ( red bridge ) no podemos reconocer a los contenedores por su hostname . En cambio, cuando creamos una red (aunque utilice el driver bridge) es posible la comunicaci\u00f3n entre contenedores a trav\u00e9s de su hostname, esto se debe a que son redes definidas como \" user define network \". Para realizar una prueba de comunicaci\u00f3n entre dos contenedores podemos utilizar el comando ping . Podemos hacer la prueba mediante la direcci\u00f3n ip o mediante el nombre del contenedor. #Direcci\u00f3n ip docker exec nombre_contenedor bash -c \"ping -c 3 ip_contenedor2\" #Hostname docker exec nombre_contenedor bash -c \"ping -c 3 nombre_contenedor2\" Contenedores en m\u00e1s de una red # Los contenedores ya existentes pueden tener configurado m\u00e1s de una red diferente. docker network connect nombre_red nombre_contenedor El comando docker inspect nos permite inspeccionar un contenedor, lo cual permite verificar las diferentes redes configuradas en dicho contenedor, de ese modo podr\u00edamos verificar si se ha a\u00f1adido la nueva red. Al igual que se puede configurar varias redes en un contenedor, tambi\u00e9n podemos eliminar varias redes de los contenedores. docker network disconnect nombre_red nombre_contenedor Eliminar redes # Las redes creadas por un usuario se pueden eliminar, para ello es necesario que ning\u00fan contenedor se encuentre asociado a dicha red. docker network rm nombre_red Tipos de drivers de red # Bridge # En Docker es el driver de red por defecto, sino se espec\u00edfica uno diferente es el driver utilizado por defecto a la hora de crear nuevas redes. Host # Este tipo de driver de red elimina el aislamiento entre el contenedor y la m\u00e1quina anfitriona, por lo tanto utiliza la red que utiliza la m\u00e1quina anfitriona. Es decir, estos contenedores podr\u00e1n recibir una direcci\u00f3n ip de forma din\u00e1mica por parte del servidor DHCP que tengamos configurado en nuestra red local. Overlay # Permite la comunicaci\u00f3n entre diferentes servidores Docker (docker daemons), esto permite que diferentes servicios puedan comunicarse entre si. Macvlan # Permite asignar una direcci\u00f3n MAC a un contenedor, lo cual simula disponer de una tarjeta de red en dicho contenedor. None # Este tipo de driver permite deshabilitar la red en los contenedores.","title":"Redes"},{"location":"Docker/redes-docker/#creacion-de-redes","text":"Cuando creamos una red nueva, esta utilizar\u00e1 los drivers bridge (esto se puede cambiar pasando el par\u00e1metro --driver string cuando creamos la nueva red). El comando para la creaci\u00f3n de nuevas redes es el siguiente: docker network create nombre_de_red Docker nos permite especificar ciertas configuraciones a la hora de crear la red como puede ser la direcci\u00f3n de red o la puerta de enlace. Para ver que opciones tenemos podemos ejecutar docker network create --help . docker network create --driver bridge --subnet 172 .16.16.0/24 --gateway 172 .16.16.254 red-prueba Tambi\u00e9n existe la posibilidad de establecer una direcci\u00f3n ip espec\u00edfica a un contenedor, para ello se utiliza el flag --ip . docker run --network nombre_red --ip 192 .168.50.2 -dti --name nombre_contenedor ubuntu","title":"Creaci\u00f3n de redes"},{"location":"Docker/redes-docker/#conectando-un-contenedor-a-una-red-diferente","text":"Sabemos que Docker asigna como red por defecto bridge , por lo que si queremos elegir otra red deberemos hacerlo manualmente. La instrucci\u00f3n necesaria para elegir una red diferente a la red por defecto es la siguiente: docker run --network nombre_de_red -dti --name prueba-red ubuntu Note Podemos ejecutar docker inspecto prueba-red para ver las propiedades del contenedor, en las que aparecer\u00e1 la secci\u00f3n NetworkSetting y se podr\u00e1 ver la red asignada a este contenedor.","title":"Conectando un contenedor a una red diferente"},{"location":"Docker/redes-docker/#conectar-contenedores-a-la-misma-red","text":"En la red por defecto de Docker ( red bridge ) no podemos reconocer a los contenedores por su hostname . En cambio, cuando creamos una red (aunque utilice el driver bridge) es posible la comunicaci\u00f3n entre contenedores a trav\u00e9s de su hostname, esto se debe a que son redes definidas como \" user define network \". Para realizar una prueba de comunicaci\u00f3n entre dos contenedores podemos utilizar el comando ping . Podemos hacer la prueba mediante la direcci\u00f3n ip o mediante el nombre del contenedor. #Direcci\u00f3n ip docker exec nombre_contenedor bash -c \"ping -c 3 ip_contenedor2\" #Hostname docker exec nombre_contenedor bash -c \"ping -c 3 nombre_contenedor2\"","title":"Conectar contenedores a la misma red"},{"location":"Docker/redes-docker/#contenedores-en-mas-de-una-red","text":"Los contenedores ya existentes pueden tener configurado m\u00e1s de una red diferente. docker network connect nombre_red nombre_contenedor El comando docker inspect nos permite inspeccionar un contenedor, lo cual permite verificar las diferentes redes configuradas en dicho contenedor, de ese modo podr\u00edamos verificar si se ha a\u00f1adido la nueva red. Al igual que se puede configurar varias redes en un contenedor, tambi\u00e9n podemos eliminar varias redes de los contenedores. docker network disconnect nombre_red nombre_contenedor","title":"Contenedores en m\u00e1s de una red"},{"location":"Docker/redes-docker/#eliminar-redes","text":"Las redes creadas por un usuario se pueden eliminar, para ello es necesario que ning\u00fan contenedor se encuentre asociado a dicha red. docker network rm nombre_red","title":"Eliminar redes"},{"location":"Docker/redes-docker/#tipos-de-drivers-de-red","text":"","title":"Tipos de drivers de red"},{"location":"Docker/redes-docker/#bridge","text":"En Docker es el driver de red por defecto, sino se espec\u00edfica uno diferente es el driver utilizado por defecto a la hora de crear nuevas redes.","title":"Bridge"},{"location":"Docker/redes-docker/#host","text":"Este tipo de driver de red elimina el aislamiento entre el contenedor y la m\u00e1quina anfitriona, por lo tanto utiliza la red que utiliza la m\u00e1quina anfitriona. Es decir, estos contenedores podr\u00e1n recibir una direcci\u00f3n ip de forma din\u00e1mica por parte del servidor DHCP que tengamos configurado en nuestra red local.","title":"Host"},{"location":"Docker/redes-docker/#overlay","text":"Permite la comunicaci\u00f3n entre diferentes servidores Docker (docker daemons), esto permite que diferentes servicios puedan comunicarse entre si.","title":"Overlay"},{"location":"Docker/redes-docker/#macvlan","text":"Permite asignar una direcci\u00f3n MAC a un contenedor, lo cual simula disponer de una tarjeta de red en dicho contenedor.","title":"Macvlan"},{"location":"Docker/redes-docker/#none","text":"Este tipo de driver permite deshabilitar la red en los contenedores.","title":"None"},{"location":"Docker/referencias/","text":"Docker bases # Docker, de principiante a experto Docker for beginners Cap\u00edtulos Docker atareao.es Docker Tips Docker desde las bases: Comprendiendo imagenes Docker espa\u00f1ol GitHub Docker en profundidad # Lesser Known Docker Tips for Andvanced Users Docker Tips: about /var/run/docker.sock Docker CMD vs ENTRYPOINT Dockerfile: ENTRYPOINT vs CMD Understanding how uid and gid work in Docker containers Buenas pr\u00e1cticas construyendo im\u00e1genes Docker Eliminar vol\u00famenes hu\u00e9rfanos Dopcker Hub Automated Build Tagging Using Semver for Docker Image Tags Comando para saber los dockers corriendo y sus puertos Docker security best practices Herramientas # Play with Docker Lazy Docker Tool for Exploring Docker Image Buildx","title":"Referencias"},{"location":"Docker/referencias/#docker-bases","text":"Docker, de principiante a experto Docker for beginners Cap\u00edtulos Docker atareao.es Docker Tips Docker desde las bases: Comprendiendo imagenes Docker espa\u00f1ol GitHub","title":"Docker bases"},{"location":"Docker/referencias/#docker-en-profundidad","text":"Lesser Known Docker Tips for Andvanced Users Docker Tips: about /var/run/docker.sock Docker CMD vs ENTRYPOINT Dockerfile: ENTRYPOINT vs CMD Understanding how uid and gid work in Docker containers Buenas pr\u00e1cticas construyendo im\u00e1genes Docker Eliminar vol\u00famenes hu\u00e9rfanos Dopcker Hub Automated Build Tagging Using Semver for Docker Image Tags Comando para saber los dockers corriendo y sus puertos Docker security best practices","title":"Docker en profundidad"},{"location":"Docker/referencias/#herramientas","text":"Play with Docker Lazy Docker Tool for Exploring Docker Image Buildx","title":"Herramientas"},{"location":"Docker/seguridad-docker/","text":"Este apartado lo he denominado \"seguridad\" porque creo que es donde mejor encajala gesti\u00f3n de los usuarios en Docker. Para profundizar en el tema de seguridad es conveniente revisar la documentaci\u00f3n oficial . Simplificando mucho, sabemos que los contenedores de Docker son procesos para el sistema anfitri\u00f3n, por lo tanto el kernel del sistema es compartido entre todos los contenedores y el propio sistema. Es importante tener en cuenta esto ya que el kernel de Linux es el encargado de gestionar el uid y el gid de los diferentes usuarios, por lo tanto, estos ser\u00e1n compartidos con los contenedores de Docker. Cuando ejecutamos un contenedor, si no se especifica un usuario en la creaci\u00f3n del propio contenedor o en la imagen base del mismo, el uid y gid por defecto ser\u00e1 0 . Este id corresponde al usuario root , el usuario administrador de nuestro sistema. Una buena pr\u00e1ctica para controlar este comportamiento es contar con un usuario espec\u00edfico para Docker, al que se le otorgar\u00e1n los permisos exclusivamente necesarios para que el contenedor que hayamos creado pueda \u00fanicamente realizar la tarea para la que se ha creado. Despu\u00e9s de que hayamos creado el usuario que utilizaremos en los contenedores Docker, podemos obtener los ids que necestiamos (uid y gid) ejecutando el siguiente comando: id usuario-docker Para indicar al contenedor que usuario ser\u00e1 el que ejecute el CMD , se lo indicaremos con el flag -u . docker run -u = \"uid:gid\" Para verlo de una forma m\u00e1s clara, lo trataremos con un ejemplo . Imaginemos que queremos montar una biblioteca multimedia al estilo \"Netflix\" a partir de las pel\u00edculas y series digitales que tenemos en nuestros equipos. Hay diversas herramientas que nos facilitan esto, como por ejemplo Plex , que es una de las m\u00e1s conocidas. Esta biblioteca podemos ponerla en marcha a trav\u00e9s de un contenedor Docker, pero para que funcione correctamente este contenedor necesita acceso a las carpetas donde se encuentra todo nuestro contenido multimedia. Bien, si el usuario del contenedor no es el adecuado el contenedor no ser\u00e1 capaz de leer los directorios donde se encuentra todo el contenido multimedia, y por lo tanto no podr\u00e1 realizar su trabajo y no tendremos nuestra ansiada biblioteca multimedia. Siguiendo con la premisa de un usuario exclusivo para Docker, este usuario deber\u00eda tener acceso a los directorios donde se encuentra todo el contenido multimedia y a su vez, ser el usuario que hemos pasado por par\u00e1metros al contenedor de Plex.","title":"Seguridad"},{"location":"Docker/volumenes-docker/","text":"Como ya sabemos, si eliminamos un contenedor todos sus datos se eliminar\u00e1n con \u00e9l. Para evitar esto tenemos los vol\u00famenes que nos permiten hacer persistentes algunos datos de nuestros contenedores. Estos datos se almacenan en un directorio de la m\u00e1quina anfitriona. Docker cuenta con tres tipos de vol\u00famenes. Vol\u00famenes Host # En este tipo de vol\u00famenes definimos el directorio donde queremos que se almacene la informaci\u00f3n que debe ser persistente. Es el tipo de vol\u00famenes que m\u00e1s utilizaremos: docker run -v /midirectorio:/directorio-docker Vol\u00famenes Anonymous # Seguimos haciendo persistentes los datos, pero en este caso no definimos donde queremos que se almacene la informaci\u00f3n, sino que Docker genera un directorio aleatorio. docker run -v /directorio-docker Estos directorios se encuentran en una ruta espec\u00edfica bajo el directorio \" ra\u00edz \" del servicio Docker. Para conocer dicho directorio es necesario ejecutar la siguiente instrucci\u00f3n: docker info | grep -i root Entre los diferentes directorio bajo el directorio ra\u00edz de Docker, tenemos un directorio denominado vol\u00famenes, que es el directorio donde se almacenaran estos directorios llamados anonymous . Los directorios anonymous tambi\u00e9n aparecen cuando en un fichero Dockerfile definimos la capa VOLUME pero a la hora de ejecutar el contenedor no definimos ning\u00fan volumen. Esta forma de crear vol\u00famenes no es aconsejable por varios motivos. El nombre que otorga al directorio es aleatorio (habitualmente conformado por n\u00fameros), por lo tanto no ser\u00e1 sencillo saber que volumen se encuentra asociado a cada contenedor. A la hora de eliminar el contenedor si pasamos la opci\u00f3n -v eliminaremos tambi\u00e9n el volumen asociado a este contenedor. Vol\u00famenes Nombrados # Es una mezcla de los dos anteriores. El volumen se almacena en el mismo lugar que los vol\u00famenes anonymous, pero en este caso somos nosotros quienes elegimos un nombre para estos vol\u00famenes en vez de ser un nombre aleatorio. Los siguientes comandos se utilizan para la gesti\u00f3n de vol\u00famenes: Creando un volumen docker volume create nombre_del_volumen Listar los vol\u00famenes docker volume ls Eliminar un volumen docker volume rm nombre_del_volumen Utilizar un volumen nombrado docker run -v nombre_del_volumen:/dockercontainer A diferencia de los vol\u00famenes host, donde debemos indicar la ruta completa del directorio, solo es necesario indicar el nombre del volumen que hayamos creado. Dangling Volumes # Este concepto que hemos visto con los contenedores tambi\u00e9n existe con los vol\u00famenes. Estos aparecen cuando hemos eliminado un contenedor y el volumen asociado a este (volumen anonymous) no se ha eliminado. Para eliminar estos vol\u00famenes podemos hacerlo con la siguiente l\u00ednea de terminal: docker volume ls -f \"dangling=true\" -q | xargs docker volume rm -f / --filtering : flag utilizado para filtrar los vol\u00famenes. dangling : es un filtro booleano que \u00fanicamente permite true o false . **-q **(quiet): imprime el ID que identifica a cada volumen. Con xargs pasamos el resultado a un segundo comando, de ese modo conseguimos eliminar con una \u00fanica l\u00ednea todos los vol\u00famenes. Note Los vol\u00famenes se pueden compartir entre varios contenedores, simplemente es indicar el volumen en el par\u00e1metro correspondiente cuando creemos los contenedores. Puede ser \u00fatil cuando necesitamos que dos contenedores accedan a la informaci\u00f3n que se encuentra en un directorio de nuestra m\u00e1quina.","title":"Vol\u00famenes"},{"location":"Docker/volumenes-docker/#volumenes-host","text":"En este tipo de vol\u00famenes definimos el directorio donde queremos que se almacene la informaci\u00f3n que debe ser persistente. Es el tipo de vol\u00famenes que m\u00e1s utilizaremos: docker run -v /midirectorio:/directorio-docker","title":"Vol\u00famenes Host"},{"location":"Docker/volumenes-docker/#volumenes-anonymous","text":"Seguimos haciendo persistentes los datos, pero en este caso no definimos donde queremos que se almacene la informaci\u00f3n, sino que Docker genera un directorio aleatorio. docker run -v /directorio-docker Estos directorios se encuentran en una ruta espec\u00edfica bajo el directorio \" ra\u00edz \" del servicio Docker. Para conocer dicho directorio es necesario ejecutar la siguiente instrucci\u00f3n: docker info | grep -i root Entre los diferentes directorio bajo el directorio ra\u00edz de Docker, tenemos un directorio denominado vol\u00famenes, que es el directorio donde se almacenaran estos directorios llamados anonymous . Los directorios anonymous tambi\u00e9n aparecen cuando en un fichero Dockerfile definimos la capa VOLUME pero a la hora de ejecutar el contenedor no definimos ning\u00fan volumen. Esta forma de crear vol\u00famenes no es aconsejable por varios motivos. El nombre que otorga al directorio es aleatorio (habitualmente conformado por n\u00fameros), por lo tanto no ser\u00e1 sencillo saber que volumen se encuentra asociado a cada contenedor. A la hora de eliminar el contenedor si pasamos la opci\u00f3n -v eliminaremos tambi\u00e9n el volumen asociado a este contenedor.","title":"Vol\u00famenes Anonymous"},{"location":"Docker/volumenes-docker/#volumenes-nombrados","text":"Es una mezcla de los dos anteriores. El volumen se almacena en el mismo lugar que los vol\u00famenes anonymous, pero en este caso somos nosotros quienes elegimos un nombre para estos vol\u00famenes en vez de ser un nombre aleatorio. Los siguientes comandos se utilizan para la gesti\u00f3n de vol\u00famenes: Creando un volumen docker volume create nombre_del_volumen Listar los vol\u00famenes docker volume ls Eliminar un volumen docker volume rm nombre_del_volumen Utilizar un volumen nombrado docker run -v nombre_del_volumen:/dockercontainer A diferencia de los vol\u00famenes host, donde debemos indicar la ruta completa del directorio, solo es necesario indicar el nombre del volumen que hayamos creado.","title":"Vol\u00famenes Nombrados"},{"location":"Docker/volumenes-docker/#dangling-volumes","text":"Este concepto que hemos visto con los contenedores tambi\u00e9n existe con los vol\u00famenes. Estos aparecen cuando hemos eliminado un contenedor y el volumen asociado a este (volumen anonymous) no se ha eliminado. Para eliminar estos vol\u00famenes podemos hacerlo con la siguiente l\u00ednea de terminal: docker volume ls -f \"dangling=true\" -q | xargs docker volume rm -f / --filtering : flag utilizado para filtrar los vol\u00famenes. dangling : es un filtro booleano que \u00fanicamente permite true o false . **-q **(quiet): imprime el ID que identifica a cada volumen. Con xargs pasamos el resultado a un segundo comando, de ese modo conseguimos eliminar con una \u00fanica l\u00ednea todos los vol\u00famenes. Note Los vol\u00famenes se pueden compartir entre varios contenedores, simplemente es indicar el volumen en el par\u00e1metro correspondiente cuando creemos los contenedores. Puede ser \u00fatil cuando necesitamos que dos contenedores accedan a la informaci\u00f3n que se encuentra en un directorio de nuestra m\u00e1quina.","title":"Dangling Volumes"},{"location":"Git/bare-repositories/","text":"Los repositorios bare son repositorios remotos propios, es decir, prescindimos de servicios de hosting de git como GtiHub por un repositorio remoto de nuestra propiedad. Dos caracter\u00edsticas importantes que debemos destacar. No cuentan con Working Directory . Se trabaja a trav\u00e9s de push y pull . Es frecuente su uso cuando deseamos trabajar de forma centralizada y por diversas razones no podemos/queremos utilizar servicios de hosting de git. Dispondremos de un servidor en el que tendremos un directorio que contendr\u00e1 todo nuestro proyecto (semejante al Working Directory). Una vez que tenemos el servidor con el directorio respondiente, dentro del directorio debemos ejecutar un comando para iniciar git. git init --bare nombre-repositorio.git Note Es necesario que el nombre del repositorio termine el .git . El pr\u00f3ximo paso es clonar en local el repositorio que acabamos de crear en el servidor. Esto nos permitir\u00e1 interactuar con el bare repositorie a trav\u00e9s de los comandos git push y git pull . git clone /ruta/nombre-repositorio.git /ruta//working-directory-local","title":"Bare Repositories"},{"location":"Git/comandos-git/","text":"Git alias # Git nos permite trabajar con alias. Tienen un funcionamiento similar a los alias de Linux, es \u00faltil crear estos alias para evitar introducir largos comandos. git conifg --global alias.nombre-del-alias \"comando-git\" Git stash # Este comando nos permite hacer un guardado de cambios que hayamos hecho en nuestro Working Directory pero sobre los que no queremos hacer por el momento ning\u00fan commit. git stash Una vez que ejecutamos este comando, los cambios que hemos hecho desde que iniciamos el commit hasta la ejecuci\u00f3n del comando desaparecer\u00e1n del commit actual, pero ser\u00e1n almacenados para recuperarlos posteriormente cuando lo necesitemos. Continuamos con nuestro proyecto, incluso realizando nuevos commit, y llega el momento que decidimos recuperar algunos de los cambios sobre los que no hemos hecho commit pero s\u00ed tenemos almacenados (WIP = Working In Progress). Listamos todos los cambios que hemos ido guardando. git stash list Una vez que los tenemos listados procedemos recuperarlos con el siguiente comando: #Recuperamos todos los cambios almacenados git stash apply #Recuperamos un cambios espec\u00edfico git stash apply stash { 1 } Guardado r\u00e1pido y limpieza Git Reset # Hay ocasiones, y no son pocas, en las que queremos volver atr\u00e1s en el tiempo (siempre refiri\u00e9ndonos a los commit) y para ello tenemos el comando git reset . Dependiendo de qu\u00e9 contenido queremos recuperar, este comando tiene diferentes opciones que son importante conocer. Antes de conocer los tres argumentos que podemos utilizar es necesario conocer alguna peculiaridad de este comando. Cuando invocamos git reset sin argumentos, de forma impl\u00edcita se est\u00e1 ejecutando git reset --mixed HEAD . Si no especificamos commit id , el comando se invocar\u00e1 con HEAD como commit objetivo. Note HEAD es sin\u00f3nimo de \"\u00faltimo commit\". Par\u00e1metro hard # De las tres opciones que tenemos esta es la m\u00e1s \"bestia\" (tambi\u00e9n peligrosa) ya que restablece el staging area y el working directory . Esto significa que todo el trabajo que se encontrase en estos dos \"\u00e1rboles\" se perder\u00e1. git reset --hard commit_id Par\u00e1metro mixed # El argumento mixed no realiza modificaciones sobre el working directory como si hace el argumento hard. Es decir, movemos el \"puntero\" HEAD al commit que hayamos especificado y restablecemos el staging area . Ejecutar git reset junto al argumento mixed es muy \u00fatil cuando queremos resumir varios commit en uno. Esto se debe a que trasladamos todos los cambios al working directory y despu\u00e9s podemos ejecutar git add y git commit -m para crear el nuevo commit. git reset --mixed commit_id Par\u00e1metro soft # Solo realiza cambios de \"puntero\", mantiene el working directory y el staging area sin alterar. git reset --soft commit_id \u200b !!!note Si necesitamos movernos entre diferentes commit sin restablecer ninguno de los tres \u00e1rboles de git, podemos ejecutar git checkout (estudiaremos este comando m\u00e1s adelante) el cual funciona del mismo modo que al ejecutarlo para movernos entre diferentes ramas de un proyecto. Git diff # Este comando nos permite comparar cambios a nivel de commit, ramas, archivos, etc. git diff commmit_id Para conocer m\u00e1s a fondo este comando podemos revisar este enlace que nos llevar\u00e1 a los tutoriales de Atlassian Git commit --amend # El par\u00e1metro amend nos permite modificar el commit m\u00e1s reciente, es decir el \u00faltimo commit de nuestro proyecto. \u00bfQu\u00e9 podemos conseguir? Combinar un nuevo commit que vayamos a hacer junto con el \u00faltimo commit en el \"historial\", con lo que se crear\u00e1 un nuevo commit con la \"mezcla\" de ambos. El comando deber\u00eda ejecutarse del siguiente modo: #Modificando el mensaje git commit -m \"Descripci\u00f3n\" --amend #Sin modificar el mensaje git commit --amend --no-edit Editar el mensaje del \u00faltimo commit. Cuando ejecutemos el comando se nos abrir\u00e1 un editor para realizar dicha modificaci\u00f3n. La ejecuci\u00f3n en este caso es m\u00e1s simple. git commit --amend Note Si ejecutamos el \u00faltimo comando git commit --amend -m \"Descripci\u00f3n actualizada\" se actualizar\u00e1 el mensaje sin necesidad de abrir el editor para realziar cambios.","title":"Comandos gen\u00e9ricos"},{"location":"Git/comandos-git/#git-alias","text":"Git nos permite trabajar con alias. Tienen un funcionamiento similar a los alias de Linux, es \u00faltil crear estos alias para evitar introducir largos comandos. git conifg --global alias.nombre-del-alias \"comando-git\"","title":"Git alias"},{"location":"Git/comandos-git/#git-stash","text":"Este comando nos permite hacer un guardado de cambios que hayamos hecho en nuestro Working Directory pero sobre los que no queremos hacer por el momento ning\u00fan commit. git stash Una vez que ejecutamos este comando, los cambios que hemos hecho desde que iniciamos el commit hasta la ejecuci\u00f3n del comando desaparecer\u00e1n del commit actual, pero ser\u00e1n almacenados para recuperarlos posteriormente cuando lo necesitemos. Continuamos con nuestro proyecto, incluso realizando nuevos commit, y llega el momento que decidimos recuperar algunos de los cambios sobre los que no hemos hecho commit pero s\u00ed tenemos almacenados (WIP = Working In Progress). Listamos todos los cambios que hemos ido guardando. git stash list Una vez que los tenemos listados procedemos recuperarlos con el siguiente comando: #Recuperamos todos los cambios almacenados git stash apply #Recuperamos un cambios espec\u00edfico git stash apply stash { 1 } Guardado r\u00e1pido y limpieza","title":"Git stash"},{"location":"Git/comandos-git/#git-reset","text":"Hay ocasiones, y no son pocas, en las que queremos volver atr\u00e1s en el tiempo (siempre refiri\u00e9ndonos a los commit) y para ello tenemos el comando git reset . Dependiendo de qu\u00e9 contenido queremos recuperar, este comando tiene diferentes opciones que son importante conocer. Antes de conocer los tres argumentos que podemos utilizar es necesario conocer alguna peculiaridad de este comando. Cuando invocamos git reset sin argumentos, de forma impl\u00edcita se est\u00e1 ejecutando git reset --mixed HEAD . Si no especificamos commit id , el comando se invocar\u00e1 con HEAD como commit objetivo. Note HEAD es sin\u00f3nimo de \"\u00faltimo commit\".","title":"Git Reset"},{"location":"Git/comandos-git/#parametro-hard","text":"De las tres opciones que tenemos esta es la m\u00e1s \"bestia\" (tambi\u00e9n peligrosa) ya que restablece el staging area y el working directory . Esto significa que todo el trabajo que se encontrase en estos dos \"\u00e1rboles\" se perder\u00e1. git reset --hard commit_id","title":"Par\u00e1metro hard"},{"location":"Git/comandos-git/#parametro-mixed","text":"El argumento mixed no realiza modificaciones sobre el working directory como si hace el argumento hard. Es decir, movemos el \"puntero\" HEAD al commit que hayamos especificado y restablecemos el staging area . Ejecutar git reset junto al argumento mixed es muy \u00fatil cuando queremos resumir varios commit en uno. Esto se debe a que trasladamos todos los cambios al working directory y despu\u00e9s podemos ejecutar git add y git commit -m para crear el nuevo commit. git reset --mixed commit_id","title":"Par\u00e1metro mixed"},{"location":"Git/comandos-git/#parametro-soft","text":"Solo realiza cambios de \"puntero\", mantiene el working directory y el staging area sin alterar. git reset --soft commit_id \u200b !!!note Si necesitamos movernos entre diferentes commit sin restablecer ninguno de los tres \u00e1rboles de git, podemos ejecutar git checkout (estudiaremos este comando m\u00e1s adelante) el cual funciona del mismo modo que al ejecutarlo para movernos entre diferentes ramas de un proyecto.","title":"Par\u00e1metro soft"},{"location":"Git/comandos-git/#git-diff","text":"Este comando nos permite comparar cambios a nivel de commit, ramas, archivos, etc. git diff commmit_id Para conocer m\u00e1s a fondo este comando podemos revisar este enlace que nos llevar\u00e1 a los tutoriales de Atlassian","title":"Git diff"},{"location":"Git/comandos-git/#git-commit-amend","text":"El par\u00e1metro amend nos permite modificar el commit m\u00e1s reciente, es decir el \u00faltimo commit de nuestro proyecto. \u00bfQu\u00e9 podemos conseguir? Combinar un nuevo commit que vayamos a hacer junto con el \u00faltimo commit en el \"historial\", con lo que se crear\u00e1 un nuevo commit con la \"mezcla\" de ambos. El comando deber\u00eda ejecutarse del siguiente modo: #Modificando el mensaje git commit -m \"Descripci\u00f3n\" --amend #Sin modificar el mensaje git commit --amend --no-edit Editar el mensaje del \u00faltimo commit. Cuando ejecutemos el comando se nos abrir\u00e1 un editor para realizar dicha modificaci\u00f3n. La ejecuci\u00f3n en este caso es m\u00e1s simple. git commit --amend Note Si ejecutamos el \u00faltimo comando git commit --amend -m \"Descripci\u00f3n actualizada\" se actualizar\u00e1 el mensaje sin necesidad de abrir el editor para realziar cambios.","title":"Git commit --amend"},{"location":"Git/configuracion-inicial/","text":"Configuraci\u00f3n inicial # Lo primero que debemos hacer es aplicar una serie de configuraciones globales. Estas configuraciones globales que haremos servir\u00e1n para a\u00f1adir metadatos a los diferentes commit que vayamos haciendo. Nombre de usuario: git config --global user.name \"nombre\" Email: git config --global user.email \"email\" Listar las configuraciones globales: git config --list Git se encuentra rastreando de forma constante nuestro Working Directory en busca de cambios que se hayan realizado. Dentro de estos cambios se encuentran las modificaciones, eliminaci\u00f3n y creaci\u00f3n de ficheros y/o directorios. Para que Git realice su trabajo de rastreo es necesario ejecutar el comando para que inicie dicho rastreo. git init Note El comando ha de ejecutarse dentro del directorio que queremos rastrear. A pesar de que Git rastrea continuamente qu\u00e9 cambios hacemos, no almacenar\u00e1 ning\u00fan cambio hasta que nosotros se lo indiquemos expl\u00edcitamente. Podemos ver en que estado se encuentra nuestro Working Directory . #Vista normal git status #Para ver de un modo resumido ejecutaremos: git status --short Despu\u00e9s de ejecutar el comando git status , si ha habido alg\u00fan tipo de cambio en el directorio, podemos observar que hay contenido dentro de nuestro Working Directory modificado o del que a\u00fan no llevamos ning\u00fan control. Si nos encontramos con alg\u00fan cambio, tendremos que ejecutar una serie de comandos: A\u00f1adiendo el contenido al Staging Area . #Para a\u00f1adir un fichero o m\u00e1s los haremos escribiendo su nombre git add 404 .html #Para a\u00f1adir todo el contenido disponible (dos opciones) git add -A git add . Una vez que el contenido est\u00e1 preparado, crearemos la referencia ( commit ) a esos cambios. git commit -m \"Creaci\u00f3n inicial del proyecto\" Estas dos operaciones, git add y git commit se pueden unir en una \u00fanica operaci\u00f3n. git commit -am \"Creaci\u00f3n inicial del proyecto\" Historial del proyecto # Hay un t\u00e9rmino muy conocido en el mundo de la inform\u00e1tica que hace referencia a registros que se almacenan en un archivo, lo cuales hacen referencia a cambios o acontecimientos surgidos a lo largo del tiempo. A este termino se le denomina log , y en git se utiliza para hacer referencia al historial de commit. git log Este comando tiene muchos par\u00e1metros que podemos pasar y modificar la salida del comando. Por ejemplo si tenemos muchos commit, la forma que muestra por defecto la salida del comando no es demasiado c\u00f3moda, por lo que ser\u00e1 interesante pasar diferentes par\u00e1metros como: --oneline : muestra una l\u00ednea por commit. Commit id + t\u00edtulo del commit. --graph : muestra de forma gr\u00e1fica los commit. Se combina con --online y --decorate. --date=relative : fecha relativa a la fecha del sistema. Es decir mostrar\u00e1 hace \"x\" minutos. --stat : muestra qu\u00e9 cambios ha habido en cada commit. --pretty=format:\"formato personalizado\" : damos formato al log. -n : donde n es un n\u00famero para mostrar los \u00faltimos commit en funci\u00f3n del n\u00famero que hayamos puesto. --grep=\"mensaje\" : como el comando grep de la terminal, busca por mensaje. Si a\u00f1adimos -i no distinguir\u00e1 entre may\u00fasculas y min\u00fasculas. - -nombre_fichero : nos busca en que commit se encuentra. #Podemos ver que miembros han contribuido y cuantos commit han hecho cada uno git shortlog Gitignore # Es un fichero oculto (su nombre nos lo indica .gitignore ) con el que evitamos que ciertos archivos sean tenidos en cuenta por git. En el fichero se pueden definir ficheros por su nombre completo, o utilizar expresiones regulares (regex). Podemos hacer uso de / , terminando con este s\u00edmbolo para referirnos a un directorio. El signo de exclamaci\u00f3n ! al inicio denota negaci\u00f3n. Directorios anidados. Se expresa del siguiente modo: directorio1/**/directorio2, coincidir\u00eda con directorio1/otrodirectorio/directorio2 doc/**/*.txt ignorar\u00e1 todos los .txt que se encuentren bajo el directorio doc, aunque est\u00e9n en otro directorio dentro de doc.","title":"Configuraci\u00f3n inicial"},{"location":"Git/configuracion-inicial/#configuracion-inicial","text":"Lo primero que debemos hacer es aplicar una serie de configuraciones globales. Estas configuraciones globales que haremos servir\u00e1n para a\u00f1adir metadatos a los diferentes commit que vayamos haciendo. Nombre de usuario: git config --global user.name \"nombre\" Email: git config --global user.email \"email\" Listar las configuraciones globales: git config --list Git se encuentra rastreando de forma constante nuestro Working Directory en busca de cambios que se hayan realizado. Dentro de estos cambios se encuentran las modificaciones, eliminaci\u00f3n y creaci\u00f3n de ficheros y/o directorios. Para que Git realice su trabajo de rastreo es necesario ejecutar el comando para que inicie dicho rastreo. git init Note El comando ha de ejecutarse dentro del directorio que queremos rastrear. A pesar de que Git rastrea continuamente qu\u00e9 cambios hacemos, no almacenar\u00e1 ning\u00fan cambio hasta que nosotros se lo indiquemos expl\u00edcitamente. Podemos ver en que estado se encuentra nuestro Working Directory . #Vista normal git status #Para ver de un modo resumido ejecutaremos: git status --short Despu\u00e9s de ejecutar el comando git status , si ha habido alg\u00fan tipo de cambio en el directorio, podemos observar que hay contenido dentro de nuestro Working Directory modificado o del que a\u00fan no llevamos ning\u00fan control. Si nos encontramos con alg\u00fan cambio, tendremos que ejecutar una serie de comandos: A\u00f1adiendo el contenido al Staging Area . #Para a\u00f1adir un fichero o m\u00e1s los haremos escribiendo su nombre git add 404 .html #Para a\u00f1adir todo el contenido disponible (dos opciones) git add -A git add . Una vez que el contenido est\u00e1 preparado, crearemos la referencia ( commit ) a esos cambios. git commit -m \"Creaci\u00f3n inicial del proyecto\" Estas dos operaciones, git add y git commit se pueden unir en una \u00fanica operaci\u00f3n. git commit -am \"Creaci\u00f3n inicial del proyecto\"","title":"Configuraci\u00f3n inicial"},{"location":"Git/configuracion-inicial/#historial-del-proyecto","text":"Hay un t\u00e9rmino muy conocido en el mundo de la inform\u00e1tica que hace referencia a registros que se almacenan en un archivo, lo cuales hacen referencia a cambios o acontecimientos surgidos a lo largo del tiempo. A este termino se le denomina log , y en git se utiliza para hacer referencia al historial de commit. git log Este comando tiene muchos par\u00e1metros que podemos pasar y modificar la salida del comando. Por ejemplo si tenemos muchos commit, la forma que muestra por defecto la salida del comando no es demasiado c\u00f3moda, por lo que ser\u00e1 interesante pasar diferentes par\u00e1metros como: --oneline : muestra una l\u00ednea por commit. Commit id + t\u00edtulo del commit. --graph : muestra de forma gr\u00e1fica los commit. Se combina con --online y --decorate. --date=relative : fecha relativa a la fecha del sistema. Es decir mostrar\u00e1 hace \"x\" minutos. --stat : muestra qu\u00e9 cambios ha habido en cada commit. --pretty=format:\"formato personalizado\" : damos formato al log. -n : donde n es un n\u00famero para mostrar los \u00faltimos commit en funci\u00f3n del n\u00famero que hayamos puesto. --grep=\"mensaje\" : como el comando grep de la terminal, busca por mensaje. Si a\u00f1adimos -i no distinguir\u00e1 entre may\u00fasculas y min\u00fasculas. - -nombre_fichero : nos busca en que commit se encuentra. #Podemos ver que miembros han contribuido y cuantos commit han hecho cada uno git shortlog","title":"Historial del proyecto"},{"location":"Git/configuracion-inicial/#gitignore","text":"Es un fichero oculto (su nombre nos lo indica .gitignore ) con el que evitamos que ciertos archivos sean tenidos en cuenta por git. En el fichero se pueden definir ficheros por su nombre completo, o utilizar expresiones regulares (regex). Podemos hacer uso de / , terminando con este s\u00edmbolo para referirnos a un directorio. El signo de exclamaci\u00f3n ! al inicio denota negaci\u00f3n. Directorios anidados. Se expresa del siguiente modo: directorio1/**/directorio2, coincidir\u00eda con directorio1/otrodirectorio/directorio2 doc/**/*.txt ignorar\u00e1 todos los .txt que se encuentren bajo el directorio doc, aunque est\u00e9n en otro directorio dentro de doc.","title":"Gitignore"},{"location":"Git/git-hosting/","text":"Son plataformas que se encargan de alojar el c\u00f3digo de los diferentes proyectos que diferentes desarrolladores deciden publicar. La decisi\u00f3n habitualmente puede deberse a varios motivos. Colaboraci\u00f3n. Es una herramienta magn\u00edfica para que diferentes desarrolladores trabajen sobre un mismo proyecto. Permitir que otras personas ajenas al proyecto lo mejoren. Crear nuevo software a partir de dicho proyecto. Favorecer el Software de c\u00f3digo abierto. Hay varias plataformas disponibles para ello, como por ejemplo GitHub , que ser\u00e1 la plataforma sobre la que se basar\u00e1n todas las explicaciones que hagan referencia a Git en repositorios remotos, GitLab o Bitbucket . Clonaci\u00f3n de repositorios # La clonaci\u00f3n nos permite descargar un proyecto a nuestro equipo local. Es una forma de poder estudiar el c\u00f3digo del proyecto que nos estamos descargando. git clone direcci\u00f3n_repositorio Podemos utilizar la direcci\u00f3n del repositorio en formato ssh o https que copiaremos del repositorio remoto en GitHub. Note La descarga de un proyecto incluye todo el historial de commit. Conexi\u00f3n SSH con GitHub # Creaci\u00f3n de llaves (p\u00fablica y privada) ssh ssh-keygen -t rsa -b 4096 -t: type -b: n\u00famero de bits Copiar la llave p\u00fablica creada en el apartado correspondiente de los ajustes de GitHub. Conexi\u00f3n con remotos # Cuando queremos conectar nuestro proyecto local con el repositorio en GitHub debemos a\u00f1adir la conexi\u00f3n remota con este para poder realizar las acciones de env\u00edo ( push ) y recepci\u00f3n ( pull ) de c\u00f3digo. Para llevar a cabo la conexi\u00f3n simplemente debemos ejecutar un comando, donde direcci\u00f3n_remota ser\u00e1 la direcci\u00f3n del repositorio que GitHub nos indique y nombre_remoto utilizaremos la palabra origin . Si no nos hemos dado cuenta, cuando ejecutamos git clone para descargarnos un repositorio remoto, se asocia un remoto que evidentemente apunta a la direcci\u00f3n del repositorio clonado. git remote add origin direcci\u00f3n_remota Note La descarga de un proyecto incluye todo el historial de commit. Si la direcci\u00f3n del remoto que hemos establecido es incorrecta podemos cambiarla ejecutando el siguiente comando. git remote set-url origin direcci\u00f3n_remota Env\u00edo y recepci\u00f3n # Con esto nos referimos al contenido que subimos o nos descargamos a/hacia un repositorio remoto. Subir contenido # Subimos la rama master git push origin master Subimos todas las ramas del proyecto git push origin --all Note El nombre remoto tal y como hemos visto en el anterior apartado ser\u00e1 origin ya que es el nombre que hemos asignado a la url que apunta al repositorio remoto. Descargar contenido # Actualizamos/descargamos la rama master git pull origin master Actualizamos la rama master y reorganizamos commit git pull --rebase origin master Note Al igual que sucede con el comando git push origin es la referencia a la url del repositorio remoto. Desengranando Git pull # A la hora de descargar contenido del repositorio remoto es habitual utilizar el comando git pull . Este comando realmente se compone de otros dos comandos que se ejecutan por detr\u00e1s. Git fetch # Este es el primer comando que se ejecuta, el cual pregunta al repositorio remoto si tiene novedades y en caso de que as\u00ed sea las descarga en la rama origin/master de nuestro repositorio local. git fetch origin Git merge # Este comando lo hemos visto en el apartado de las fusiones y aqu\u00ed tiene la misma funcionalidad. Trata de fusionar la rama origin/master , que contiene las novedades del repositorio remoto, con la rama master local para que esta est\u00e9 actualizada. git merge origin/master Note Es necesario recordar que como ya hab\u00edamos visto es necesario situarnos en la rama a la que queremos fusionar la rama que introducimos en el comando. Cuando trabajamos en colaboraci\u00f3n con otras personas en un proyecto es importante conocer estos dos comandos ya que habitualmente sustituir\u00e1n al comando git pull . En muchas ocasiones el repositorio remoto y el local no estar\u00e1n sincronizados debido a que el remoto habr\u00e1 sido actualizado por un alg\u00fan colaborador. Por lo tanto, antes de realizar git push ser\u00e1 necesario actualizar nuestro repositorio local para que este se encuentre sincronizado con el repositorio remoto. La mejor forma de llevar el control de estos cambios es ejecutando git fetch y git merge como sustitutos de git pull . Fork de un repositorio # Realizar fork no es m\u00e1s que realizar una copia de un repositorio. En el momento de la copia ambos repositorios son id\u00e9nticos, ramas, historial del proyecto, etc. A partir de ese momento cada uno de ellos puede evolucionar por caminos diferentes ya que no est\u00e1n sincronizados de ning\u00fan modo. En este punto se puede dar lo siguiente: Evolucionar el proyecto de forma independiente, el proyecto original y su fork tienen un historial completamente diferente. Mejorar el proyecto manteniendo el historial de ambos sincronizado. En el primer punto simplemente trabajaremos como si de un nuevo proyecto se tratara, sincronizaci\u00f3n entre el repositorio remoto de nuestra cuenta de GitHub y nuestro repositorio local. En el segundo punto, el que nos interesa, se trata de mejorar el proyecto original y despu\u00e9s incorporar dichas mejoras a trav\u00e9s de una solicitud que se denomina pull request . Cuando trabajamos en este tipo de repositorios pasamos a trabajar con dos repositorios remotos. origin : este remoto ya lo conocemos, es el remoto que apunta a la direcci\u00f3n donde se encuentra nuestro repositorio remoto. upstream : al igual que origin , se utiliza este nombre por convenci\u00f3n. En este caso, apunta a la direcci\u00f3n del repositorio original, es decir, al repositorio sobre el que hemos hecho fork. El proceso para sincronizar el repositorio original y nuestro repositorio local es similar al que hemos visto anteriormente. A\u00f1adimos el repositorio remoto original. git remote add upstream direcci\u00f3n_remota Comprobamos y descargamos cambios en caso de que haya a local. git fetch upstream Fusionamos los cambios upstream con nuestra rama master local. git merge origin/upstream","title":"Hosting para git"},{"location":"Git/git-hosting/#clonacion-de-repositorios","text":"La clonaci\u00f3n nos permite descargar un proyecto a nuestro equipo local. Es una forma de poder estudiar el c\u00f3digo del proyecto que nos estamos descargando. git clone direcci\u00f3n_repositorio Podemos utilizar la direcci\u00f3n del repositorio en formato ssh o https que copiaremos del repositorio remoto en GitHub. Note La descarga de un proyecto incluye todo el historial de commit.","title":"Clonaci\u00f3n de repositorios"},{"location":"Git/git-hosting/#conexion-ssh-con-github","text":"Creaci\u00f3n de llaves (p\u00fablica y privada) ssh ssh-keygen -t rsa -b 4096 -t: type -b: n\u00famero de bits Copiar la llave p\u00fablica creada en el apartado correspondiente de los ajustes de GitHub.","title":"Conexi\u00f3n SSH con GitHub"},{"location":"Git/git-hosting/#conexion-con-remotos","text":"Cuando queremos conectar nuestro proyecto local con el repositorio en GitHub debemos a\u00f1adir la conexi\u00f3n remota con este para poder realizar las acciones de env\u00edo ( push ) y recepci\u00f3n ( pull ) de c\u00f3digo. Para llevar a cabo la conexi\u00f3n simplemente debemos ejecutar un comando, donde direcci\u00f3n_remota ser\u00e1 la direcci\u00f3n del repositorio que GitHub nos indique y nombre_remoto utilizaremos la palabra origin . Si no nos hemos dado cuenta, cuando ejecutamos git clone para descargarnos un repositorio remoto, se asocia un remoto que evidentemente apunta a la direcci\u00f3n del repositorio clonado. git remote add origin direcci\u00f3n_remota Note La descarga de un proyecto incluye todo el historial de commit. Si la direcci\u00f3n del remoto que hemos establecido es incorrecta podemos cambiarla ejecutando el siguiente comando. git remote set-url origin direcci\u00f3n_remota","title":"Conexi\u00f3n con remotos"},{"location":"Git/git-hosting/#envio-y-recepcion","text":"Con esto nos referimos al contenido que subimos o nos descargamos a/hacia un repositorio remoto.","title":"Env\u00edo y recepci\u00f3n"},{"location":"Git/git-hosting/#subir-contenido","text":"Subimos la rama master git push origin master Subimos todas las ramas del proyecto git push origin --all Note El nombre remoto tal y como hemos visto en el anterior apartado ser\u00e1 origin ya que es el nombre que hemos asignado a la url que apunta al repositorio remoto.","title":"Subir contenido"},{"location":"Git/git-hosting/#descargar-contenido","text":"Actualizamos/descargamos la rama master git pull origin master Actualizamos la rama master y reorganizamos commit git pull --rebase origin master Note Al igual que sucede con el comando git push origin es la referencia a la url del repositorio remoto.","title":"Descargar contenido"},{"location":"Git/git-hosting/#desengranando-git-pull","text":"A la hora de descargar contenido del repositorio remoto es habitual utilizar el comando git pull . Este comando realmente se compone de otros dos comandos que se ejecutan por detr\u00e1s.","title":"Desengranando Git pull"},{"location":"Git/git-hosting/#git-fetch","text":"Este es el primer comando que se ejecuta, el cual pregunta al repositorio remoto si tiene novedades y en caso de que as\u00ed sea las descarga en la rama origin/master de nuestro repositorio local. git fetch origin","title":"Git fetch"},{"location":"Git/git-hosting/#git-merge","text":"Este comando lo hemos visto en el apartado de las fusiones y aqu\u00ed tiene la misma funcionalidad. Trata de fusionar la rama origin/master , que contiene las novedades del repositorio remoto, con la rama master local para que esta est\u00e9 actualizada. git merge origin/master Note Es necesario recordar que como ya hab\u00edamos visto es necesario situarnos en la rama a la que queremos fusionar la rama que introducimos en el comando. Cuando trabajamos en colaboraci\u00f3n con otras personas en un proyecto es importante conocer estos dos comandos ya que habitualmente sustituir\u00e1n al comando git pull . En muchas ocasiones el repositorio remoto y el local no estar\u00e1n sincronizados debido a que el remoto habr\u00e1 sido actualizado por un alg\u00fan colaborador. Por lo tanto, antes de realizar git push ser\u00e1 necesario actualizar nuestro repositorio local para que este se encuentre sincronizado con el repositorio remoto. La mejor forma de llevar el control de estos cambios es ejecutando git fetch y git merge como sustitutos de git pull .","title":"Git merge"},{"location":"Git/git-hosting/#fork-de-un-repositorio","text":"Realizar fork no es m\u00e1s que realizar una copia de un repositorio. En el momento de la copia ambos repositorios son id\u00e9nticos, ramas, historial del proyecto, etc. A partir de ese momento cada uno de ellos puede evolucionar por caminos diferentes ya que no est\u00e1n sincronizados de ning\u00fan modo. En este punto se puede dar lo siguiente: Evolucionar el proyecto de forma independiente, el proyecto original y su fork tienen un historial completamente diferente. Mejorar el proyecto manteniendo el historial de ambos sincronizado. En el primer punto simplemente trabajaremos como si de un nuevo proyecto se tratara, sincronizaci\u00f3n entre el repositorio remoto de nuestra cuenta de GitHub y nuestro repositorio local. En el segundo punto, el que nos interesa, se trata de mejorar el proyecto original y despu\u00e9s incorporar dichas mejoras a trav\u00e9s de una solicitud que se denomina pull request . Cuando trabajamos en este tipo de repositorios pasamos a trabajar con dos repositorios remotos. origin : este remoto ya lo conocemos, es el remoto que apunta a la direcci\u00f3n donde se encuentra nuestro repositorio remoto. upstream : al igual que origin , se utiliza este nombre por convenci\u00f3n. En este caso, apunta a la direcci\u00f3n del repositorio original, es decir, al repositorio sobre el que hemos hecho fork. El proceso para sincronizar el repositorio original y nuestro repositorio local es similar al que hemos visto anteriormente. A\u00f1adimos el repositorio remoto original. git remote add upstream direcci\u00f3n_remota Comprobamos y descargamos cambios en caso de que haya a local. git fetch upstream Fusionamos los cambios upstream con nuestra rama master local. git merge origin/upstream","title":"Fork de un repositorio"},{"location":"Git/git-tags/","text":"Podemos entender los tags (etiquetas en castellano) como puntos relevantes del repositorio, habitualmente utilizados para versionar el proyecto en el que nos encontramos trabajando. Existen dos formas de crear tags: Annotated tags (etiquetas anotadas): nos permite generar un mensaje en la etiqueta. git tag -a tag-elegido -m \"mensaje\" Lightweight tags (etiquetas ligeras): \u00fanicamente establecemos la etiqueta, a pesar de ello podemos a\u00f1adir una descripci\u00f3n. Note La gran diferencia entre estos dos tipos de etiquetas es que las anotadas permiten almacenar los metadatos (nombre, correo electr\u00f3nico, fecha, etc.) tal y como hacen los commit. Se recomienda el uso de estas por encima de las etiquetas ligeras. Los tags nos proporcionan la ventaja de poder movernos en el historial a trav\u00e9s del propio tag en vez de hacerlo a trav\u00e9s del commit id como se hace habitualmente. git checkout tag Siguiendo con los tags, disponemos de otra serie de comandos para trabajar con ellos. Listar tags disponibles git tag Buscar una tag en particular git tag -l \"tag\" Asignar un tag a un commit id git tag -a tag commit_id Subir tags git push tags","title":"Tags"},{"location":"Git/informacion-adicional/","text":"Git Extras # El repositorio oficial lo encontramos en GitHub . Su instalaci\u00f3n se encuentra disponible para los tres principales sistemas operativos, en el repositorio encontramos las instrucciones para su instalaci\u00f3n. Podemos encontrar un resumen de todos los comandos que nos encontramos en git extras summary . GitHub Cli # Hasta hace poco si quer\u00edamos interactuar con GitHub desde la l\u00ednea de comandos no hab\u00eda ninguna herramienta oficial, era necesario buscar herramientas desarrolladas por desarrolladores independientes o similares. Recientemente ( septiembre de 2002 ) disponemos de la primera versi\u00f3n ( 1.0 ) de GitHub Cli, una herramienta de l\u00ednea de comandos para llevar a cabo todo el flujo de trabajo que se hac\u00eda desde la web desde nuestro terminal. Anuncio de GitHub CLI 1.0 GitHub CLI sitio oficial Todos los comandos disponibles Enlaces con resoluci\u00f3n de dudas # Closing issues using keywords git diff --color-moved Git branch explained in more detail","title":"Informaci\u00f3n adicional"},{"location":"Git/informacion-adicional/#git-extras","text":"El repositorio oficial lo encontramos en GitHub . Su instalaci\u00f3n se encuentra disponible para los tres principales sistemas operativos, en el repositorio encontramos las instrucciones para su instalaci\u00f3n. Podemos encontrar un resumen de todos los comandos que nos encontramos en git extras summary .","title":"Git Extras"},{"location":"Git/informacion-adicional/#github-cli","text":"Hasta hace poco si quer\u00edamos interactuar con GitHub desde la l\u00ednea de comandos no hab\u00eda ninguna herramienta oficial, era necesario buscar herramientas desarrolladas por desarrolladores independientes o similares. Recientemente ( septiembre de 2002 ) disponemos de la primera versi\u00f3n ( 1.0 ) de GitHub Cli, una herramienta de l\u00ednea de comandos para llevar a cabo todo el flujo de trabajo que se hac\u00eda desde la web desde nuestro terminal. Anuncio de GitHub CLI 1.0 GitHub CLI sitio oficial Todos los comandos disponibles","title":"GitHub Cli"},{"location":"Git/informacion-adicional/#enlaces-con-resolucion-de-dudas","text":"Closing issues using keywords git diff --color-moved Git branch explained in more detail","title":"Enlaces con resoluci\u00f3n de dudas"},{"location":"Git/introduccion-git/","text":"Introducci\u00f3n # Git es un software de control de versiones, es decir un software que \"almacena\" un historial de los cambios que hagamos sobre aquello que hayamos establecido para controlar. \u00c1rea Local - Working Directory : es el \u00e1rea de trabajo, donde tenemos los recursos sobre los que queremos llevar un control. \u00c1rea Local - Staging Area : es el \u00e1rea donde se preparan los archivos que se enviar\u00e1n al repositorio. Es el espacio donde se \"encapsula\" el contenido para despu\u00e9s realizar un commit sobre el mismo. No es necesario almacenar en este \u00e1rea todo el contenido que tenemos en el Working Directory . Repositorio : aqu\u00ed se encuentra el registro de los cambios que hemos realizado y que hemos decidido \"almacenar\". El flujo m\u00e1s habitual de Git es el siguiente: Trabajamos sobre los archivos que se encuentran en el Working Directory . Una vez que hay modificaciones en el Working Directory pasamos a prepar los archivos a\u00f1adi\u00e9ndolos al Staging Area . Confirmamos los cambios, esto significa que se recoge los archivos tal y como se encuentran en el \u00e1rea de preparaci\u00f3n y se almacenan esas inst\u00e1ntaneas de manera permanente en el repositorio. Note Este proceso se lleva a cabo cada vez que necesitamos registrar alg\u00fan cambio en Git. Instalaci\u00f3n de Git # En la web git-scm.com podemos encontrar informaci\u00f3n para descargar Git en las diferentes plataformas en las que se encuentra disponible. Entre estas plataformas tenemos Windows, MacOS y Linux. Adem\u00e1s de la versi\u00f3n cli (l\u00ednea de comandos), tambi\u00e9n dispone de versi\u00f3n con interfaz gr\u00e1fica. Despu\u00e9s de seguir con el proceso de instalaci\u00f3n de Git, podemos comprobar si se encuentra instalado ejecutando el comando git --version .","title":"Introducci\u00f3n a Git"},{"location":"Git/introduccion-git/#introduccion","text":"Git es un software de control de versiones, es decir un software que \"almacena\" un historial de los cambios que hagamos sobre aquello que hayamos establecido para controlar. \u00c1rea Local - Working Directory : es el \u00e1rea de trabajo, donde tenemos los recursos sobre los que queremos llevar un control. \u00c1rea Local - Staging Area : es el \u00e1rea donde se preparan los archivos que se enviar\u00e1n al repositorio. Es el espacio donde se \"encapsula\" el contenido para despu\u00e9s realizar un commit sobre el mismo. No es necesario almacenar en este \u00e1rea todo el contenido que tenemos en el Working Directory . Repositorio : aqu\u00ed se encuentra el registro de los cambios que hemos realizado y que hemos decidido \"almacenar\". El flujo m\u00e1s habitual de Git es el siguiente: Trabajamos sobre los archivos que se encuentran en el Working Directory . Una vez que hay modificaciones en el Working Directory pasamos a prepar los archivos a\u00f1adi\u00e9ndolos al Staging Area . Confirmamos los cambios, esto significa que se recoge los archivos tal y como se encuentran en el \u00e1rea de preparaci\u00f3n y se almacenan esas inst\u00e1ntaneas de manera permanente en el repositorio. Note Este proceso se lleva a cabo cada vez que necesitamos registrar alg\u00fan cambio en Git.","title":"Introducci\u00f3n"},{"location":"Git/introduccion-git/#instalacion-de-git","text":"En la web git-scm.com podemos encontrar informaci\u00f3n para descargar Git en las diferentes plataformas en las que se encuentra disponible. Entre estas plataformas tenemos Windows, MacOS y Linux. Adem\u00e1s de la versi\u00f3n cli (l\u00ednea de comandos), tambi\u00e9n dispone de versi\u00f3n con interfaz gr\u00e1fica. Despu\u00e9s de seguir con el proceso de instalaci\u00f3n de Git, podemos comprobar si se encuentra instalado ejecutando el comando git --version .","title":"Instalaci\u00f3n de Git"},{"location":"Git/ramas/","text":"Crear Ramas # Para crear ramas en git tenemos dos formas de hacerlo. Crear una rama git branch nombre_de_rama Crear una rama y movernos a ella git checkout -b nombre_de_rama Ejecutando git branch no obtendremos ning\u00fan resultado por pantalla, pero podemos comprobar si la nueva rama se ha creado correctamente. git branch #Este comando mostrar\u00e1 un listado de las ramas locales Movernos entre ramas # El comando que necesitamos para movernos de una rama a otra nos resultar\u00e1 familiar. git checkout nombre_de_rama Otro comando interesante que nos permite movernos a la rama anterior en la que nos encontr\u00e1bamos cuando nos hemos movido de forma r\u00e1pida. git checkout - Este comando tambi\u00e9n es utilizado para descartar cambios que hayamos hecho en el Working Directory, es decir cambios sobre los que no hemos ejecutado el comando git add o git commit . git checkout -- nombre-fichero Cambiar nombre rama # git branch -m nombre_rama nombre_rama_nuevo Note No es necesario indicar el nombre_rama si la rama que quieres modificar es en la que te encuentras. Con el comando anterior \u00fanicamente conseguimos modificar el nombre de la rama local. El objetivo es que tanto la rama local como la rama remota (por ejemplo la rama del proyecto en GitHub) tengan el mismo nombre, con lo que deberemos ejecutar los siguientes comandos adem\u00e1s del anterior. #Eliminar rama remota git push origin --delete nombre_rama #Crear la nueva rama remota git push origin -u nombre_rama Note La opci\u00f3n -u (--set-upstream) se utiliza habitualmente cuando disponemos de varias ramas en nuestro proyecto. De este modo estamos \"enlazando\" la rama local con la rama remota. Cuando se ejecute git push , este enviar\u00e1 los cambios a la rama correspondiente. Fusionar ramas # Para fusionar ramas es necesario situarse en la rama que va a recibir los cambios hechos en esa segunda rama que queremos fusionar. Habitualmente cuando vamos a fusionar una rama lo haremos con la rama principal (no siempre tiene por qu\u00e9 ser as\u00ed) que es la rama master. git merge nombre_de_rama #Ser\u00e1 la rama que queremos fusionar Seguido de ejecutar el comando nos aparecer\u00e1 en la terminar para poder insertar un mensaje de commit, ya que a partir de la fusi\u00f3n estaremos creando un commit nuevo a partir de las ramas fusionadas. Esto es as\u00ed siempre y cuando no haya ning\u00fan conflicto entre ramas, de ah\u00ed que distingamos dos tipos de fusiones. Fast-forward : es la fusi\u00f3n que \"simple\", cuando no existe ning\u00fan conflicto la rama principal absorbe la rama \"secundaria\" y crea un commit a partir de las dos ramas fusionadas. Manual Merge : esto se da cuando se han modificado partes iguales de un mismo fichero en las ramas que vamos a fusionar. En el momento que ejecutamos git merge se nos mostrar\u00e1 un mensaje de error indicando que hay un conflicto y que debemos resolverlo. Debeos resolver el conflicto manualmente, aunque existen herramientas que nos facilitan el trabajo. Rama rebase # Rebase , a diferencia de merge , nos permite reescribir el historial de commit. Ambos comandos pretenden integrar una rama en otra, pero cada uno de ellos lo hace de forma diferente. En este caso lo que conseguimos con rebase es mantener el historial de commit de forma lineal, es decir, cuando hacemos un rebase lo que conseguimos es posicionar los commit (depender\u00e1 de las opciones agregadas al comando) de la rama actual por delante de la rama master (puede ser cualquier otra rama). Lo que conlleva este proceso es la reescritura del historial. Plantear este m\u00e9todo como fusi\u00f3n tiene ciertas implicaciones, tanto positivas como negativas, que es necesario conocer. Ventajas # Historial de proyecto lineal. Evitamos crear los commit innecesario referentes a la fusi\u00f3n tal y como sucede con el comando git merge . Desventajas # A la vez que conseguimos un historial lineal alteramos dicho historial, con lo cual corremos el riesgo de perdida de commit y de alterar el proyecto en el que colaboramos. Perdemos trazabilidad por tener un historial lineal. Los comandos m\u00e1s simples que entran en acci\u00f3n cuando queremos llevar a cabo rebase son los siguientes: Situarse en la rama sobre la que queremos realizar el rebase. git checkout nombre_rama Ejecutamos el comando rebase, se tendr\u00e1n en cuenta todos los commit de dicha rama. git rebase master Una vez que los commit de la rama secundaria se han situado por delante de la rama master, nos movemos a esta. git checkout master Por \u00faltimo moveremos la rama master hasta el \u00faltimo commit de la rama secundaria , para ello es necesario realizar una fusi\u00f3n fast-forward . git merge nombre_rama Para conocer este maravilloso comando en profundidad, tanto la parte interactiva como las recomendaciones, es imprescindible visitar estos dos enlaces: Git rebase Merging vs rebasing Eliminar ramas # En algunas ocasiones es necesario eliminar ramas, ya sea despu\u00e9s de haber realizado fusionado la rama o porque no vamos a continuar trabajando sobre dicha rama. git branch -d nombre_rama El comando anterior nos permite eliminar una rama local, pero si queremos eliminar una rama remota tenemos dos opciones. Opci\u00f3n 1: git push origin :nombre_rama Opci\u00f3n 2: git push origin --delete nombre_rama","title":"Ramas"},{"location":"Git/ramas/#crear-ramas","text":"Para crear ramas en git tenemos dos formas de hacerlo. Crear una rama git branch nombre_de_rama Crear una rama y movernos a ella git checkout -b nombre_de_rama Ejecutando git branch no obtendremos ning\u00fan resultado por pantalla, pero podemos comprobar si la nueva rama se ha creado correctamente. git branch #Este comando mostrar\u00e1 un listado de las ramas locales","title":"Crear Ramas"},{"location":"Git/ramas/#movernos-entre-ramas","text":"El comando que necesitamos para movernos de una rama a otra nos resultar\u00e1 familiar. git checkout nombre_de_rama Otro comando interesante que nos permite movernos a la rama anterior en la que nos encontr\u00e1bamos cuando nos hemos movido de forma r\u00e1pida. git checkout - Este comando tambi\u00e9n es utilizado para descartar cambios que hayamos hecho en el Working Directory, es decir cambios sobre los que no hemos ejecutado el comando git add o git commit . git checkout -- nombre-fichero","title":"Movernos entre ramas"},{"location":"Git/ramas/#cambiar-nombre-rama","text":"git branch -m nombre_rama nombre_rama_nuevo Note No es necesario indicar el nombre_rama si la rama que quieres modificar es en la que te encuentras. Con el comando anterior \u00fanicamente conseguimos modificar el nombre de la rama local. El objetivo es que tanto la rama local como la rama remota (por ejemplo la rama del proyecto en GitHub) tengan el mismo nombre, con lo que deberemos ejecutar los siguientes comandos adem\u00e1s del anterior. #Eliminar rama remota git push origin --delete nombre_rama #Crear la nueva rama remota git push origin -u nombre_rama Note La opci\u00f3n -u (--set-upstream) se utiliza habitualmente cuando disponemos de varias ramas en nuestro proyecto. De este modo estamos \"enlazando\" la rama local con la rama remota. Cuando se ejecute git push , este enviar\u00e1 los cambios a la rama correspondiente.","title":"Cambiar nombre rama"},{"location":"Git/ramas/#fusionar-ramas","text":"Para fusionar ramas es necesario situarse en la rama que va a recibir los cambios hechos en esa segunda rama que queremos fusionar. Habitualmente cuando vamos a fusionar una rama lo haremos con la rama principal (no siempre tiene por qu\u00e9 ser as\u00ed) que es la rama master. git merge nombre_de_rama #Ser\u00e1 la rama que queremos fusionar Seguido de ejecutar el comando nos aparecer\u00e1 en la terminar para poder insertar un mensaje de commit, ya que a partir de la fusi\u00f3n estaremos creando un commit nuevo a partir de las ramas fusionadas. Esto es as\u00ed siempre y cuando no haya ning\u00fan conflicto entre ramas, de ah\u00ed que distingamos dos tipos de fusiones. Fast-forward : es la fusi\u00f3n que \"simple\", cuando no existe ning\u00fan conflicto la rama principal absorbe la rama \"secundaria\" y crea un commit a partir de las dos ramas fusionadas. Manual Merge : esto se da cuando se han modificado partes iguales de un mismo fichero en las ramas que vamos a fusionar. En el momento que ejecutamos git merge se nos mostrar\u00e1 un mensaje de error indicando que hay un conflicto y que debemos resolverlo. Debeos resolver el conflicto manualmente, aunque existen herramientas que nos facilitan el trabajo.","title":"Fusionar ramas"},{"location":"Git/ramas/#rama-rebase","text":"Rebase , a diferencia de merge , nos permite reescribir el historial de commit. Ambos comandos pretenden integrar una rama en otra, pero cada uno de ellos lo hace de forma diferente. En este caso lo que conseguimos con rebase es mantener el historial de commit de forma lineal, es decir, cuando hacemos un rebase lo que conseguimos es posicionar los commit (depender\u00e1 de las opciones agregadas al comando) de la rama actual por delante de la rama master (puede ser cualquier otra rama). Lo que conlleva este proceso es la reescritura del historial. Plantear este m\u00e9todo como fusi\u00f3n tiene ciertas implicaciones, tanto positivas como negativas, que es necesario conocer.","title":"Rama rebase"},{"location":"Git/ramas/#ventajas","text":"Historial de proyecto lineal. Evitamos crear los commit innecesario referentes a la fusi\u00f3n tal y como sucede con el comando git merge .","title":"Ventajas"},{"location":"Git/ramas/#desventajas","text":"A la vez que conseguimos un historial lineal alteramos dicho historial, con lo cual corremos el riesgo de perdida de commit y de alterar el proyecto en el que colaboramos. Perdemos trazabilidad por tener un historial lineal. Los comandos m\u00e1s simples que entran en acci\u00f3n cuando queremos llevar a cabo rebase son los siguientes: Situarse en la rama sobre la que queremos realizar el rebase. git checkout nombre_rama Ejecutamos el comando rebase, se tendr\u00e1n en cuenta todos los commit de dicha rama. git rebase master Una vez que los commit de la rama secundaria se han situado por delante de la rama master, nos movemos a esta. git checkout master Por \u00faltimo moveremos la rama master hasta el \u00faltimo commit de la rama secundaria , para ello es necesario realizar una fusi\u00f3n fast-forward . git merge nombre_rama Para conocer este maravilloso comando en profundidad, tanto la parte interactiva como las recomendaciones, es imprescindible visitar estos dos enlaces: Git rebase Merging vs rebasing","title":"Desventajas"},{"location":"Git/ramas/#eliminar-ramas","text":"En algunas ocasiones es necesario eliminar ramas, ya sea despu\u00e9s de haber realizado fusionado la rama o porque no vamos a continuar trabajando sobre dicha rama. git branch -d nombre_rama El comando anterior nos permite eliminar una rama local, pero si queremos eliminar una rama remota tenemos dos opciones. Opci\u00f3n 1: git push origin :nombre_rama Opci\u00f3n 2: git push origin --delete nombre_rama","title":"Eliminar ramas"},{"location":"Git/referencias/","text":"Libros # ProGit Git Internals Conversational Git Fuentes recomendadas # Become a Git pro in just one blog Git Tutorial Atlassian Bitbucket Abbreviated git Workflow GitHub Cheat Sheet Git Immersion RipTutorial Git tags Guide GitHub Guides Gestionando ramas A Tutorial for Tagging Releases How to change a commit message in git Como colaborar en un proyecto en GitHub","title":"Referencias"},{"location":"Git/referencias/#libros","text":"ProGit Git Internals Conversational Git","title":"Libros"},{"location":"Git/referencias/#fuentes-recomendadas","text":"Become a Git pro in just one blog Git Tutorial Atlassian Bitbucket Abbreviated git Workflow GitHub Cheat Sheet Git Immersion RipTutorial Git tags Guide GitHub Guides Gestionando ramas A Tutorial for Tagging Releases How to change a commit message in git Como colaborar en un proyecto en GitHub","title":"Fuentes recomendadas"},{"location":"Kubernetes/introduccion-kubernetes/","text":"Es una tecnolog\u00eda desarrollada inicialmente por Google, aunque actualmente pertenece a Cloud Native Computing Foundation gracias a que fue donada por parte de Google. La primera versi\u00f3n de este sistema fue liberada el 21 de julio de 2015. Kubernetes es un sistema de c\u00f3digo abierto utilizado para automatizar el despliegue de aplicaciones containerizadas. B\u00e1sicamente se encarga de orquestar los contenedores que se despliegan (el proceso de despliegue se automatiza), de forma transparente los distribuye entre los diferentes nodos (m\u00e1quinas f\u00edsicas o virtuales que componen el cl\u00faster) que conforman Kubernetes. Por lo tanto, el usuario no tiene que preocuparse de la gesti\u00f3n f\u00edsica de los servidores, el cl\u00faster es interpretado como un conjunto de recursos que se encuentran disponibles para el despliegue de las diferentes aplicaciones. Kubernetes facilita una API para trabajar con el cl\u00faster, que se utiliza para automatizar el proceso de despliegue ajustando el ciclo de vida de la aplicaci\u00f3n. Por ejemplo, establecer cuantos recursos necesita la app para funcionar correctamente, \"healtchecks\" que informan si la aplicaci\u00f3n sigue funcionando o seleccionar mediante etiquetas en que nodos se ejecutar\u00e1n nuestras aplicaciones. \u00bfQu\u00e9 ventajas nos aporta Kubernetes? Escalabilidad \u2192 automatizar el despligue y la replicaci\u00f3n de contenedores. Confiabilidad \u2192 reemplazar contenedores en caso de que estos \"mueran\". Eficiencia \u2192 recursos disponibles mejor optimizados. Caracter\u00edsticas relevantes # Inmutabilidad : a diferencia de los sistemas operativos que hemos conocido hasta la actualidad, los cuales reciben actualizaciones incrementales reemplazando los ficheros ya existentes, los sistemas inmutables, las actualizaciones se aplican construyendo un sistema completamente nuevo, en el ambito en el que nos encontramos dir\u00edamos que se construye una nueva imagen. Declarative configuration : todo lo que nos encontramos en Kubernetes es un objeto creado a trav\u00e9s de un fichero en el que declaramos el estado de dicho objeto. Kubernetes se encarga de mantener el estado tal y como lo hemos definido. Self-healing systems : la \"tarea\" de Kubernetes se centra, como hemos dicho, en mantener el estado del sistema tal y como lo hemos definido. Realiza tareas como la recreaci\u00f3n de los contenedores que hayan dejado de funcionar, cumpliendo con lo declarado en el fichero de configuraci\u00f3n. Componentes Kubernetes # Cl\u00faster # Un cl\u00faster es un grupo de nodos. Si hablamos f\u00edsicamente, ser\u00e1 un grupo de m\u00e1quinas que trabajar\u00e1n conjuntamente. El cluster es el que contendr\u00e1 todo este sistema, del que partir\u00e1n el resto de partes que lo conforman. Nodo # Es la primera parte con la que nos encontramos cuando queremos desglosar el cl\u00faster de Kubernetes. Habitualmente est\u00e1 representado por una m\u00e1quina ( workers ), por lo tanto cada m\u00e1quina de un cl\u00faster podr\u00eda interpretarse como un nodo. Dentro de este \"grupo\" nos encontramos con dos tipos: Nodo Master : es el nodo que \"central\" que controla el resto de nodos. En este nodo se ejecutan varios procesos. kube-apiserver kube-controller-manager kube-scheduler Nodos : en este grupo nos encontrar\u00edamos con el resto de nodos, los que son controlados desde el Master. Cada uno de estos nodos ejecutan los siguientes procesos. kubelet \u2192 es el encargado de comunicarse con el Master. kube-proxy \u2192 implementa los servicios de red de Kubernetes. Una vez que los nodos est\u00e1n en funcionamiento, el \u00fanico nodo con el que interactuaremos ser\u00e1 con el Master, que es el que recibe las instrucciones cuando hacemos uso del comando kubectl . Namespaces # Nos permiten ogranizar los diferentes objetos dentro del cl\u00faster. Podemos entender cada namespace como directorio que manteine un grupo de objetos. El namespace por defecto es default . Se puede utilizar un namespace diferente, lo veremos m\u00e1s adelante. Pod # Es el objeto que representa uno o varios contenedores utilizados para desplegar nuestra aplicaci\u00f3n. Es habitual que un pod sea exclusivamente un \u00fanico contenedor. Todos los contenedores que se encuentra en un pod siempre est\u00e1n en la misma m\u00e1quina, es decir en el mismo nodo. Las aplicaciones/contenedores que se encuentra en el mismo pod comparten direcci\u00f3n ip , espacio de puertos (un mismo puerto no puede ser utilizado por m\u00e1s de un contenedor) y el mismo hostname (se comunican entre ellos utilizando localhost ). Por tanto, las aplicaciones que se encuentran en diferentes pods se encuentran aisladas unas de otras.","title":"Introducci\u00f3n a Kubernetes"},{"location":"Kubernetes/introduccion-kubernetes/#caracteristicas-relevantes","text":"Inmutabilidad : a diferencia de los sistemas operativos que hemos conocido hasta la actualidad, los cuales reciben actualizaciones incrementales reemplazando los ficheros ya existentes, los sistemas inmutables, las actualizaciones se aplican construyendo un sistema completamente nuevo, en el ambito en el que nos encontramos dir\u00edamos que se construye una nueva imagen. Declarative configuration : todo lo que nos encontramos en Kubernetes es un objeto creado a trav\u00e9s de un fichero en el que declaramos el estado de dicho objeto. Kubernetes se encarga de mantener el estado tal y como lo hemos definido. Self-healing systems : la \"tarea\" de Kubernetes se centra, como hemos dicho, en mantener el estado del sistema tal y como lo hemos definido. Realiza tareas como la recreaci\u00f3n de los contenedores que hayan dejado de funcionar, cumpliendo con lo declarado en el fichero de configuraci\u00f3n.","title":"Caracter\u00edsticas relevantes"},{"location":"Kubernetes/introduccion-kubernetes/#componentes-kubernetes","text":"","title":"Componentes Kubernetes"},{"location":"Kubernetes/introduccion-kubernetes/#cluster","text":"Un cl\u00faster es un grupo de nodos. Si hablamos f\u00edsicamente, ser\u00e1 un grupo de m\u00e1quinas que trabajar\u00e1n conjuntamente. El cluster es el que contendr\u00e1 todo este sistema, del que partir\u00e1n el resto de partes que lo conforman.","title":"Cl\u00faster"},{"location":"Kubernetes/introduccion-kubernetes/#nodo","text":"Es la primera parte con la que nos encontramos cuando queremos desglosar el cl\u00faster de Kubernetes. Habitualmente est\u00e1 representado por una m\u00e1quina ( workers ), por lo tanto cada m\u00e1quina de un cl\u00faster podr\u00eda interpretarse como un nodo. Dentro de este \"grupo\" nos encontramos con dos tipos: Nodo Master : es el nodo que \"central\" que controla el resto de nodos. En este nodo se ejecutan varios procesos. kube-apiserver kube-controller-manager kube-scheduler Nodos : en este grupo nos encontrar\u00edamos con el resto de nodos, los que son controlados desde el Master. Cada uno de estos nodos ejecutan los siguientes procesos. kubelet \u2192 es el encargado de comunicarse con el Master. kube-proxy \u2192 implementa los servicios de red de Kubernetes. Una vez que los nodos est\u00e1n en funcionamiento, el \u00fanico nodo con el que interactuaremos ser\u00e1 con el Master, que es el que recibe las instrucciones cuando hacemos uso del comando kubectl .","title":"Nodo"},{"location":"Kubernetes/introduccion-kubernetes/#namespaces","text":"Nos permiten ogranizar los diferentes objetos dentro del cl\u00faster. Podemos entender cada namespace como directorio que manteine un grupo de objetos. El namespace por defecto es default . Se puede utilizar un namespace diferente, lo veremos m\u00e1s adelante.","title":"Namespaces"},{"location":"Kubernetes/introduccion-kubernetes/#pod","text":"Es el objeto que representa uno o varios contenedores utilizados para desplegar nuestra aplicaci\u00f3n. Es habitual que un pod sea exclusivamente un \u00fanico contenedor. Todos los contenedores que se encuentra en un pod siempre est\u00e1n en la misma m\u00e1quina, es decir en el mismo nodo. Las aplicaciones/contenedores que se encuentra en el mismo pod comparten direcci\u00f3n ip , espacio de puertos (un mismo puerto no puede ser utilizado por m\u00e1s de un contenedor) y el mismo hostname (se comunican entre ellos utilizando localhost ). Por tanto, las aplicaciones que se encuentran en diferentes pods se encuentran aisladas unas de otras.","title":"Pod"},{"location":"Kubernetes/kubectl/","text":"El cliente de Kubernetes que nos permite controlarlo es kubectl . Es una herramienta de l\u00ednea de comandos para interactuar con la API de Kubernetes, utilizada para gestionar la mayor parte de objetos de Kubernetes, tales como los pods, servicios, namespaces, etc. Adem\u00e1s permite conocer el estado general del cl\u00faster. Esta herramienta se encuentra disponible en los diferentes Sistemas Operativos. En este caso la instalaci\u00f3n se ha realizado en MacOS Catalina y en Fedora 30 , que ser\u00e1n los equipos desde controlaremos el cl\u00faster de Kubernetes. brew install kubectl #A\u00f1adir repositorio cat <<EOF> /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes basurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF #Descargar el paquete sudo dnf install kubectl Para m\u00e1s informaci\u00f3n: Install kubectl Una vez que tenemos kubectl instalado localmente, necesitamos un fichero kubeconfig (fichero utilizado para configurar el acceso al cl\u00faster) para que kubectl se comunique con la API de Kubernetes. Aprovecharemos el fichero que se ha generado en el nodo master, lo descargaremos y guardaremos en el directorio $HOME/.kube , que es el directorio donde kubectl busca el fichero con el nombre config . Podemos visualizar el fichero con kubectl. kubectl config view Si el fichero de configuraci\u00f3n no tiene el nombre por defecto (config), deberemos utilizar la opci\u00f3n --kubeconfig=fichero-configuracion . kubectl config --kubeconfig = fichero-configuracion view Set the KUBECONFIG environment variable - Organize cluster access kubeconfig Si ya disponemos de conexi\u00f3n con el cl\u00faster podremos conocer tanto la versi\u00f3n de kubectl como de la API de Kubernetes . kubectl version Note Para facilitar el uso de kubectl podemos habilitar el autocompletado ejecutando el comando sudo kubectl completion bash > /etc/bas_completion.d/kubectl 1 . El siguiente paso ser\u00e1 comprobar el estado del cl\u00faster. kubectl get cs El resultado ser\u00e1 similar a esto: NAME STATUS MESSAGE ERROR scheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy { \"health\" : \"true\" } Scheduler : es el responsable de distribuir los pods en los diferentes nodos del cl\u00faster. Controller-manager : es el encargado de correr varios controladores que regulan el estado del cl\u00faster, por ejemplo que las replicas que hayamos definido se encuentren disponibles. Servidor etcd : es el lugar en donde se almacenan todos los objetos. Listamos todos los nodos del cl\u00faster. kubectl get nodes Tal y como hemos visto en estos dos \u00faltimos comandos, kubectl get recurso (pods, services, nodes, etc.) nos muestra un listado de los recursos en el namespace en el que nos encontramos (recordamos que default es el namespace por defecto). Podemos ampliar la informaci\u00f3n que nos muestras utilizando la opoci\u00f3n -o wide . Adem\u00e1s, otra de las opciones interesantes es --no-headers , suprime los encabezados. Otro de los comandos importantes que nos provee kuibectl es kubectl desribe recurso objeto . La salida de este comando muestra informaci\u00f3n muy completa del objeto que le hayamos pasado. Por ejemplo podemos solicitar la informaci\u00f3n de un nodo del cl\u00faster en particular. kubectl describe nodes rpi4 Creando objetos # Los objetos en Kubernetes se definen en un fichero con sintaxis json o yaml . Estos ficheros se utilizan tanto para crear, actualizar o eliminar dichos objetos. Para crear o actualizar un objeto utilizaremos el siguiente comando. #Este comando nos permite crear y actualizar un objeto kubectl apply -f fichero.yaml Disponemos de la posibilidad de actualizar los objetos de forma interactiva, es decir se abre un editor en la terminal, realizaremos las modificaciones que deseemos y una vez que guardemos Kubernetes se encargar\u00e1 de aplicar los cambios. kubectl edit recurso objeto Note Es importante tener cuidado con los cambios que se realizan al vuelo puesto que estos no modifican el manifiesto, por lo que lo m\u00e1s recomendable es aplicar cambios con el comando kubectl apply -f . El comando para eliminar los objetos es muy similar al de crearlos. Cuando eliminamos un pod, todos los datos almacenados dentro de los contenedores asociados al pod son eliminados. Para que esto no suceda disponemos de vol\u00famenes persistentes que veremos m\u00e1s adelante. kubectl detete -f fichero.yaml kubectl delete recurso objeto Desplegando objetos # Disponemos varias formas de desplegar pods en nuestro cl\u00faster. La forma m\u00e1s sencilla es ejecutando kubectl run . Por ejemplo si queremos desplegar un pod de Nginx como servidor web. Podemos desplegar un pod ejecutando el siguiente comando: kubectl run nombre-pod --image = nginx:latest En el flag --image podemos a\u00f1adir una imagen local o una imagen que se encuentra alojada en el registry oficcial de Docker. Ejemplo de un manifiesto de pod. apiVersion : v1 kind : Pod metadata : name : nginx spec : containers : - image : nginx:latest name : nginx-prueba ports : - name : web containerPort : 80 protocol : TCP Info El fichero yaml que vemos ser\u00e1 el fichero base que utilizaremos para a\u00f1adirle nuevas secciones que iremos conociendo a lo largo del proyecto. Gesti\u00f3n de recursos # Kubernetes no solo trata que el despliegue de aplicaciones sea m\u00e1s sencillo, sino que adem\u00e1s intenta que el aprovechamiento de los recursos est\u00e9 mejor optimizado. Nos encontramos con dos formas para la gesti\u00f3n de los recursos. Resource requests : la cantidad m\u00ednima de recursos que necesita una aplicaci\u00f3n para funcionar. Resource limits : la cantidad m\u00e1xima de recursos que una aplicaci\u00f3n puede hacer uso. Note Los recursos se especifican por cada contenedor, no por cada pod. apiVersion : v1 kind : Pod metadata : name : nginx spec : containers : - image : nginx:latest name : nginx-prueba resources : requests : cpu : \"500m\" memory : \"128Mi\" limits : cpu : \"1000m\" memory : \"256Mi\" ports : - name : web containerPort : 80 protocol : TPC Cuando el sistema se queda sin memoria, kubelet se encarga de \"matar\" los contenedores que est\u00e1n utilizando m\u00e1s memoria de la que hemos definido. Los contenedores volver\u00e1n a iniciarse con un consumo menor de recursos ajustados a los que hayamos definido. Vol\u00famenes # Los vol\u00famenes son una herramienta muy \u00fatil cuando trabajamos con contenedores, nos permite mantener datos m\u00e1s haya del contenedor que los haya generado. Los principales motivos por los que deseamos utilizar vol\u00famenes: Sincronizaci\u00f3n : acceso a por parte de m\u00e1s de un contenedor a los mismos datos. Cach\u00e9 : datos como miniaturas que no son relevantes pero que se utilizan para mostrar algo dentro de una aplicaci\u00f3n. Si los datos los almacenamos en un vol\u00famen no ser\u00e1 necesario crearlos cada vez que el pod sea recreado. Evitamos un consumo extra de recursos. Datos persistentes : datos que queremos que se mantengan en el tiempo a pesar de que el pod del que depend\u00edan no vaya a utilizarse. \u00bfC\u00f3mo se definen en el fichero yaml? # Nivel spec : se definen los vol\u00famenes que pueden ser accedidos por el/los contenedores de un pod. Si un pod dispone de m\u00e1s de un contenedor no es necesario que todos ellos utilicen los vol\u00famenes definidos. Adem\u00e1s existe la posibilidad de utilizar discos remotos, como por ejemplo vol\u00famenes NFS. Info Es interesante utilizar servicios remotos como NFS porque nos permite que los datos persistentes sean independientes del nodo donde se encuentre el Pod. Nivel container : en este apartado se define el volumen del contenedor que ir\u00e1 asociado al volumen definido en el apartado anterior. A continuaci\u00f3n podemos ver un ejemplo con dos vol\u00famenes que podemos utilizar en los contenedores que contenga el Pod. apiVersion : v1 kind : Pod metadata : name : nginx spec : volumes : - name : \"nginx-data\" hostPath : path : \"/nginx/my-web\" - name : \"nginx-data-nfs\" nfs : server : rpi-nfs.local path : \"/exports\" containers : - image : nginx:latest name : nginx-prueba volumeMounts : - mountPath : \"/usr/share/nginx/html\" name : \"nginx-data\" ports : - name : web containerPort : 80 protocol : TPC Labels # Nos facilita la identificaci\u00f3n de los diferentes objetos de nuestro cl\u00faster. Esto nos permite agrupar , visualizar y operar de una forma m\u00e1s sencilla. --labels = \"version=1,app=nginx\" Podemos a\u00f1adir manualmente labels a un objeto que ya hemos creado. kubectl label pods nginx \"env=lab\" Tambi\u00e9n podemos eliminar un label (o varios) que est\u00e9 asociado a un objeto. Se utiliza un el s\u00edmbolo - para ello. kubectl label pods nginx \"app-\" Mostrar columnas adicionales con la informaci\u00f3n referente a los labels . kubectl get pods -L app El resultado nos muestra una columna adicional que hace referencia a la clave del label que hemos indicado en el comando anterior. En dicha columna aparecer\u00e1 el valor que tiene asignado dicha clave. Si el pod no tiene asignada clave:valor , no aparecer\u00e1 nada. NAME READY UP-TO-DATE AVAILABLE AGE APP nginx 1 /1 1 1 6d23h nginx nginx2 1 /1 1 1 3d1h Una de las funciones que nos aportan los labels es la posiblidad de filtrar objetos. kubectl get pods --selector = \"version=1\" Podemos utilizar una serie de operadores para utilizar junto al flag --selector . Operador Descripci\u00f3n key=value Key es igual a value kye!=value Key es diferente a value key in (value1, value2) Key puede ser tanto value1 como value2 key notin (value1, value2) Key no es ni value1 ni value2 key Key est\u00e1 definida !key Key no est\u00e1 definida Por ejemplo podemos mostrar los pods que se correspondan tanto con la versi\u00f3n 1 como con la versi\u00f3n 2. kubectl get pods --selector = \"version in (1,2)\" Tambi\u00e9n podemos utilizar una estructura similar en los fichero yaml . selector : matchLabels : app : nginx matchExpressions : - { key : ver , operator : IN , values : [ 1 , 2 ]} ReplicaSet # Un ReplicaSet nos garantiza que un n\u00famero concreto de instancias (lo definimos nosotros) de un Pod est\u00e9n siempre operativas. La recomendaci\u00f3n es aplicarlo exclusivamente a Pods sin estado ( stateless ), es decir que no tengan sesiones como puede ser una base de datos, ya que podr\u00eda darnos problemas. Este objeto nos ofrece una serie de ventajas. Redundancia \u2192 la posibilidad de disponer de varias instancias de un mismo Pod nos proporciona tolerancia a fallos . Escalabilidad \u2192 nos permite repartir el \"trabajo\" entre las diferentes instancias. El manifiesto de un ReplicaSet debe contener lo siguiente: Un nombre que identifique al propio ReplicaSet. En la secci\u00f3n spec es necesario indicar el n\u00famero de replicas. Podemos a\u00f1adir una secci\u00f3n m\u00e1s para definir una serie de Pods en el manifiesto del ReplicaSet. No es necesario a\u00f1adir esta seccion ( template ) ya que el ReplicaSet a trav\u00e9s de los labels ser\u00e1 capaz de identificar los Pods que debe \"adoptar\". Podemos comprobar si un Pod est\u00e1 siendo controlado por un ReplicaSet. Para ello ejecutaremos kubectl get pods nombre-pod -o yaml que nos dar\u00e1 como resultado el siguiente contenido. apiVersion : v1 kind : Pod metadata : name : nginx-f89759699-b662g namespace : default ownerReferences : - apiVersion : apps/v1 blockOwnerDeletion : true controller : true kind : ReplicaSet name : nginx-f89759699 uid : 8743e705-b5a0-4f04-8e7b-09acea2418da Observamos que controller: true y es del tipo ReplicaSet kind: ReplicaSet . En ocasiones es posible que neceistemos escalar de forma urgente y temporal un set de Pods, para ello tenemos el comando kubectl scale . kubectl scale replicasets nginx --replicas = 8 Con el ejemplo anterior hemos escalado hasta ocho Pods, lo que nos permitir\u00e1 en un momento determinado recibir m\u00e1s peticiones en nuestro servidor web Nginx. Note Para que estos cambias sean permanente deberemos actualizar el manifiesto correspondiente al ReplicaSet. Health Checks # Es la forma de mantener una aplicaci\u00f3n viva en todo momento, si una aplicaci\u00f3n falla Kubernetes se encarga de reiniciarla. Kubernetes nos proporciona dos formas health checks que se utilizan para objetivos diferentes, ambas se definen a nivel de contenedor. Liveness : verifica a nivel l\u00f3gico de aplicaci\u00f3n si esta est\u00e1 funcionando correctamente. Readiness : verifica cuando un contenedor est\u00e1 preparado para recibir peticiones. Cuando tenemos definidos cualquiera de estos dos health checks , podemos verificar el estado de los pods ejecutando kubectl describe pods nombre-pod . A continuaci\u00f3n vemos un ejemplo de livenessProbe que hemos aplicado al deployment de Ghost. spec : containers : livenessProbe : tcpSocket : port : ghost-port initialDelaySeconds : 30 timeoutSeconds : 5 periodSeconds : 20 failureThreshold : 3 En este ejemplo hemos utilizado initialDelaySeconds : es el tiempo en segundos que debe esperar Kubernetes desde que el contenedor se ha iniciado para iniciar livenesProbe . timeoutSeconds : es el tiempo en segundos de espera hasta que livenessProbe entiende que el contenedor est\u00e1 fallando. periodSeconds : cuanto tiempo en segundos espera Kubernetes para realizar la siguiente prueba. failureThreshold : el n\u00famero de intentos que realizar\u00e1 livenessProbe . Deployment # Es el objeto que se utiliza habitualmente para el despliegue de aplicaciones ya que engloba la creaci\u00f3n de un Pod y un ReplicaSet. Adem\u00e1s es una forma sencilla para controlar el lanzamiento de nuevas versiones de nuestras aplicaciones debido a que nos permite movernos tanto hac\u00eda atr\u00e1s (versiones antiguas) como hac\u00eda delante (versiones nuevas) facilmente. Para que la gesti\u00f3n de las diferentes versiones de nuestra aplicaci\u00f3n sea sencilla, este guarda un hist\u00f3rico de los cambios que se han ido desplegando. Es recomendable establecer un m\u00e1ximo de versiones, lo haremos en el manifiesto del Deployment. spec : revisionHistoryLimit : 10 Podemos ver el hist\u00f3rico de un deployment. kubectl rollout history deployment nginx El resultado nos muestra una lista con las diferentes versiones, desde la m\u00e1s antigua hasta la m\u00e1s nueva. Si queremos conocer m\u00e1s sobre una versi\u00f3n espec\u00edfica podemos utilizar el flag --revision , al que deberemos indicar el n\u00famero de la columna Revision . Es importante mantener actualizada la key annotations , ya que esta recibe la descipci\u00f3n de los cambios que hemos realizado en la versi\u00f3n que vamos a desplegar. Adem\u00e1s es la informaci\u00f3n que aparece en la columna Change-cause . spec : template : metadata : annotations : kubernetes.io/change-cause : \"Actualizaci\u00f3n versi\u00f3n 2\" Al igual que con otros objetos, podemos interactuar con este modificando su configuraci\u00f3n \"al vuelo\" o modificando el manifiesto (lo m\u00e1s recomendable). kubectl rollout undo deployment nginx Este comando nos permite volver a la versi\u00f3n anterior del Pod nginx. Podemos utilizar el flag --to-revision para volver a una versi\u00f3n espec\u00edfica. kubectl rollout undo deployment nginx --to-revision = 2 Note Lo m\u00e1s recomendable es actualizar el manifiesto, modificar la versi\u00f3n y aplicarla con el comando kubectl apply . Disponemos de dos estrategias diferentes para el despliegue de nuevas versiones: Recreate : esta estrategia no se utilizar para entornos de producci\u00f3n. El funcionamiento es sencillo y r\u00e1pido, el ReplicaSet se encarga de las actualizaciones parando todas las instancias y recreandolas. No hay ning\u00fan tipo de control sobre los updates, por lo tanto tendremos el servicio parado durante un determinado tiempo y adem\u00e1s es posible que este no vuelva a inciarse correctamente. RollingUpdate : es una estrategia m\u00e1s sofisticada y robusta que la anterior, pero implicia mayor demora en la actualizaci\u00f3n de todas la instancias. La actulizaci\u00f3n se va aplicando de forma incremental, actualizando las instancias en bloques hasta que todas hayan recibido la actualizaci\u00f3n. De este modo evitamos que haya una parada del servicio y en caso de fallo de la actualizaci\u00f3n que el servicio no vuelva a iniciarse. Esta estrategia mantiene durante el periodo de actualizaci\u00f3n tanto la nueva versi\u00f3n como la anterior funcionando de forma concurrente. Disponemos de varias configuraciones maxUnavailable : se establece el n\u00famero m\u00e1ximo de Pods que pueden no estar disponibles durante la actualizaci\u00f3n. maxSurge : controla cuantos recursos extras podemos definir para llevar a cabo la actualizaci\u00f3n. Si por ejemplo asignamos 50% sobre 10 Pods, crear\u00e1 5 Pods extra durante la actualizaci\u00f3n para realizar el despliegue, para mantener 10 Pods de la versi\u00f3n anterior siempre en funcionamiento hasta que la actualizaci\u00f3n haya finalizado con \u00e9xito. spec : strategy : rollingUpdate : maxUnavailable : 50% maxSurge : 50% type : RollingUpdate Info En ambas configuraciones se puede definir como n\u00famero entero o en porcentaje. El RollingUpdate es la estrategia m\u00e1s adecuada porque es un despliegue por etapas, lo que asegura que las actualizaciones terminar\u00e1n en estado healthy . El estado de cada Pod actualizado se determina con los readiness checks . Ademas: minReadySeconds : es el tiempo m\u00ednimo de espera por cada etapa para poder pasar a la siguiente. spec : minReadySencods : 60 progressDeadlineSeconds : en este caso se indica el tiempo m\u00e1ximo que debe esperar por cada etapa. spec : progressDeadlineSeconds : 300 Services # Seg\u00fan la definici\u00f3n que podemos encontrar en la documentaci\u00f3n oficial de Kubernetes, es una forma abstracta de exponer una aplicaci\u00f3n que se encuentra en uno o m\u00e1s Pods como un servicio de red. Una de las razones de la existencia de este objeto es la efimeridad de los Pods, estos pueden morir y volver a nacer , por lo que a lo largo del tiempo la direcci\u00f3n IP de los Pods puede cambiar. Si disponemos de un conjunto de Pods que deben interactuar entre ellos (frontend vs backend) necesitamos una formula para que estos puedan comunicarse sin depender de su direcci\u00f3n IP. Los servicios son un endpoint permanente (punto de entrada) que nos permite acceder a un conjunto de Pods. Un servicio utiliza los labels para reconocer los Pods que deben estar detr\u00e1s de un servicio. Kubernetes nos ofrece tres tipos de servicios: ClusterIP (es el tipo de servicio por defecto): este servicio es expuesto con una direcci\u00f3n IP interna del cl\u00faster, por lo tanto solo es accesible desde dentro del cl\u00faster. NodePort : este servicio expone un puerto de forma est\u00e1tica en todos los nodos, por lo que nuestros Pods ser\u00e1n accesibles desde el exterior realizando una petici\u00f3n a IP:Puerto . LoadBalancer : es un servicio utilizado en Plataformas Cloud que lo que ofrece es una \u00fanica direcci\u00f3n IP que reenviar\u00e1 todo el tr\u00e1fico al servicio correspondiente, que se encargar\u00e1 de realizar el reenv\u00edo a los Pods. Debug # Hay formas muy avanzadas de gestionar los logs, aunque kubectl nos proporciona un comando para ello. kubectl logs pod Si queremos mantener la terminal actualizada con la salida de los logs podemos utilizar el flag -f . Adem\u00e1s, si el pod contiene m\u00e1s de un contenedor la opci\u00f3n -c contenedor nos permite revisar los logs de un contenedor en particular. En el caso de que la informaci\u00f3n mostrada con los anteriores comandos no sea suficiente, podemos \"entrar\" dentro del contendor para buscar de forma m\u00e1s precisa posibles errores que hayan surgido. kubectl exec -it pod -- bash Autocompletado kubectl \u21a9","title":"Kubectl"},{"location":"Kubernetes/kubectl/#creando-objetos","text":"Los objetos en Kubernetes se definen en un fichero con sintaxis json o yaml . Estos ficheros se utilizan tanto para crear, actualizar o eliminar dichos objetos. Para crear o actualizar un objeto utilizaremos el siguiente comando. #Este comando nos permite crear y actualizar un objeto kubectl apply -f fichero.yaml Disponemos de la posibilidad de actualizar los objetos de forma interactiva, es decir se abre un editor en la terminal, realizaremos las modificaciones que deseemos y una vez que guardemos Kubernetes se encargar\u00e1 de aplicar los cambios. kubectl edit recurso objeto Note Es importante tener cuidado con los cambios que se realizan al vuelo puesto que estos no modifican el manifiesto, por lo que lo m\u00e1s recomendable es aplicar cambios con el comando kubectl apply -f . El comando para eliminar los objetos es muy similar al de crearlos. Cuando eliminamos un pod, todos los datos almacenados dentro de los contenedores asociados al pod son eliminados. Para que esto no suceda disponemos de vol\u00famenes persistentes que veremos m\u00e1s adelante. kubectl detete -f fichero.yaml kubectl delete recurso objeto","title":"Creando objetos"},{"location":"Kubernetes/kubectl/#desplegando-objetos","text":"Disponemos varias formas de desplegar pods en nuestro cl\u00faster. La forma m\u00e1s sencilla es ejecutando kubectl run . Por ejemplo si queremos desplegar un pod de Nginx como servidor web. Podemos desplegar un pod ejecutando el siguiente comando: kubectl run nombre-pod --image = nginx:latest En el flag --image podemos a\u00f1adir una imagen local o una imagen que se encuentra alojada en el registry oficcial de Docker. Ejemplo de un manifiesto de pod. apiVersion : v1 kind : Pod metadata : name : nginx spec : containers : - image : nginx:latest name : nginx-prueba ports : - name : web containerPort : 80 protocol : TCP Info El fichero yaml que vemos ser\u00e1 el fichero base que utilizaremos para a\u00f1adirle nuevas secciones que iremos conociendo a lo largo del proyecto.","title":"Desplegando objetos"},{"location":"Kubernetes/kubectl/#gestion-de-recursos","text":"Kubernetes no solo trata que el despliegue de aplicaciones sea m\u00e1s sencillo, sino que adem\u00e1s intenta que el aprovechamiento de los recursos est\u00e9 mejor optimizado. Nos encontramos con dos formas para la gesti\u00f3n de los recursos. Resource requests : la cantidad m\u00ednima de recursos que necesita una aplicaci\u00f3n para funcionar. Resource limits : la cantidad m\u00e1xima de recursos que una aplicaci\u00f3n puede hacer uso. Note Los recursos se especifican por cada contenedor, no por cada pod. apiVersion : v1 kind : Pod metadata : name : nginx spec : containers : - image : nginx:latest name : nginx-prueba resources : requests : cpu : \"500m\" memory : \"128Mi\" limits : cpu : \"1000m\" memory : \"256Mi\" ports : - name : web containerPort : 80 protocol : TPC Cuando el sistema se queda sin memoria, kubelet se encarga de \"matar\" los contenedores que est\u00e1n utilizando m\u00e1s memoria de la que hemos definido. Los contenedores volver\u00e1n a iniciarse con un consumo menor de recursos ajustados a los que hayamos definido.","title":"Gesti\u00f3n de recursos"},{"location":"Kubernetes/kubectl/#volumenes","text":"Los vol\u00famenes son una herramienta muy \u00fatil cuando trabajamos con contenedores, nos permite mantener datos m\u00e1s haya del contenedor que los haya generado. Los principales motivos por los que deseamos utilizar vol\u00famenes: Sincronizaci\u00f3n : acceso a por parte de m\u00e1s de un contenedor a los mismos datos. Cach\u00e9 : datos como miniaturas que no son relevantes pero que se utilizan para mostrar algo dentro de una aplicaci\u00f3n. Si los datos los almacenamos en un vol\u00famen no ser\u00e1 necesario crearlos cada vez que el pod sea recreado. Evitamos un consumo extra de recursos. Datos persistentes : datos que queremos que se mantengan en el tiempo a pesar de que el pod del que depend\u00edan no vaya a utilizarse.","title":"Vol\u00famenes"},{"location":"Kubernetes/kubectl/#como-se-definen-en-el-fichero-yaml","text":"Nivel spec : se definen los vol\u00famenes que pueden ser accedidos por el/los contenedores de un pod. Si un pod dispone de m\u00e1s de un contenedor no es necesario que todos ellos utilicen los vol\u00famenes definidos. Adem\u00e1s existe la posibilidad de utilizar discos remotos, como por ejemplo vol\u00famenes NFS. Info Es interesante utilizar servicios remotos como NFS porque nos permite que los datos persistentes sean independientes del nodo donde se encuentre el Pod. Nivel container : en este apartado se define el volumen del contenedor que ir\u00e1 asociado al volumen definido en el apartado anterior. A continuaci\u00f3n podemos ver un ejemplo con dos vol\u00famenes que podemos utilizar en los contenedores que contenga el Pod. apiVersion : v1 kind : Pod metadata : name : nginx spec : volumes : - name : \"nginx-data\" hostPath : path : \"/nginx/my-web\" - name : \"nginx-data-nfs\" nfs : server : rpi-nfs.local path : \"/exports\" containers : - image : nginx:latest name : nginx-prueba volumeMounts : - mountPath : \"/usr/share/nginx/html\" name : \"nginx-data\" ports : - name : web containerPort : 80 protocol : TPC","title":"\u00bfC\u00f3mo se definen en el fichero yaml?"},{"location":"Kubernetes/kubectl/#labels","text":"Nos facilita la identificaci\u00f3n de los diferentes objetos de nuestro cl\u00faster. Esto nos permite agrupar , visualizar y operar de una forma m\u00e1s sencilla. --labels = \"version=1,app=nginx\" Podemos a\u00f1adir manualmente labels a un objeto que ya hemos creado. kubectl label pods nginx \"env=lab\" Tambi\u00e9n podemos eliminar un label (o varios) que est\u00e9 asociado a un objeto. Se utiliza un el s\u00edmbolo - para ello. kubectl label pods nginx \"app-\" Mostrar columnas adicionales con la informaci\u00f3n referente a los labels . kubectl get pods -L app El resultado nos muestra una columna adicional que hace referencia a la clave del label que hemos indicado en el comando anterior. En dicha columna aparecer\u00e1 el valor que tiene asignado dicha clave. Si el pod no tiene asignada clave:valor , no aparecer\u00e1 nada. NAME READY UP-TO-DATE AVAILABLE AGE APP nginx 1 /1 1 1 6d23h nginx nginx2 1 /1 1 1 3d1h Una de las funciones que nos aportan los labels es la posiblidad de filtrar objetos. kubectl get pods --selector = \"version=1\" Podemos utilizar una serie de operadores para utilizar junto al flag --selector . Operador Descripci\u00f3n key=value Key es igual a value kye!=value Key es diferente a value key in (value1, value2) Key puede ser tanto value1 como value2 key notin (value1, value2) Key no es ni value1 ni value2 key Key est\u00e1 definida !key Key no est\u00e1 definida Por ejemplo podemos mostrar los pods que se correspondan tanto con la versi\u00f3n 1 como con la versi\u00f3n 2. kubectl get pods --selector = \"version in (1,2)\" Tambi\u00e9n podemos utilizar una estructura similar en los fichero yaml . selector : matchLabels : app : nginx matchExpressions : - { key : ver , operator : IN , values : [ 1 , 2 ]}","title":"Labels"},{"location":"Kubernetes/kubectl/#replicaset","text":"Un ReplicaSet nos garantiza que un n\u00famero concreto de instancias (lo definimos nosotros) de un Pod est\u00e9n siempre operativas. La recomendaci\u00f3n es aplicarlo exclusivamente a Pods sin estado ( stateless ), es decir que no tengan sesiones como puede ser una base de datos, ya que podr\u00eda darnos problemas. Este objeto nos ofrece una serie de ventajas. Redundancia \u2192 la posibilidad de disponer de varias instancias de un mismo Pod nos proporciona tolerancia a fallos . Escalabilidad \u2192 nos permite repartir el \"trabajo\" entre las diferentes instancias. El manifiesto de un ReplicaSet debe contener lo siguiente: Un nombre que identifique al propio ReplicaSet. En la secci\u00f3n spec es necesario indicar el n\u00famero de replicas. Podemos a\u00f1adir una secci\u00f3n m\u00e1s para definir una serie de Pods en el manifiesto del ReplicaSet. No es necesario a\u00f1adir esta seccion ( template ) ya que el ReplicaSet a trav\u00e9s de los labels ser\u00e1 capaz de identificar los Pods que debe \"adoptar\". Podemos comprobar si un Pod est\u00e1 siendo controlado por un ReplicaSet. Para ello ejecutaremos kubectl get pods nombre-pod -o yaml que nos dar\u00e1 como resultado el siguiente contenido. apiVersion : v1 kind : Pod metadata : name : nginx-f89759699-b662g namespace : default ownerReferences : - apiVersion : apps/v1 blockOwnerDeletion : true controller : true kind : ReplicaSet name : nginx-f89759699 uid : 8743e705-b5a0-4f04-8e7b-09acea2418da Observamos que controller: true y es del tipo ReplicaSet kind: ReplicaSet . En ocasiones es posible que neceistemos escalar de forma urgente y temporal un set de Pods, para ello tenemos el comando kubectl scale . kubectl scale replicasets nginx --replicas = 8 Con el ejemplo anterior hemos escalado hasta ocho Pods, lo que nos permitir\u00e1 en un momento determinado recibir m\u00e1s peticiones en nuestro servidor web Nginx. Note Para que estos cambias sean permanente deberemos actualizar el manifiesto correspondiente al ReplicaSet.","title":"ReplicaSet"},{"location":"Kubernetes/kubectl/#health-checks","text":"Es la forma de mantener una aplicaci\u00f3n viva en todo momento, si una aplicaci\u00f3n falla Kubernetes se encarga de reiniciarla. Kubernetes nos proporciona dos formas health checks que se utilizan para objetivos diferentes, ambas se definen a nivel de contenedor. Liveness : verifica a nivel l\u00f3gico de aplicaci\u00f3n si esta est\u00e1 funcionando correctamente. Readiness : verifica cuando un contenedor est\u00e1 preparado para recibir peticiones. Cuando tenemos definidos cualquiera de estos dos health checks , podemos verificar el estado de los pods ejecutando kubectl describe pods nombre-pod . A continuaci\u00f3n vemos un ejemplo de livenessProbe que hemos aplicado al deployment de Ghost. spec : containers : livenessProbe : tcpSocket : port : ghost-port initialDelaySeconds : 30 timeoutSeconds : 5 periodSeconds : 20 failureThreshold : 3 En este ejemplo hemos utilizado initialDelaySeconds : es el tiempo en segundos que debe esperar Kubernetes desde que el contenedor se ha iniciado para iniciar livenesProbe . timeoutSeconds : es el tiempo en segundos de espera hasta que livenessProbe entiende que el contenedor est\u00e1 fallando. periodSeconds : cuanto tiempo en segundos espera Kubernetes para realizar la siguiente prueba. failureThreshold : el n\u00famero de intentos que realizar\u00e1 livenessProbe .","title":"Health Checks"},{"location":"Kubernetes/kubectl/#deployment","text":"Es el objeto que se utiliza habitualmente para el despliegue de aplicaciones ya que engloba la creaci\u00f3n de un Pod y un ReplicaSet. Adem\u00e1s es una forma sencilla para controlar el lanzamiento de nuevas versiones de nuestras aplicaciones debido a que nos permite movernos tanto hac\u00eda atr\u00e1s (versiones antiguas) como hac\u00eda delante (versiones nuevas) facilmente. Para que la gesti\u00f3n de las diferentes versiones de nuestra aplicaci\u00f3n sea sencilla, este guarda un hist\u00f3rico de los cambios que se han ido desplegando. Es recomendable establecer un m\u00e1ximo de versiones, lo haremos en el manifiesto del Deployment. spec : revisionHistoryLimit : 10 Podemos ver el hist\u00f3rico de un deployment. kubectl rollout history deployment nginx El resultado nos muestra una lista con las diferentes versiones, desde la m\u00e1s antigua hasta la m\u00e1s nueva. Si queremos conocer m\u00e1s sobre una versi\u00f3n espec\u00edfica podemos utilizar el flag --revision , al que deberemos indicar el n\u00famero de la columna Revision . Es importante mantener actualizada la key annotations , ya que esta recibe la descipci\u00f3n de los cambios que hemos realizado en la versi\u00f3n que vamos a desplegar. Adem\u00e1s es la informaci\u00f3n que aparece en la columna Change-cause . spec : template : metadata : annotations : kubernetes.io/change-cause : \"Actualizaci\u00f3n versi\u00f3n 2\" Al igual que con otros objetos, podemos interactuar con este modificando su configuraci\u00f3n \"al vuelo\" o modificando el manifiesto (lo m\u00e1s recomendable). kubectl rollout undo deployment nginx Este comando nos permite volver a la versi\u00f3n anterior del Pod nginx. Podemos utilizar el flag --to-revision para volver a una versi\u00f3n espec\u00edfica. kubectl rollout undo deployment nginx --to-revision = 2 Note Lo m\u00e1s recomendable es actualizar el manifiesto, modificar la versi\u00f3n y aplicarla con el comando kubectl apply . Disponemos de dos estrategias diferentes para el despliegue de nuevas versiones: Recreate : esta estrategia no se utilizar para entornos de producci\u00f3n. El funcionamiento es sencillo y r\u00e1pido, el ReplicaSet se encarga de las actualizaciones parando todas las instancias y recreandolas. No hay ning\u00fan tipo de control sobre los updates, por lo tanto tendremos el servicio parado durante un determinado tiempo y adem\u00e1s es posible que este no vuelva a inciarse correctamente. RollingUpdate : es una estrategia m\u00e1s sofisticada y robusta que la anterior, pero implicia mayor demora en la actualizaci\u00f3n de todas la instancias. La actulizaci\u00f3n se va aplicando de forma incremental, actualizando las instancias en bloques hasta que todas hayan recibido la actualizaci\u00f3n. De este modo evitamos que haya una parada del servicio y en caso de fallo de la actualizaci\u00f3n que el servicio no vuelva a iniciarse. Esta estrategia mantiene durante el periodo de actualizaci\u00f3n tanto la nueva versi\u00f3n como la anterior funcionando de forma concurrente. Disponemos de varias configuraciones maxUnavailable : se establece el n\u00famero m\u00e1ximo de Pods que pueden no estar disponibles durante la actualizaci\u00f3n. maxSurge : controla cuantos recursos extras podemos definir para llevar a cabo la actualizaci\u00f3n. Si por ejemplo asignamos 50% sobre 10 Pods, crear\u00e1 5 Pods extra durante la actualizaci\u00f3n para realizar el despliegue, para mantener 10 Pods de la versi\u00f3n anterior siempre en funcionamiento hasta que la actualizaci\u00f3n haya finalizado con \u00e9xito. spec : strategy : rollingUpdate : maxUnavailable : 50% maxSurge : 50% type : RollingUpdate Info En ambas configuraciones se puede definir como n\u00famero entero o en porcentaje. El RollingUpdate es la estrategia m\u00e1s adecuada porque es un despliegue por etapas, lo que asegura que las actualizaciones terminar\u00e1n en estado healthy . El estado de cada Pod actualizado se determina con los readiness checks . Ademas: minReadySeconds : es el tiempo m\u00ednimo de espera por cada etapa para poder pasar a la siguiente. spec : minReadySencods : 60 progressDeadlineSeconds : en este caso se indica el tiempo m\u00e1ximo que debe esperar por cada etapa. spec : progressDeadlineSeconds : 300","title":"Deployment"},{"location":"Kubernetes/kubectl/#services","text":"Seg\u00fan la definici\u00f3n que podemos encontrar en la documentaci\u00f3n oficial de Kubernetes, es una forma abstracta de exponer una aplicaci\u00f3n que se encuentra en uno o m\u00e1s Pods como un servicio de red. Una de las razones de la existencia de este objeto es la efimeridad de los Pods, estos pueden morir y volver a nacer , por lo que a lo largo del tiempo la direcci\u00f3n IP de los Pods puede cambiar. Si disponemos de un conjunto de Pods que deben interactuar entre ellos (frontend vs backend) necesitamos una formula para que estos puedan comunicarse sin depender de su direcci\u00f3n IP. Los servicios son un endpoint permanente (punto de entrada) que nos permite acceder a un conjunto de Pods. Un servicio utiliza los labels para reconocer los Pods que deben estar detr\u00e1s de un servicio. Kubernetes nos ofrece tres tipos de servicios: ClusterIP (es el tipo de servicio por defecto): este servicio es expuesto con una direcci\u00f3n IP interna del cl\u00faster, por lo tanto solo es accesible desde dentro del cl\u00faster. NodePort : este servicio expone un puerto de forma est\u00e1tica en todos los nodos, por lo que nuestros Pods ser\u00e1n accesibles desde el exterior realizando una petici\u00f3n a IP:Puerto . LoadBalancer : es un servicio utilizado en Plataformas Cloud que lo que ofrece es una \u00fanica direcci\u00f3n IP que reenviar\u00e1 todo el tr\u00e1fico al servicio correspondiente, que se encargar\u00e1 de realizar el reenv\u00edo a los Pods.","title":"Services"},{"location":"Kubernetes/kubectl/#debug","text":"Hay formas muy avanzadas de gestionar los logs, aunque kubectl nos proporciona un comando para ello. kubectl logs pod Si queremos mantener la terminal actualizada con la salida de los logs podemos utilizar el flag -f . Adem\u00e1s, si el pod contiene m\u00e1s de un contenedor la opci\u00f3n -c contenedor nos permite revisar los logs de un contenedor en particular. En el caso de que la informaci\u00f3n mostrada con los anteriores comandos no sea suficiente, podemos \"entrar\" dentro del contendor para buscar de forma m\u00e1s precisa posibles errores que hayan surgido. kubectl exec -it pod -- bash Autocompletado kubectl \u21a9","title":"Debug"},{"location":"Kubernetes/kubernetes-raspberrypi/","text":"Desplegando Kubernetes # Actualmente disponemos diferentes formas de desplegar Kubernetes. Basado en la nube , siendo este muy sencillo de configurar y mantener, y basado en m\u00e1quinas f\u00edsicas (bare metal), sistema m\u00e1s complejo de desplegar y mantener. Este proyecto lo llevaremos a cabo en un cl\u00faster con 3 Raspberry Pi , explicando en este apartado los pasos necesarios para desplegar nuestro cl\u00faster de Kubernetes. Comenzaremos haciendo una breve introducci\u00f3n de las primeras configuraciones que debemos realizar para acceder a nuestras Raspberry Pi. Puesto que este proyecto se centra en Kubernetes, no profundizaremos en los pasos que debemos seguir para tener un SO funcionando en una Raspberry Pi. El sistema elegido para cada una de nuestras Raspberry Pi ha sido CentOS 7 , la cual podemos descargar desde este enlace . Ya que el proyecto que realizamos se basa centra en Kubernetes, no profundizaremos sobre los pasos que debemos seguir para instalar y configurar los SO en la Raspberry Pi. Una vez que tenemos la imagen que deseamos (la elegida ha sido la minimal) podemos seguir los pasos para preparar la tarjeta SD y las recomendaciones que nos encontramos en la wiki de CentOS . Partiendo de que ya tenemos las Raspberry Pi funcionando correctamente, vamos a configurar nuestro equipo agregando las llaves y los datos de conexi\u00f3n para facilitar el acceso v\u00eda ssh. Fichero .ssh/config Host rpi4 HostName 192.168.11.200 User root IdentityFile ~/.ssh/rpi4.pub Host rpi2 HostName 192.168.11.205 User root IdentityFile ~/.ssh/rpi2.pub Host rpi2-nfs Hostname 192.168.11.220 User root IdentityFile ~/.ssh/rpi2-nfs.pub A continuaci\u00f3n nos centraremos con las configuraciones que debemos realizar para preprar nuestro cl\u00faster. En primer lugar configurar el fichero /etc/hosts de cada una de las placas y a\u00f1adir todos los nodos que conforman el cl\u00faster. 192.168.11.200 rpi4.local 192.168.11.205 rpi2.local 192.168.11.206 rpi3-node.local 192.168.11.207 rpi3.local En la distribuciones que cuentan con SELinux es necesario establecerlo en el modo permisivo . Esto se debe a que los contenedores necesitan acceder al sistema de ficheros del anfitri\u00f3n. Establecer SELinux en modo permisivo en la sesi\u00f3n actual. setenforce 0 De igual modo es neceario modificar el fichero SELinux para que se aplique la configuraci\u00f3n de forma permanente. sed -i & #39;s/SELINUX=enforcing$/SELINUX=permissive/&#39; /etc/selinux/config Necesitamos abrir una serie de puertos para diferentes finalidades. Protocolo Puerto Funci\u00f3n Comando TCP 64443 Kubernetes API firewall-cmd --permanent --add-port=6443/tcp TCP 2379-2380 API del cliente del servidor etcd firewall-cmd --permanent --add-port=2379-2380/tcp TCP 10250 Kubelet API firewall-cmd --permanent --add-port=10250/tcp TCP 10251 Kube-scheduler firewall-cmd --permanent --add-port=10251/tcp TCP 10252 Kube-controller-manager firewall-cmd --permanent --add-port=10252/tcp Despu\u00e9s de configurar los puertos en el firewall es necesario ejecutar los siguientes comandos: #Recargar la configuraci\u00f3n del firewall firewall-cmd --reload #A\u00f1adir el modulo br_netfilter al kernel modprobe br_netfilter #Iptables configuration echo & #39;1&#39; > /proc/sys/net/bridge/bridge-nf-call-iptables #Deshabilitar swap swapoff -a Tanto el comando relacionado tanto con iptables como con swap \u00fanicamente afectan al sistema en ejecuci\u00f3n, por lo que si deseamos que los cambios sean permanentes es necesario realizar varias modificaciones. Fichero /etc/fstab : comentar ( # ) la l\u00ednea que hace referencia a swap. Fichero /etc/sysctl.conf : a\u00f1adir la l\u00ednea net.bridge.bridge-nf-call-iptables=1 . A continuaci\u00f3n procederemos a la instalaci\u00f3n de los paquetes necesarios para el funcionamiento del Nodo Master. Note En la gu\u00eda que podemos encontrar en la web de Kubernetes, nos facilitan los datos del repositorio para la descarga de paquetes. Este repositorio no funciona correctamente en armhfp. La alternativa que tenemos es decargarnos los paquetes manualmente desde este enlace e instalarlos con rpm. Debido a que el repositorio que hemos configurado no funciona correctamente es necesario realizar la instalaci\u00f3n de los paquetes y sus dependencias manualmente. Una vez descargado kubeadm , si ejecutamos el comando rpm -ivh kbueadm.armhfp.rpm nos aparecer\u00e1 el siguiente mensaje: error: Error de dependencias: cri-tools > = 1 .13.0 es necesario por kubeadm-1.18.2-0.armhfp kubectl > = 1 .13.0 es necesario por kubeadm-1.18.2-0.armhfp kubelet > = 1 .13.0 es necesario por kubeadm-1.18.2-0.armhfp kubernetes-cni > = 0 .7.5 es necesario por kubeadm-1.18.2-0.armhfp Vamos a descargarnos los paquetes manualmente. #cri-tools curl -O https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-armhfp/Packages/7a54305aa8552436821a60337683164a50d34fd76ac558dfd2ef529e6e29395e-cri-tools-1.13.0-0.armhfp.rpm Note Ser\u00e1 necesario seguir el mismo procedimiento con el resto de paquetes. Procedemos a instalar los paquetes. #Kubeadm rpm -ivh --ignorearch *.rpm Note La opci\u00f3n --ignorearch es necesaria puesto que los metadatos de los paquetes rpm que hacen referencia a la arquitectura no son correctos. Es posible que nos d\u00e9 alg\u00fan error de dependencias, ser\u00e1 necesario instalar los paquetes que nos indique. Continuamos con la puesta en marcha del sistema, iniciando y habilitando los diferentes servicios necesarios para el correcto funcionamiento de kubernetes. #Docker yum install -y docker systemctl enable docker systemctl start docker #Kubelet systemctl enable kubelet systemctl start kubelet Si comprobamos el estado de kubelet systemctl status kubeletet , es posible que aparezca un error relacionado con cgroup_driver . Para solucionarlos es necesario a\u00f1adir en el fichero /etc/sysconfig/kubelet KUBELET_EXTRA_ARGS=--cgroup-driver=systemd . El siguiente paso ser\u00e1 iniciar kubeadm ejecutando el comando kubeadm init . Si la ejecuci\u00f3n del comando ha sido exitosa veremos la siguiente informaci\u00f3n. Warning Es posible que nos aparezca un error cgroups_memory missing . Para solventar este error es necesario a\u00f1adir cgroup_enable=memory y cgroup_memory=1 en el fichero /boot/cmdline.txt . Siguiendo las indicaciones que podemos ver en la imagen ejecutaremos los comandos que nos indican. mkdir -p $HOME /.kube cp -i /etc/kubernetes/admin.conf $HOME /.kube/config chown $( id -u ) : $( id -g ) $HOME /.kube/config Kubectl es la herramienta de l\u00ednea de comandos (m\u00e1s adelante se estudiar\u00e1 en profundidad) utilizada para controlar Kubernetes. Uno de los primeros comandos que utilizaremos ser\u00e1 para comprobar el estado de los nodos. kubectl get nodes El resultado nos mostrar\u00e1 el/los nodos que tenemos en nuestro cl\u00faster. En el momento de instalaci\u00f3n solo dispon\u00edamos del Nodo Master. NAME STATUS ROLES AGE VERSION rpi4 NotReady master 6h45m v1.18.2 El Nodo Master se encuentra como no disponible , ser\u00e1 necesario seleccionar el modo de gestionar la red de Kubernetes de la lista que podemos encontrar aqu\u00ed . La elegida es Weave Net from Weaveworks puesto que es simple de utilizar y su funcionamiento es fiable. kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version= $( kubectl version | base64 | tr -d & #39;\\n&#39;)\" Para a\u00f1adir nodos a nuestro cl\u00faster ser\u00e1 necesario seguir el proceso que hemos seguido hasta este momento. El \u00fanico comando que no es necesario ejecutar es kubeadm init , que es el comando encargado de crear el cl\u00faster de Kubernetes. Al final del proceso ser\u00e1 necesario a\u00f1adir el nuevo nodo al cl\u00faster ejecutando el comando que hemos visto en la imagen anterior. kubeadm join 192 .168.11.200:6443 --token yk32k7.oc6ezdeidt9w3331 --discovery-token-ca-cert-hash sha256:c3c449377707d7f1a85dad7e67f6ad6de864780430b78107f07b86209abdbe60 Note Si no hemos capturado la informaci\u00f3n que nos mostraba la cli despu\u00e9s de crear el cl\u00faster, podemos obtener la misma informaci\u00f3n ejecutando kubeadm token create --print-join-command .","title":"Kubernetes en Raspberry Pi"},{"location":"Kubernetes/kubernetes-raspberrypi/#desplegando-kubernetes","text":"Actualmente disponemos diferentes formas de desplegar Kubernetes. Basado en la nube , siendo este muy sencillo de configurar y mantener, y basado en m\u00e1quinas f\u00edsicas (bare metal), sistema m\u00e1s complejo de desplegar y mantener. Este proyecto lo llevaremos a cabo en un cl\u00faster con 3 Raspberry Pi , explicando en este apartado los pasos necesarios para desplegar nuestro cl\u00faster de Kubernetes. Comenzaremos haciendo una breve introducci\u00f3n de las primeras configuraciones que debemos realizar para acceder a nuestras Raspberry Pi. Puesto que este proyecto se centra en Kubernetes, no profundizaremos en los pasos que debemos seguir para tener un SO funcionando en una Raspberry Pi. El sistema elegido para cada una de nuestras Raspberry Pi ha sido CentOS 7 , la cual podemos descargar desde este enlace . Ya que el proyecto que realizamos se basa centra en Kubernetes, no profundizaremos sobre los pasos que debemos seguir para instalar y configurar los SO en la Raspberry Pi. Una vez que tenemos la imagen que deseamos (la elegida ha sido la minimal) podemos seguir los pasos para preparar la tarjeta SD y las recomendaciones que nos encontramos en la wiki de CentOS . Partiendo de que ya tenemos las Raspberry Pi funcionando correctamente, vamos a configurar nuestro equipo agregando las llaves y los datos de conexi\u00f3n para facilitar el acceso v\u00eda ssh. Fichero .ssh/config Host rpi4 HostName 192.168.11.200 User root IdentityFile ~/.ssh/rpi4.pub Host rpi2 HostName 192.168.11.205 User root IdentityFile ~/.ssh/rpi2.pub Host rpi2-nfs Hostname 192.168.11.220 User root IdentityFile ~/.ssh/rpi2-nfs.pub A continuaci\u00f3n nos centraremos con las configuraciones que debemos realizar para preprar nuestro cl\u00faster. En primer lugar configurar el fichero /etc/hosts de cada una de las placas y a\u00f1adir todos los nodos que conforman el cl\u00faster. 192.168.11.200 rpi4.local 192.168.11.205 rpi2.local 192.168.11.206 rpi3-node.local 192.168.11.207 rpi3.local En la distribuciones que cuentan con SELinux es necesario establecerlo en el modo permisivo . Esto se debe a que los contenedores necesitan acceder al sistema de ficheros del anfitri\u00f3n. Establecer SELinux en modo permisivo en la sesi\u00f3n actual. setenforce 0 De igual modo es neceario modificar el fichero SELinux para que se aplique la configuraci\u00f3n de forma permanente. sed -i & #39;s/SELINUX=enforcing$/SELINUX=permissive/&#39; /etc/selinux/config Necesitamos abrir una serie de puertos para diferentes finalidades. Protocolo Puerto Funci\u00f3n Comando TCP 64443 Kubernetes API firewall-cmd --permanent --add-port=6443/tcp TCP 2379-2380 API del cliente del servidor etcd firewall-cmd --permanent --add-port=2379-2380/tcp TCP 10250 Kubelet API firewall-cmd --permanent --add-port=10250/tcp TCP 10251 Kube-scheduler firewall-cmd --permanent --add-port=10251/tcp TCP 10252 Kube-controller-manager firewall-cmd --permanent --add-port=10252/tcp Despu\u00e9s de configurar los puertos en el firewall es necesario ejecutar los siguientes comandos: #Recargar la configuraci\u00f3n del firewall firewall-cmd --reload #A\u00f1adir el modulo br_netfilter al kernel modprobe br_netfilter #Iptables configuration echo & #39;1&#39; > /proc/sys/net/bridge/bridge-nf-call-iptables #Deshabilitar swap swapoff -a Tanto el comando relacionado tanto con iptables como con swap \u00fanicamente afectan al sistema en ejecuci\u00f3n, por lo que si deseamos que los cambios sean permanentes es necesario realizar varias modificaciones. Fichero /etc/fstab : comentar ( # ) la l\u00ednea que hace referencia a swap. Fichero /etc/sysctl.conf : a\u00f1adir la l\u00ednea net.bridge.bridge-nf-call-iptables=1 . A continuaci\u00f3n procederemos a la instalaci\u00f3n de los paquetes necesarios para el funcionamiento del Nodo Master. Note En la gu\u00eda que podemos encontrar en la web de Kubernetes, nos facilitan los datos del repositorio para la descarga de paquetes. Este repositorio no funciona correctamente en armhfp. La alternativa que tenemos es decargarnos los paquetes manualmente desde este enlace e instalarlos con rpm. Debido a que el repositorio que hemos configurado no funciona correctamente es necesario realizar la instalaci\u00f3n de los paquetes y sus dependencias manualmente. Una vez descargado kubeadm , si ejecutamos el comando rpm -ivh kbueadm.armhfp.rpm nos aparecer\u00e1 el siguiente mensaje: error: Error de dependencias: cri-tools > = 1 .13.0 es necesario por kubeadm-1.18.2-0.armhfp kubectl > = 1 .13.0 es necesario por kubeadm-1.18.2-0.armhfp kubelet > = 1 .13.0 es necesario por kubeadm-1.18.2-0.armhfp kubernetes-cni > = 0 .7.5 es necesario por kubeadm-1.18.2-0.armhfp Vamos a descargarnos los paquetes manualmente. #cri-tools curl -O https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-armhfp/Packages/7a54305aa8552436821a60337683164a50d34fd76ac558dfd2ef529e6e29395e-cri-tools-1.13.0-0.armhfp.rpm Note Ser\u00e1 necesario seguir el mismo procedimiento con el resto de paquetes. Procedemos a instalar los paquetes. #Kubeadm rpm -ivh --ignorearch *.rpm Note La opci\u00f3n --ignorearch es necesaria puesto que los metadatos de los paquetes rpm que hacen referencia a la arquitectura no son correctos. Es posible que nos d\u00e9 alg\u00fan error de dependencias, ser\u00e1 necesario instalar los paquetes que nos indique. Continuamos con la puesta en marcha del sistema, iniciando y habilitando los diferentes servicios necesarios para el correcto funcionamiento de kubernetes. #Docker yum install -y docker systemctl enable docker systemctl start docker #Kubelet systemctl enable kubelet systemctl start kubelet Si comprobamos el estado de kubelet systemctl status kubeletet , es posible que aparezca un error relacionado con cgroup_driver . Para solucionarlos es necesario a\u00f1adir en el fichero /etc/sysconfig/kubelet KUBELET_EXTRA_ARGS=--cgroup-driver=systemd . El siguiente paso ser\u00e1 iniciar kubeadm ejecutando el comando kubeadm init . Si la ejecuci\u00f3n del comando ha sido exitosa veremos la siguiente informaci\u00f3n. Warning Es posible que nos aparezca un error cgroups_memory missing . Para solventar este error es necesario a\u00f1adir cgroup_enable=memory y cgroup_memory=1 en el fichero /boot/cmdline.txt . Siguiendo las indicaciones que podemos ver en la imagen ejecutaremos los comandos que nos indican. mkdir -p $HOME /.kube cp -i /etc/kubernetes/admin.conf $HOME /.kube/config chown $( id -u ) : $( id -g ) $HOME /.kube/config Kubectl es la herramienta de l\u00ednea de comandos (m\u00e1s adelante se estudiar\u00e1 en profundidad) utilizada para controlar Kubernetes. Uno de los primeros comandos que utilizaremos ser\u00e1 para comprobar el estado de los nodos. kubectl get nodes El resultado nos mostrar\u00e1 el/los nodos que tenemos en nuestro cl\u00faster. En el momento de instalaci\u00f3n solo dispon\u00edamos del Nodo Master. NAME STATUS ROLES AGE VERSION rpi4 NotReady master 6h45m v1.18.2 El Nodo Master se encuentra como no disponible , ser\u00e1 necesario seleccionar el modo de gestionar la red de Kubernetes de la lista que podemos encontrar aqu\u00ed . La elegida es Weave Net from Weaveworks puesto que es simple de utilizar y su funcionamiento es fiable. kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version= $( kubectl version | base64 | tr -d & #39;\\n&#39;)\" Para a\u00f1adir nodos a nuestro cl\u00faster ser\u00e1 necesario seguir el proceso que hemos seguido hasta este momento. El \u00fanico comando que no es necesario ejecutar es kubeadm init , que es el comando encargado de crear el cl\u00faster de Kubernetes. Al final del proceso ser\u00e1 necesario a\u00f1adir el nuevo nodo al cl\u00faster ejecutando el comando que hemos visto en la imagen anterior. kubeadm join 192 .168.11.200:6443 --token yk32k7.oc6ezdeidt9w3331 --discovery-token-ca-cert-hash sha256:c3c449377707d7f1a85dad7e67f6ad6de864780430b78107f07b86209abdbe60 Note Si no hemos capturado la informaci\u00f3n que nos mostraba la cli despu\u00e9s de crear el cl\u00faster, podemos obtener la misma informaci\u00f3n ejecutando kubeadm token create --print-join-command .","title":"Desplegando Kubernetes"},{"location":"Kubernetes/referencias/","text":"Referencias # Awesome-Kubernetes Learning Kubernetes the future of the cloud Kubernetes 101 - The build Building a Kubernetes cluster on Raspberry Pi and low-end equipment - Part 1 10 most common mistakes using kubernetes k8s on Raspbian Learn the Kubernetes Key Concepts Why is Kubernetes getting so popular? Kubernetes NodePort vs LoadBalancer vs Ingress Everything I know about Kubernetes I learned from a cluster of Raspberry Pis Traefik Controller Resoluci\u00f3n de incidencias # Kubelet failed with kubelet cgroup driver Bridge-nf-call-iptables persist across reboot Index of /kubernetes/yum/repos/kubernetes-el7-armhfp/Packages/ Organizar el acceso a los cl\u00fasteres utilizando archivos kubeconfig - Kubernetes Instalar y Configurar kubectl - Kubernetes","title":"Referencias"},{"location":"Kubernetes/referencias/#referencias","text":"Awesome-Kubernetes Learning Kubernetes the future of the cloud Kubernetes 101 - The build Building a Kubernetes cluster on Raspberry Pi and low-end equipment - Part 1 10 most common mistakes using kubernetes k8s on Raspbian Learn the Kubernetes Key Concepts Why is Kubernetes getting so popular? Kubernetes NodePort vs LoadBalancer vs Ingress Everything I know about Kubernetes I learned from a cluster of Raspberry Pis Traefik Controller","title":"Referencias"},{"location":"Kubernetes/referencias/#resolucion-de-incidencias","text":"Kubelet failed with kubelet cgroup driver Bridge-nf-call-iptables persist across reboot Index of /kubernetes/yum/repos/kubernetes-el7-armhfp/Packages/ Organizar el acceso a los cl\u00fasteres utilizando archivos kubeconfig - Kubernetes Instalar y Configurar kubectl - Kubernetes","title":"Resoluci\u00f3n de incidencias"},{"location":"MacOS/personalizando-terminal/","text":"Personalizando el terminal # Powerline es una utilizar que nos permite personalizar nuestra terminal. Las instalaci\u00f3n de esta herramienta es sencilla, aunque necesitaremos el gestor de paquetes pip proporcionado por Python . Instalando python a trav\u00e9s del gestor de paquetes Homebrew brew install python Instalando powerline pip3 install --user powerline-status Para comprobar la ruta donde se ha instalado esta utilidad ejecutaremos el siguiente comando: pip3 show powerline-status Aparecer\u00e1 una serie de informaci\u00f3n, entre ellas una l\u00ednea que comienza por \"Location\" , la cual nos informa de la ruta. Es importante tenerla en cuenta ya que ser\u00e1 necesario para las siguientes configuraciones. Lo siguiente que haremos ser\u00e1 introducirlo en el fichero .bash_profile (es uno de los ficheros utilizados por bash para configurar el etorno del sistema) de nuestro usuario. En caso de que este fichero no se encuentre en nuestro sistema podemos crearlo ejecutando vim .bash_profile . A este archivo le a\u00f1adiremos lo siguiente: #A\u00f1adimos python a la variable PATH export PATH = $PATH : $HOME /Librar/Python/3.7/bin #Habilitamos powerline powerline-daemon -q POWERLINE_BASH_CONTINUATION = 1 POWERLINE_BASH_SELECT = 1 source $HOME /Library/Python/3.7/lib/python/site-packages/powerline/bindings/bash/powerline.sh Copiando la configuraci\u00f3n # Para una edici\u00f3n posterior de los ficheros de configuraci\u00f3n que nos permitir\u00e1n personalizar powerline al extremo, es necesario copiar el directorio config_flies a nuestro $HOME. Para ello ejecutaremos los siguiente comandos: #Creamos el directorio en nuestro $HOME mkdir ~/.config/powerline #Copiamos los ficheros de configuraci\u00f3n cp -R $HOME //Library/Python/3.7/lib/python/site-packages/powerline/config_files/* ~/.config/powerline El siguiente paso ser\u00e1 realizar una modificaci\u00f3n en un fichero de configuraci\u00f3n que se encuentra en la ruta ~/.config/powerline/config.json . Debemos modificar el bloque que hace referencia a la shell , cambiando el tema a default_leftonly . \"shell\" : { \"colorscheme\" : \"default\" , \"theme\" : \"default_leftonly\" , \"local_themes\" : { \"continuation\" : \"continuation\" , \"select\" : \"select\" } Tip \u200b Despu\u00e9s de realizar cambios en los ficheros de configuraci\u00f3n es imprescindible ejecutar el comando powerline-daemon --replace . Instalando las fuentes # # Clonaci\u00f3n del repositorio git clone https://github.com/powerline/fonts.git --depth = 1 # Instalaci\u00f3n de las fuentes cd fonts ./install.sh # Eliminamos el repositorio descargado cd .. rm -rf fonts Como se puede observar en el script de instalaci\u00f3n ( install.sh ), al realizar la instalaci\u00f3n en MacOS las fuentes se almacenan en la ruta $HOME/Library/Fonts . Para que la terminal muestre correctamente los iconos, es necesario cambiar la fuente en la configuraci\u00f3n del terminal a una de las descargadas compatibles con powerline. Powerline-gitstatus # Es un peque\u00f1o \"plugin\" que utilizamos para a\u00f1adir informaci\u00f3n sobre git en el prompt. El listado de informaci\u00f3n que es capaz de mostrar se puede encontrar aqu\u00ed . Podemos utilizar el gestor de paquetes pip para instalarlo. pip install --user powerline-gitstatus Una vez que lo hayamos instalado (podemos comprobarlo ejecutando pip list installed | grep gitstatus ) debemos modificar dos ficheros de configuraci\u00f3n. Esquema de colores : el fichero a modificar se encuentra en la ruta ~/.config/powerline/colorschemes/shell/default.json . { \"groups\" : { \"gitstatus\" : { \"fg\" : \"gray8\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_branch\" : { \"fg\" : \"gray8\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_branch_clean\" : { \"fg\" : \"green\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_branch_dirty\" : { \"fg\" : \"gray8\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_branch_detached\" : { \"fg\" : \"mediumpurple\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_tag\" : { \"fg\" : \"darkcyan\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_behind\" : { \"fg\" : \"gray10\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_ahead\" : { \"fg\" : \"gray10\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_staged\" : { \"fg\" : \"green\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_unmerged\" : { \"fg\" : \"brightred\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_changed\" : { \"fg\" : \"mediumorange\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_untracked\" : { \"fg\" : \"brightestorange\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_stashed\" : { \"fg\" : \"darkblue\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus:divider\" : { \"fg\" : \"gray8\" , \"bg\" : \"gray2\" , \"attrs\" : [] } } } Segmento : el fichero a modificar se encuentra en la ruta ~/.config/powerline/themes/shell/default_leftonly.json . { \"function\" : \"powerline_gitstatus.gitstatus\" , \"priority\" : 40 } Warning \u200b La ruta de los ficheros puede variar. Temas para el terminal # La terminal por defecto de MacOS permite a\u00f1adir importar temas. Los temas pueden ser desarrollados por nosotros o descargados desde internet. Para importar un tema debemos abrir el panel de preferencias de la terminal. Desplegar el men\u00fa de configuraci\u00f3n. Seleccionar la opci\u00f3n Importar: Temas: # Iceberg Solarized Referencias # Documentaci\u00f3n Powerline Shell configuration How to install Powerline to pimp you Bash prompt (for Mac)","title":"Terminal"},{"location":"MacOS/personalizando-terminal/#personalizando-el-terminal","text":"Powerline es una utilizar que nos permite personalizar nuestra terminal. Las instalaci\u00f3n de esta herramienta es sencilla, aunque necesitaremos el gestor de paquetes pip proporcionado por Python . Instalando python a trav\u00e9s del gestor de paquetes Homebrew brew install python Instalando powerline pip3 install --user powerline-status Para comprobar la ruta donde se ha instalado esta utilidad ejecutaremos el siguiente comando: pip3 show powerline-status Aparecer\u00e1 una serie de informaci\u00f3n, entre ellas una l\u00ednea que comienza por \"Location\" , la cual nos informa de la ruta. Es importante tenerla en cuenta ya que ser\u00e1 necesario para las siguientes configuraciones. Lo siguiente que haremos ser\u00e1 introducirlo en el fichero .bash_profile (es uno de los ficheros utilizados por bash para configurar el etorno del sistema) de nuestro usuario. En caso de que este fichero no se encuentre en nuestro sistema podemos crearlo ejecutando vim .bash_profile . A este archivo le a\u00f1adiremos lo siguiente: #A\u00f1adimos python a la variable PATH export PATH = $PATH : $HOME /Librar/Python/3.7/bin #Habilitamos powerline powerline-daemon -q POWERLINE_BASH_CONTINUATION = 1 POWERLINE_BASH_SELECT = 1 source $HOME /Library/Python/3.7/lib/python/site-packages/powerline/bindings/bash/powerline.sh","title":"Personalizando el terminal"},{"location":"MacOS/personalizando-terminal/#copiando-la-configuracion","text":"Para una edici\u00f3n posterior de los ficheros de configuraci\u00f3n que nos permitir\u00e1n personalizar powerline al extremo, es necesario copiar el directorio config_flies a nuestro $HOME. Para ello ejecutaremos los siguiente comandos: #Creamos el directorio en nuestro $HOME mkdir ~/.config/powerline #Copiamos los ficheros de configuraci\u00f3n cp -R $HOME //Library/Python/3.7/lib/python/site-packages/powerline/config_files/* ~/.config/powerline El siguiente paso ser\u00e1 realizar una modificaci\u00f3n en un fichero de configuraci\u00f3n que se encuentra en la ruta ~/.config/powerline/config.json . Debemos modificar el bloque que hace referencia a la shell , cambiando el tema a default_leftonly . \"shell\" : { \"colorscheme\" : \"default\" , \"theme\" : \"default_leftonly\" , \"local_themes\" : { \"continuation\" : \"continuation\" , \"select\" : \"select\" } Tip \u200b Despu\u00e9s de realizar cambios en los ficheros de configuraci\u00f3n es imprescindible ejecutar el comando powerline-daemon --replace .","title":"Copiando la configuraci\u00f3n"},{"location":"MacOS/personalizando-terminal/#instalando-las-fuentes","text":"# Clonaci\u00f3n del repositorio git clone https://github.com/powerline/fonts.git --depth = 1 # Instalaci\u00f3n de las fuentes cd fonts ./install.sh # Eliminamos el repositorio descargado cd .. rm -rf fonts Como se puede observar en el script de instalaci\u00f3n ( install.sh ), al realizar la instalaci\u00f3n en MacOS las fuentes se almacenan en la ruta $HOME/Library/Fonts . Para que la terminal muestre correctamente los iconos, es necesario cambiar la fuente en la configuraci\u00f3n del terminal a una de las descargadas compatibles con powerline.","title":"Instalando las fuentes"},{"location":"MacOS/personalizando-terminal/#powerline-gitstatus","text":"Es un peque\u00f1o \"plugin\" que utilizamos para a\u00f1adir informaci\u00f3n sobre git en el prompt. El listado de informaci\u00f3n que es capaz de mostrar se puede encontrar aqu\u00ed . Podemos utilizar el gestor de paquetes pip para instalarlo. pip install --user powerline-gitstatus Una vez que lo hayamos instalado (podemos comprobarlo ejecutando pip list installed | grep gitstatus ) debemos modificar dos ficheros de configuraci\u00f3n. Esquema de colores : el fichero a modificar se encuentra en la ruta ~/.config/powerline/colorschemes/shell/default.json . { \"groups\" : { \"gitstatus\" : { \"fg\" : \"gray8\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_branch\" : { \"fg\" : \"gray8\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_branch_clean\" : { \"fg\" : \"green\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_branch_dirty\" : { \"fg\" : \"gray8\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_branch_detached\" : { \"fg\" : \"mediumpurple\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_tag\" : { \"fg\" : \"darkcyan\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_behind\" : { \"fg\" : \"gray10\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_ahead\" : { \"fg\" : \"gray10\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_staged\" : { \"fg\" : \"green\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_unmerged\" : { \"fg\" : \"brightred\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_changed\" : { \"fg\" : \"mediumorange\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_untracked\" : { \"fg\" : \"brightestorange\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus_stashed\" : { \"fg\" : \"darkblue\" , \"bg\" : \"gray2\" , \"attrs\" : [] }, \"gitstatus:divider\" : { \"fg\" : \"gray8\" , \"bg\" : \"gray2\" , \"attrs\" : [] } } } Segmento : el fichero a modificar se encuentra en la ruta ~/.config/powerline/themes/shell/default_leftonly.json . { \"function\" : \"powerline_gitstatus.gitstatus\" , \"priority\" : 40 } Warning \u200b La ruta de los ficheros puede variar.","title":"Powerline-gitstatus"},{"location":"MacOS/personalizando-terminal/#temas-para-el-terminal","text":"La terminal por defecto de MacOS permite a\u00f1adir importar temas. Los temas pueden ser desarrollados por nosotros o descargados desde internet. Para importar un tema debemos abrir el panel de preferencias de la terminal. Desplegar el men\u00fa de configuraci\u00f3n. Seleccionar la opci\u00f3n Importar:","title":"Temas para el terminal"},{"location":"MacOS/personalizando-terminal/#temas","text":"Iceberg Solarized","title":"Temas:"},{"location":"MacOS/personalizando-terminal/#referencias","text":"Documentaci\u00f3n Powerline Shell configuration How to install Powerline to pimp you Bash prompt (for Mac)","title":"Referencias"},{"location":"OpenMediaVault/LVM/","text":"Logical Volume Management # LVM es un gestor de vol\u00famenes l\u00f3gicos (Logical Volume Manager) utilizado en Linux. Este sistema de almacenamiento permite establecer una capa l\u00f3gica entre el sistema de archivos y las particiones de los diferentes dispositivos de almacenamiento. Gracias a este sistema se puede combinar diferentes tipos de almacenamiento, como pueden ser particiones, RAID, etc. PV - Volumen f\u00edsico: # Hace referencia al dispositivo de almacenamiento, pudiendo ser un disco duro, una partici\u00f3n, un RAID, es decir, cualquier dispositivo de bloque. Comandos a utilizar: * A\u00f1adiendo un disco completo al volumen f\u00edsico pvcreate /dev/sdX - X ser\u00e1 la letra del disco que queramos a\u00f1adir Mostrando informaci\u00f3n de los vol\u00famenes f\u00edsicos: pvs pvdisplay /dev/sdX - X ser\u00e1 la letra del disco sobre el que queremos obtener la informaci\u00f3n VG - Grupo de vol\u00famenes: # Podr\u00eda considerarse como un disco duro virtual, donde agruparemos los vol\u00famenes f\u00edsicos que consideremos oportunos. Un grupo de vol\u00famenes puede contener un \u00fanico volumen f\u00edsico, pero siempre disponemos la posibilidad de aumentar el tama\u00f1o de un vg a\u00f1adiendo m\u00e1s vol\u00famenes f\u00edsicos a dicho grupo de vol\u00famenes. Comandos a utilizar: Al igual que con los comandos de los vol\u00famenes f\u00edsicos, veremos dos grupos de comandos, uno para crear los grupos de vol\u00famenes y otros para mostrar la informaci\u00f3n. Creando un grupo de vol\u00famenes: vgcreate nombre_del_grupo /dev/sdX Nombre_del_grupo \u2192 podemos establecer el nombre que queramos, aprovecharemos para darle un nombre que le identifique y sea f\u00e1cil reconocer que tipo de datos introduciremos en \u00e9l. /dev/sdX \u2192 ser\u00e1 el dispositivos que identifica al volumen f\u00edsico. Obteniendo informaci\u00f3n de los vol\u00famenes f\u00edsicos: vgs \u200b vgdisplay LV - Volumen l\u00f3gico: # Aqu\u00ed es donde se crearan los sistemas de ficheros, para hacer la analog\u00eda a los discos duros tradicionales, ser\u00eda como una partici\u00f3n. Un volumen l\u00f3gico puede crecer siempre y cuando el grupo de vol\u00famenes al que pertenece disponga de espacio disponible para asign\u00e1rselo. Comandos a utilizar: Al igual que los anteriores veremos comandos que id\u00e9nticas funcionalidades. Creaci\u00f3n de vol\u00famenes l\u00f3gicos: lvcreate -L 500G -n nombre_del_lv nombre_del_vg_perteneciente 1 * - L --> indicamos el tama\u00f1o en Megabytes ( M ), en Gigabytes ( G ), Terabytes ( T ), etc . En la siguiente fotograf\u00eda se puede ver de todas las opciones que disponemos . nombre_del_lv \u2192 elegimos un nombre que identifique al volumen l\u00f3gico. nombre_del_vg_perteneciente \u2192 debemos establecer el nombre del grupo de vol\u00famenes al que va a pertenecer. Obteniendo informaci\u00f3n de los vol\u00famenes l\u00f3gicos: lvdisplay Si queremos saber que vol\u00famenes f\u00edsicos est\u00e1 utilizando nuestro volumen l\u00f3gico debemos ejecutar lvdisplay -m . Una vez llegados hasta aqu\u00ed, tenemos los vol\u00famenes l\u00f3gico en crudo , es decir, nuestro siguiente paso ser\u00e1 crear el sistema de fichero (le otorgaremos ext4) mediante comandos con make file system ( mkfs ) o a trav\u00e9s de la interfaz web de OMV (as\u00ed lo realizaremos). En el panel lateral de OMV seleccionaremos Sistema de Archivos y deberemos pulsar el bot\u00f3n crear que vemos en la siguiente captura. Se abrir\u00e1 una peque\u00f1a ventana donde deeberemos elegir el dispositivo (en este caso ser\u00e1 el volumen l\u00f3gico que hayamos creado), podemos asignarle una etiqueta para identificarlo en la interfaz web de OMV y por \u00faltimo seleccionar el Sistema de Archivo (ext4 como hab\u00edamos comentado). Nos mostrar\u00e1 el proceso, no suele tardar demasiado tiempo. Una vez que termine cerramos la venta y debemos montar la unidad para que este disponible y podamos utilizarla como almacenamiento. Esto tambi\u00e9n lo podemos realizar desde la interfaz web. Debemos seleccionar la unidad que deseamos montar y pulsar el bot\u00f3n de montar tal y como se ve en la siguiente captura. Referencias: LVM para torpes I LVM para torpes II LVM para topres III","title":"Logical Volume Management"},{"location":"OpenMediaVault/LVM/#logical-volume-management","text":"LVM es un gestor de vol\u00famenes l\u00f3gicos (Logical Volume Manager) utilizado en Linux. Este sistema de almacenamiento permite establecer una capa l\u00f3gica entre el sistema de archivos y las particiones de los diferentes dispositivos de almacenamiento. Gracias a este sistema se puede combinar diferentes tipos de almacenamiento, como pueden ser particiones, RAID, etc.","title":"Logical Volume Management"},{"location":"OpenMediaVault/LVM/#pv-volumen-fisico","text":"Hace referencia al dispositivo de almacenamiento, pudiendo ser un disco duro, una partici\u00f3n, un RAID, es decir, cualquier dispositivo de bloque. Comandos a utilizar: * A\u00f1adiendo un disco completo al volumen f\u00edsico pvcreate /dev/sdX - X ser\u00e1 la letra del disco que queramos a\u00f1adir Mostrando informaci\u00f3n de los vol\u00famenes f\u00edsicos: pvs pvdisplay /dev/sdX - X ser\u00e1 la letra del disco sobre el que queremos obtener la informaci\u00f3n","title":"PV - Volumen f\u00edsico:"},{"location":"OpenMediaVault/LVM/#vg-grupo-de-volumenes","text":"Podr\u00eda considerarse como un disco duro virtual, donde agruparemos los vol\u00famenes f\u00edsicos que consideremos oportunos. Un grupo de vol\u00famenes puede contener un \u00fanico volumen f\u00edsico, pero siempre disponemos la posibilidad de aumentar el tama\u00f1o de un vg a\u00f1adiendo m\u00e1s vol\u00famenes f\u00edsicos a dicho grupo de vol\u00famenes. Comandos a utilizar: Al igual que con los comandos de los vol\u00famenes f\u00edsicos, veremos dos grupos de comandos, uno para crear los grupos de vol\u00famenes y otros para mostrar la informaci\u00f3n. Creando un grupo de vol\u00famenes: vgcreate nombre_del_grupo /dev/sdX Nombre_del_grupo \u2192 podemos establecer el nombre que queramos, aprovecharemos para darle un nombre que le identifique y sea f\u00e1cil reconocer que tipo de datos introduciremos en \u00e9l. /dev/sdX \u2192 ser\u00e1 el dispositivos que identifica al volumen f\u00edsico. Obteniendo informaci\u00f3n de los vol\u00famenes f\u00edsicos: vgs \u200b vgdisplay","title":"VG - Grupo de vol\u00famenes:"},{"location":"OpenMediaVault/LVM/#lv-volumen-logico","text":"Aqu\u00ed es donde se crearan los sistemas de ficheros, para hacer la analog\u00eda a los discos duros tradicionales, ser\u00eda como una partici\u00f3n. Un volumen l\u00f3gico puede crecer siempre y cuando el grupo de vol\u00famenes al que pertenece disponga de espacio disponible para asign\u00e1rselo. Comandos a utilizar: Al igual que los anteriores veremos comandos que id\u00e9nticas funcionalidades. Creaci\u00f3n de vol\u00famenes l\u00f3gicos: lvcreate -L 500G -n nombre_del_lv nombre_del_vg_perteneciente 1 * - L --> indicamos el tama\u00f1o en Megabytes ( M ), en Gigabytes ( G ), Terabytes ( T ), etc . En la siguiente fotograf\u00eda se puede ver de todas las opciones que disponemos . nombre_del_lv \u2192 elegimos un nombre que identifique al volumen l\u00f3gico. nombre_del_vg_perteneciente \u2192 debemos establecer el nombre del grupo de vol\u00famenes al que va a pertenecer. Obteniendo informaci\u00f3n de los vol\u00famenes l\u00f3gicos: lvdisplay Si queremos saber que vol\u00famenes f\u00edsicos est\u00e1 utilizando nuestro volumen l\u00f3gico debemos ejecutar lvdisplay -m . Una vez llegados hasta aqu\u00ed, tenemos los vol\u00famenes l\u00f3gico en crudo , es decir, nuestro siguiente paso ser\u00e1 crear el sistema de fichero (le otorgaremos ext4) mediante comandos con make file system ( mkfs ) o a trav\u00e9s de la interfaz web de OMV (as\u00ed lo realizaremos). En el panel lateral de OMV seleccionaremos Sistema de Archivos y deberemos pulsar el bot\u00f3n crear que vemos en la siguiente captura. Se abrir\u00e1 una peque\u00f1a ventana donde deeberemos elegir el dispositivo (en este caso ser\u00e1 el volumen l\u00f3gico que hayamos creado), podemos asignarle una etiqueta para identificarlo en la interfaz web de OMV y por \u00faltimo seleccionar el Sistema de Archivo (ext4 como hab\u00edamos comentado). Nos mostrar\u00e1 el proceso, no suele tardar demasiado tiempo. Una vez que termine cerramos la venta y debemos montar la unidad para que este disponible y podamos utilizarla como almacenamiento. Esto tambi\u00e9n lo podemos realizar desde la interfaz web. Debemos seleccionar la unidad que deseamos montar y pulsar el bot\u00f3n de montar tal y como se ve en la siguiente captura. Referencias: LVM para torpes I LVM para torpes II LVM para topres III","title":"LV - Volumen l\u00f3gico:"},{"location":"OpenMediaVault/Politica-actualizaciones/","text":"Cron-apt # Es el gestor que se encuentra en OMV para la gesti\u00f3n de paquetes y actualizaciones del sistema. Esta herramienta permite automatizar la ejecuci\u00f3n de varios comandos de apt-get para mantener elsistema actualizado. Una vez descargado el programa ejecutando apt-get install cron-apt (para otras distribuciones consultar la gu\u00eda de instalaci\u00f3n) hay varios ficheros a tener en cuenta. En el directorio /etc/cron-apt/config.d/ no se encuentra ning\u00fan fichero por defecto. Fichero config que se encuentra en la ruta /etc/cron-apt/ # When to send email about the cron-apt results. # Value: error (send mail on error runs) # upgrade (when packages are upgraded) # changes (mail when change in output from an action) # output (send mail when output is generated) # always (always send mail) # (else never send mail) MAILON = \"upgrade\" # Value: error (syslog on error runs) # upgrade (when packages is upgraded) # changes (syslog when change in output from an action) # output (syslog when output is generated) # always (always syslog) # (else never syslog) SYSLOGON = \"always\" OPTIONS = \"-o Acquire::http::Dl-Limit=25\" Dos ficheros que se encuentran en el directorio /etc/cron-apt/action.d/ . Los dos ficheros son los siguientes: 0-update: 3-download: Con las l\u00edneas que se encuentran en estos dos ficheros se realizar\u00e1 una actualizaci\u00f3n de la lista local de paquetes, descargar\u00e1 los paquetes para los que se encuentre una versi\u00f3n m\u00e1s actual, pero no realizar\u00e1 la instalaci\u00f3n de estos. Respondiendo al fichero de configuraci\u00f3n, enviar\u00e1 un email a la cuenta configurada para la recepci\u00f3n de estos. Cuando instalamos esta herramienta se a\u00f1ade autom\u00e1ticamente un fichero al directorio /etc/cron.d/ llamada cron-apt que contiene los comandos que ejecutar\u00e1 cron. Como veremos en el script, cron-apt se ejecuta todas las noches a las 4 de la ma\u00f1ana. # Regular cron jobs for the cron-apt package # # Every night at 4 o'clock. 0 4 * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt # Every hour. # 0 * * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt /etc/cron-apt/config2 # Every five minutes. # */5 * * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt /etc/cron-apt/config2 En Openmediavault cuando generamos una tarea desde la interfaz web, este es a\u00f1adido en la ruta /etc/cron.d/openmediavault-userdefined . El contenido de este fichero se muestra del siguiente modo: SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin # m h dom mon dow user command @daily root /var/lib/openmediavault/cron.d/userdefined-e68e3a58-58b9-49e4-92c4-aed639dbe2c1 | mail -E -s \"Cron - Rclone copy\" -a \"From: Cron Daemon <root>\" root >/dev/null 2 > & 1 Adem\u00e1s del directorio cron.d , podemos encontrarnos los directorios cron.daily , cron.hourly , cron.monthly y cron.weekly , que almacena los scripts en funci\u00f3n de la frecuencia con la que se ejecutar\u00e1n. El fichero /etc/crontab contiene las referencias a los directiorios mencionado en el p\u00e1rrafo anterior. Este fichero contiene las siguientes l\u00edneas: # /etc/crontab: system-wide crontab # Unlike any other crontab you don't have to run the `crontab' # command to install the new version when you edit this file # and files in /etc/cron.d. These files also have username fields, # that none of the other crontabs do. SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin # m h dom mon dow user command 17 * * * * root cd / && run-parts --report /etc/cron.hourly 25 6 * * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily ) 47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly ) 52 6 1 * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly ) \u00bfCu\u00e1l es su funcionamiento? # Este fichero env\u00eda una orden con el comando run-parts para que los scripts que se encuentren en el directorio hourly se ejecuten en el minuto 17 de cada hora. A su vez, con el resto de directorios, antes de enviar la orden con run-parts comprueba si anacron tiene permisos de ejecuci\u00f3n. Para ello utiliza el operador l\u00f3gico OR ( || ). Puesto que en el sistema anacron se encuentra con los permisos de ejecuci\u00f3n, cron no realizar\u00e1 ninguna tarea con los scripts que se encuentren en los directorios daily , weekly y monthly . Esta tarea la realizar\u00e1 anacron como veremos explicado en el pr\u00f3ximo apartado ( Anacron ). Es necesario que el servicio crond se encargue del directorio hourly ya que anacron s\u00f3lo puede ejecutar como m\u00e1ximo una tarea diaria. Anacron # Este servicio es ejecutado al inicio del sistema. Es un complemento a cron ya que permite comprobar si alguna tarea que se le haya especificado no ha sido ejecutado, y en tal caso la ejecutar\u00e1. El fichero anacrontab que nos encontramos en OpenMediaVault es el siguiente: # /etc/anacrontab: configuration file for anacron # See anacron(8) and anacrontab(5) for details. SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin HOME = /root LOGNAME = root # These replace cron's entries 1 5 cron.daily run-parts --report /etc/cron.daily 7 10 cron.weekly run-parts --report /etc/cron.weekly @monthly 15 cron.monthly run-parts --report /etc/cron.monthly Este fichero ejecutar\u00e1 todos los scripts que se encuentren en los directorios cron.daily , cron.weekly y cron.monthly . Los valores que vemos en cada l\u00ednea expresan lo siguiente: Primera columna: period in days \u2014 frequency of job execution in days The property value can be defined as an integer or a macro ( @daily , @weekly , @monthly ), where @daily denotes the same value as integer 1, @weekly the same as 7, and @monthly specifies that the job is run once a month regarless of the length of the month. Segunda columna: delay in minutes , n\u00famero de minutos que anacron espera hasta ejecutar el comando. Tercera columna: job identifier es un nombre que identifica a la tarea que se est\u00e1 ejecutando, es \u00fatil para cuando se analicen logs. Cuarta columna: el comando a ejecutar. Anacron se basa en el timestamp para saber si la tarea no ha sido ejecutada y en tal caso ejecutarla. De ah\u00ed que en los directorios daily , monthly y weekly haya un fichero llamado 0anacron , siendo el script que actualizar\u00e1 las marcas de tiempo ( timestamp ). Script timestamp: # #!/bin/sh # # anacron's cron script # # This script updates anacron time stamps. It is called through run-parts # either by anacron itself or by cron. # # The script is called \"0anacron\" to assure that it will be executed # _before_ all other scripts. test -x /usr/sbin/anacron || exit 0 anacron -u cron.daily","title":"Pol\u00edticas de actualizaciones"},{"location":"OpenMediaVault/Politica-actualizaciones/#cron-apt","text":"Es el gestor que se encuentra en OMV para la gesti\u00f3n de paquetes y actualizaciones del sistema. Esta herramienta permite automatizar la ejecuci\u00f3n de varios comandos de apt-get para mantener elsistema actualizado. Una vez descargado el programa ejecutando apt-get install cron-apt (para otras distribuciones consultar la gu\u00eda de instalaci\u00f3n) hay varios ficheros a tener en cuenta. En el directorio /etc/cron-apt/config.d/ no se encuentra ning\u00fan fichero por defecto. Fichero config que se encuentra en la ruta /etc/cron-apt/ # When to send email about the cron-apt results. # Value: error (send mail on error runs) # upgrade (when packages are upgraded) # changes (mail when change in output from an action) # output (send mail when output is generated) # always (always send mail) # (else never send mail) MAILON = \"upgrade\" # Value: error (syslog on error runs) # upgrade (when packages is upgraded) # changes (syslog when change in output from an action) # output (syslog when output is generated) # always (always syslog) # (else never syslog) SYSLOGON = \"always\" OPTIONS = \"-o Acquire::http::Dl-Limit=25\" Dos ficheros que se encuentran en el directorio /etc/cron-apt/action.d/ . Los dos ficheros son los siguientes: 0-update: 3-download: Con las l\u00edneas que se encuentran en estos dos ficheros se realizar\u00e1 una actualizaci\u00f3n de la lista local de paquetes, descargar\u00e1 los paquetes para los que se encuentre una versi\u00f3n m\u00e1s actual, pero no realizar\u00e1 la instalaci\u00f3n de estos. Respondiendo al fichero de configuraci\u00f3n, enviar\u00e1 un email a la cuenta configurada para la recepci\u00f3n de estos. Cuando instalamos esta herramienta se a\u00f1ade autom\u00e1ticamente un fichero al directorio /etc/cron.d/ llamada cron-apt que contiene los comandos que ejecutar\u00e1 cron. Como veremos en el script, cron-apt se ejecuta todas las noches a las 4 de la ma\u00f1ana. # Regular cron jobs for the cron-apt package # # Every night at 4 o'clock. 0 4 * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt # Every hour. # 0 * * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt /etc/cron-apt/config2 # Every five minutes. # */5 * * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt /etc/cron-apt/config2 En Openmediavault cuando generamos una tarea desde la interfaz web, este es a\u00f1adido en la ruta /etc/cron.d/openmediavault-userdefined . El contenido de este fichero se muestra del siguiente modo: SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin # m h dom mon dow user command @daily root /var/lib/openmediavault/cron.d/userdefined-e68e3a58-58b9-49e4-92c4-aed639dbe2c1 | mail -E -s \"Cron - Rclone copy\" -a \"From: Cron Daemon <root>\" root >/dev/null 2 > & 1 Adem\u00e1s del directorio cron.d , podemos encontrarnos los directorios cron.daily , cron.hourly , cron.monthly y cron.weekly , que almacena los scripts en funci\u00f3n de la frecuencia con la que se ejecutar\u00e1n. El fichero /etc/crontab contiene las referencias a los directiorios mencionado en el p\u00e1rrafo anterior. Este fichero contiene las siguientes l\u00edneas: # /etc/crontab: system-wide crontab # Unlike any other crontab you don't have to run the `crontab' # command to install the new version when you edit this file # and files in /etc/cron.d. These files also have username fields, # that none of the other crontabs do. SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin # m h dom mon dow user command 17 * * * * root cd / && run-parts --report /etc/cron.hourly 25 6 * * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily ) 47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly ) 52 6 1 * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )","title":"Cron-apt"},{"location":"OpenMediaVault/Politica-actualizaciones/#cual-es-su-funcionamiento","text":"Este fichero env\u00eda una orden con el comando run-parts para que los scripts que se encuentren en el directorio hourly se ejecuten en el minuto 17 de cada hora. A su vez, con el resto de directorios, antes de enviar la orden con run-parts comprueba si anacron tiene permisos de ejecuci\u00f3n. Para ello utiliza el operador l\u00f3gico OR ( || ). Puesto que en el sistema anacron se encuentra con los permisos de ejecuci\u00f3n, cron no realizar\u00e1 ninguna tarea con los scripts que se encuentren en los directorios daily , weekly y monthly . Esta tarea la realizar\u00e1 anacron como veremos explicado en el pr\u00f3ximo apartado ( Anacron ). Es necesario que el servicio crond se encargue del directorio hourly ya que anacron s\u00f3lo puede ejecutar como m\u00e1ximo una tarea diaria.","title":"\u00bfCu\u00e1l es su funcionamiento?"},{"location":"OpenMediaVault/Politica-actualizaciones/#anacron","text":"Este servicio es ejecutado al inicio del sistema. Es un complemento a cron ya que permite comprobar si alguna tarea que se le haya especificado no ha sido ejecutado, y en tal caso la ejecutar\u00e1. El fichero anacrontab que nos encontramos en OpenMediaVault es el siguiente: # /etc/anacrontab: configuration file for anacron # See anacron(8) and anacrontab(5) for details. SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin HOME = /root LOGNAME = root # These replace cron's entries 1 5 cron.daily run-parts --report /etc/cron.daily 7 10 cron.weekly run-parts --report /etc/cron.weekly @monthly 15 cron.monthly run-parts --report /etc/cron.monthly Este fichero ejecutar\u00e1 todos los scripts que se encuentren en los directorios cron.daily , cron.weekly y cron.monthly . Los valores que vemos en cada l\u00ednea expresan lo siguiente: Primera columna: period in days \u2014 frequency of job execution in days The property value can be defined as an integer or a macro ( @daily , @weekly , @monthly ), where @daily denotes the same value as integer 1, @weekly the same as 7, and @monthly specifies that the job is run once a month regarless of the length of the month. Segunda columna: delay in minutes , n\u00famero de minutos que anacron espera hasta ejecutar el comando. Tercera columna: job identifier es un nombre que identifica a la tarea que se est\u00e1 ejecutando, es \u00fatil para cuando se analicen logs. Cuarta columna: el comando a ejecutar. Anacron se basa en el timestamp para saber si la tarea no ha sido ejecutada y en tal caso ejecutarla. De ah\u00ed que en los directorios daily , monthly y weekly haya un fichero llamado 0anacron , siendo el script que actualizar\u00e1 las marcas de tiempo ( timestamp ).","title":"Anacron"},{"location":"OpenMediaVault/Politica-actualizaciones/#script-timestamp","text":"#!/bin/sh # # anacron's cron script # # This script updates anacron time stamps. It is called through run-parts # either by anacron itself or by cron. # # The script is called \"0anacron\" to assure that it will be executed # _before_ all other scripts. test -x /usr/sbin/anacron || exit 0 anacron -u cron.daily","title":"Script timestamp:"},{"location":"OpenMediaVault/Rclone/","text":"Rclone in OMV # En esta peque\u00f1a gu\u00eda voy a mostrar la configuraci\u00f3n de Rclone con Google Drive. Se puede utilizar con muchos m\u00e1s servicios. Consultar aqu\u00ed La instalaci\u00f3n es muy sencilla, en esta web podemos ver la instalaci\u00f3n tanto para Linux como para MacOS. Podemos optar por llamar a un script que realizar\u00e1 todo el proceso de instalaci\u00f3n, o descargarnos un fichero .zip que descomprimiremos e instalaremos. Instalaci\u00f3n: # Me he percatado que siguiendo la gu\u00eda de instalaci\u00f3n sobre Linux, no descarga la \u00faltima versi\u00f3n. Para evitar esto, y descargar la \u00faltima versi\u00f3n, iremos a este enlace y copiaremos la direcci\u00f3n del fichero .zip que corresponde con nuestra m\u00e1quina. No s\u00e9 si ya lo he comentado, pero la instalaci\u00f3n que estoy realizando es sobre OpenMediaVault que es un sistema orientado a NAS. Tal y como dicen sus desarrolladores est\u00e1 orientado a utilizar la interfaz web y no la \"cli\" (Command line interface). Es por ello que ir\u00e9 comprobando que los binarios correspondientes a los comandos que debo ejecutar se encuentran instalados en el sistema. Para ello ejecutar\u00e9 apt list --installed | grep nombre_del_binario . A continuaci\u00f3n pegar\u00e9 de la web oficial los comandos necesarios para su instalaci\u00f3n: Descarga del fichero .zip y descompresi\u00f3n. curl -O https://downloads.rclone.org/v1.47.0/rclone-v1.47.0-linux-amd64.zip unzip rclone-v1.47.0-linux-amd64.zip cd rclone-v1.47.0-linux-amd64 Como comentaba, la ruta que debemos poner es la que corresponde a la \u00faltima versi\u00f3n de Rclone Trasladar el binario rclone . sudo cp rclone /usr/bin/ sudo chown root:root /usr/bin/rclone sudo chmod 755 /usr/bin/rclone La ruta /usr/bin se encuentra en el PATH, que es la variable que contiene las rutas a los directorios que contienen los ficheros ejecutables. De ese modo podremos ejecutar Rclone sin importar en que directorio del sistema nos encontremos. A\u00f1adiendo el manual de rclone a la base de datos de manuales. sudo mkdir -p /usr/local/share/man/man1 sudo cp rclone.1 /usr/local/share/man/man1/ sudo mandb Copiamos el manual y actualizamos la base de datos de los manuales para que podamos invocar el \"man page\" ejecutando man rclone Configuraci\u00f3n: # La configuraci\u00f3n es muy sencilla ya que el propia sistema nos gu\u00eda una vez que ejecutamos rclone config . Cuando ejecutamos este comando los aparecer\u00e1 un peque\u00f1o men\u00fa desde donde crearemos los nuevos servicios remotos (por denominarlos de alg\u00fan modo). La opci\u00f3n para crear es la \" n \", que una vez seleccionada esta opci\u00f3n nos aparecer\u00e1 en el prompt para asignarle un nombre, y a continuaci\u00f3n debemos elegir que servicio queremos configurar. En mi caso he seleccionado Google Drive que es la opci\u00f3n n\u00famero 12 (quiz\u00e1 pueda variar de el n\u00famero si la versi\u00f3n de Rclone es diferente). Nos aparecer\u00e1n una serie de par\u00e1metros para ir configurando, \u00fanicamente mostrar\u00e9 los que he necesitado configurar, puesto que el resto los he dejado por defecto ya que no necesitaba configurarlos. En uno de los pasos de la configuraci\u00f3n debemos establecer los permisos que le otorgamos, he seleccionado la opci\u00f3n n\u00famero \"1\" que es la m\u00e1s permisiva, ya que tenemos acceso total a todos los contenidos. Otra de las preguntas que nos aparecer\u00e1n a continuaci\u00f3n es si deseamos editar la configuraci\u00f3n avanzada, para nuestro supuesto no es necesario, por lo que seleccionaremos \" n \". La siguiente cuesti\u00f3n a tener en cuenta es si deseamos utilizar la configuraci\u00f3n autom\u00e1tica. Como podemos ver en la explicaci\u00f3n, en el segundo punto nos indica que s\u00ed estamos trabajando en una m\u00e1quina remota (por ejemplo contra nuestro servidor v\u00eda ssh) debemos seleccionar la opci\u00f3n \" n \", que ser\u00e1 la opci\u00f3n que seleccionaremos. Al haber pulsado la opci\u00f3n \" n \" nos mostrar\u00e1 una direcci\u00f3n que debemos copiar y pegar en nuestro navegador. Esta direcci\u00f3n nos solicitar\u00e1 autenticarnos con la cuenta de Google Drive que queremos vincular con Rclone. Una vez que nos autentiquemos nos aparecer\u00e1 un c\u00f3digo que copiaremos y pegaremos en la l\u00ednea que nos solicita Rclone. Antes de finalizar, nos preguntar\u00e1 si deseamos configurar como un Team Drive 1 , no es nuestro caso por lo tanto seleccionaremos \" n \". Nos mostrar\u00e1 un peque\u00f1o resumen con el \" remote \" que hemos configurado. Para finalizar debemos seleccionar con la letra \" q \" (Quit config). Opciones utilizadas: # En la creaci\u00f3n de los Remotes he creado dos id\u00e9nticos, es decir dos de cuentas Google Drive, uno para copiar el contenido, y el otro para sincronizarlo. La diferencia es que con la opci\u00f3n copy quiero evitar que si borro contenido no se elimine de mi servidor, en cambio con la opci\u00f3n sync quiero conseguir que tanto en GD como en mi servidor el contenido sea id\u00e9ntico. Los comandos a ejecutar se introducir\u00e1n en diferentes scripts, que a su vez se incorporar\u00e1n a otro script para que compruebe si el script de rclone sync y rclone copy se est\u00e1n ejecutando, para evitar una nueva ejecuci\u00f3n. Rclone sync (script): #!/bin/bash rclone sync ASIR: /sharedfolders/ASIRDrive -v --log-file = /home/Logs/rclonesync.txt -u --bwlimit 8650k --tpslimit 10 --transfers 15 --exclude Maquinas_Virtuales/ --exclude ISOS/ exit #!/bin/bash #Comprobamos que el script no se est\u00e1 ejecutando mediante pidof if pidof -o %PPID -x sh /home/Scripts/rclonesync.sh ; then exit 1 fi #Despu\u00e9s de comprobar, si no se est\u00e1 ejecutando pasar\u00e1 a ejecutar los siguientes comandos. echo \"Ejecutando rclonesync...\" #Puesto que la ruta de los scripts no se encuentra en la variable PATH es neceario indicarle la ruta completa /home/Scripts/rclonesync.sh echo \"\u00a1La ejecuci\u00f3n del script ha finalizado!\" exit Rclone copy (script): #!/bin/bash rclone copy TzinmDrive:General /sharedfolders/CursosDrive -v --log-file = /home/Logs/rclonecopy.txt -u --bwlimit 8650k --tpslimit 10 -transfers 15 exit #!/bin/bash #Comprobamos que el script no se est\u00e1 ejecutando mediante pidof if pidof -o %PPID -x /home/Scripts/rclonecopy.sh ; then exit 1 fi #Despu\u00e9s de comprobar, si no se est\u00e1 ejecutando pasar\u00e1 a ejecutar los siguientes comandos. echo \"Ejecutando rclonecopy...\" #Puesto que la ruta de los scripts no se encuentra en la variable PATH es neceario indicarle la ruta completa /home/Scripts/rclonecopy.sh echo \"\u00a1La ejecuci\u00f3n del script ha finalizado!\" exit La ruta que he establecido despu\u00e9s de sh puede diferir con la que utilic\u00e9is. Ten\u00e9is que indicar la ruta donde se encuentra vuestro script. Una vez que tenemos los script creados s\u00f3lo quedar\u00e1 a\u00f1adirlos al cron, que podemos aprovecharnos de la interfaz web de OpenMediaVault o a\u00f1adirlos mediante comandos, en ambos casos es muy sencillo. Una vez que hemos creado los Scripts en el directorio de Rclone que hayamos decidido, les daremos permiso de ejecuci\u00f3n para que no sea necesario llamar al comando sh y con poner la ruta completa del script sea suficiente. Esto nos evitar\u00e1 algunos problemas que he visto que surgen con el comando pidof. chmod a+x /home/Scripts/* a+x: otorgamos permisos ejecuci\u00f3n a todos los usuarios. /home/Scripts/*: a todo el contenido que se encuentra en esta ruta. Rclone sync: la siguiente configuraci\u00f3n es sincronizaci\u00f3n cada 30 minutos. Rclone copy: la siguiente configuraci\u00f3n es rclone copy los domingos a la 01:00. En la siguiente captura es como lo ver\u00edamos en nuestra terminal: Ejecuci\u00f3n cron alternativa: # Por la web de Rclone no he visto como poder controlar el tama\u00f1o de los log que se van generando. Ser\u00eda interesante poder eliminar los datos antiguos, es decir establecer un l\u00edmite de por ejemplo 10MB y cuando llegue a ese l\u00edmite que vaya eliminando logs antiguos para poder introducir nuevos logs. Como digo, no he visto forma de hacerlo por lo tanto voy a a\u00f1adir al Cron un comando a ejecutar para que compruebe el tama\u00f1o de los logs y en caso de que supere el tama\u00f1o que nosotros le indiquemos (en mi caso ser\u00e1n 10MB) que realice una acci\u00f3n. find /home/Logs/ -type f -size +10M -exec rm -f {} \\; find: comando utilizado para realizar b\u00fasquedas. /home/Logs/: es la ruta en la que queremos buscar, podemos indicarle la que queramos. La ruta que he marcado es donde se encuentran los Logs de rclone. -type f: es el tipo de fichero que queremos buscar (en linux todo es un fichero), en nuestro caso ser\u00e1 un fichero de tipo file . -size +10M: buscamos fichero mayor de 10 Megabytes. Si delante del 10 indicamos un - buscar\u00e1 ficheros menores a 10 Megabytes. Se puede establecer otras unidades de medida que se encuentran explicadas en el manual de find. -exec: nos permite ejecutar una acci\u00f3n con todo aquello que ha encontrado (en funci\u00f3n de las condiciones que le hemos marcado). rm -f: rm = remove, es decir elimina lo que hemos encontrado, y como estamos seguros de que lo que ha encontrado lo queremos eliminar pasamos el par\u00e1metro -f para que no nos solicite confirmaci\u00f3n. {}: identifica a todo lo que ha encontrado el comando find. \\;: es la finalizaci\u00f3n del comando find cuando utilizamos la opci\u00f3n -excec . Man find Logging: Utilizaremos dos opciones para monitorizar rclone. -v, --verbose : rclone tiene 4 niveles de log, ERROR , AVISO , INFO Y DEBUG . Cuando utilizamos -v , rclone muestra los tres primeros niveles de error. --log-file=FILE : en combinaci\u00f3n con la anterior, todo el log monitorizado lo enviamos a un fichero, que ser\u00e1 el que establecemos despu\u00e9s del s\u00edmbolo = . Bwlimit: --bwlimit : con est\u00e1 opci\u00f3n limitamos el ancho de banda. En nuestro caso la utilizaremos para no ocupar todo el ancho de banda que nos proporciona nuestro ISP. Por la web se puede ver limitaciones de 8650k (Hace referencia a 8650 KBytes, que si hacemos la operaci\u00f3n matem\u00e1tica correspondiente son aproximadamente 750GB diarios, que es el limite para los Team Drive). Seg\u00fan lo que se puede leer por algunas consultas realizadas al soporte de Google, no hay limitaciones, salvo en lo que se refiere a contenido de video (Por ejemplo si queremos utilizar GD para almac\u00e9n del contenido de Plex) y de hosting. Limitaciones de Google: * Files you can store in Google Drive * Team Drive Limits ; After you've uploaded 750 GB to a Team Drive in 1 day, you'll be blocked from uploading additional files that day. However, file uploads already in progress will complete, up to a 5 TB maximum for a single file. Update: -u, --update : con esta opci\u00f3n obligamos a rclone que omita cualquier archivo que tenga una hora de modificaci\u00f3n m\u00e1s reciente en destino que en origen. Adem\u00e1s, si el archivo tiene la misma hora de modificaci\u00f3n en destino como en origen, s\u00f3lo se actualizar\u00e1 si el tama\u00f1o es diferente. Tpslimit: --tpslmit : debido a los baneos de las cuentas de google drive (los baneos son de 24 horas, que es el tiempo que tarde Google en refrescar las estad\u00edsticas , desconozco si los baneos son mayores si el baneo es reiterado). Seg\u00fan lo que he podido leer en varios grupos de telegram y por internet, la cifra m\u00e1s acertada es 8, que son el n\u00famero de peticiones m\u00e1ximas por segundo que har\u00edamos a la API de Google. Transfers : --transfers : es el n\u00famero de transferencias en paralelo que se realizan. Por defecto rclone establece 4 transferencias en paralelo. Puesto que me parece un n\u00famero excesivamente bajo, y aprovechando el ancho de banda que le hemos dados, vamos a elevar el n\u00famero a 15. Exclude: Vamos a utilizar reglas de filtrado, para evitar incluir varios directorios cuando utilicemos la sincronizaci\u00f3n de una de las cuentas. --exclude : podemos utilizarlo de dos modos. 1 2 1. -- exclude nombre_del_fichero 2. -- exclude - nombre_del_fichero \u00bfCu\u00e1l es la diferencia entre ambos? Con la primera opci\u00f3n enumeramos un fichero concreto, en cambio, con la segunda opci\u00f3n llamamos a un fichero que almacena diferente ficheros que queremos excluir. Evitamos tener que enumerar uno a uno los ficheros en el comando completo. Otros comandos \u00fatiles: # Listremotes: nos permite listar todos los remotes que hemos configurado. rclone listremotes List : nos permite listar el contenido. Hay varios comandos que podemos ejecutar que nos mostrar\u00e1n diferentes resultados. #Lista los objetos que se encuentran en REMOTO. rclone ls REMOTO: #Lista los directorios que se encuentra en REMOTO con fecha y hora de creaci\u00f3n. rclone lsd REMOTO: #Lista todo el contenido de la ruta que le indiques, tanto directorios como ficheros. rclone lsf REMOTO: #Lista todo el contenido (ficheros y directorios) incluido lo que se encuentra en todas las subcarpetas. rclone lsl REMOTO: Tree : nos muestra un lista de todo el contenido en forma de \u00e1rbol. (No lo recomiendo utilizar ya que tarda bastante en ejecutarse) . rclone tree REMOTO: Help: nos permite ver diferentes comandos o flags que podemos introducir. rclone --help rclone help flags rclone help backends Donde escribo **REMOTO* es necesario sustituirlo por el nombre de vuestra unidad configurada* Referencias: # Funcionamiento de logging en rclone M\u00e1s filtros de Rclone Google OAuth \u201cinvalid_grant\u201d nightmare\u200a\u2014\u200aand how to fix it Rclone commands Rclone configure \u00bfQu\u00e9 son las unidades de equipos (Team Drive)? \u21a9","title":"Rclone in OMV"},{"location":"OpenMediaVault/Rclone/#rclone-in-omv","text":"En esta peque\u00f1a gu\u00eda voy a mostrar la configuraci\u00f3n de Rclone con Google Drive. Se puede utilizar con muchos m\u00e1s servicios. Consultar aqu\u00ed La instalaci\u00f3n es muy sencilla, en esta web podemos ver la instalaci\u00f3n tanto para Linux como para MacOS. Podemos optar por llamar a un script que realizar\u00e1 todo el proceso de instalaci\u00f3n, o descargarnos un fichero .zip que descomprimiremos e instalaremos.","title":"Rclone in OMV"},{"location":"OpenMediaVault/Rclone/#instalacion","text":"Me he percatado que siguiendo la gu\u00eda de instalaci\u00f3n sobre Linux, no descarga la \u00faltima versi\u00f3n. Para evitar esto, y descargar la \u00faltima versi\u00f3n, iremos a este enlace y copiaremos la direcci\u00f3n del fichero .zip que corresponde con nuestra m\u00e1quina. No s\u00e9 si ya lo he comentado, pero la instalaci\u00f3n que estoy realizando es sobre OpenMediaVault que es un sistema orientado a NAS. Tal y como dicen sus desarrolladores est\u00e1 orientado a utilizar la interfaz web y no la \"cli\" (Command line interface). Es por ello que ir\u00e9 comprobando que los binarios correspondientes a los comandos que debo ejecutar se encuentran instalados en el sistema. Para ello ejecutar\u00e9 apt list --installed | grep nombre_del_binario . A continuaci\u00f3n pegar\u00e9 de la web oficial los comandos necesarios para su instalaci\u00f3n: Descarga del fichero .zip y descompresi\u00f3n. curl -O https://downloads.rclone.org/v1.47.0/rclone-v1.47.0-linux-amd64.zip unzip rclone-v1.47.0-linux-amd64.zip cd rclone-v1.47.0-linux-amd64 Como comentaba, la ruta que debemos poner es la que corresponde a la \u00faltima versi\u00f3n de Rclone Trasladar el binario rclone . sudo cp rclone /usr/bin/ sudo chown root:root /usr/bin/rclone sudo chmod 755 /usr/bin/rclone La ruta /usr/bin se encuentra en el PATH, que es la variable que contiene las rutas a los directorios que contienen los ficheros ejecutables. De ese modo podremos ejecutar Rclone sin importar en que directorio del sistema nos encontremos. A\u00f1adiendo el manual de rclone a la base de datos de manuales. sudo mkdir -p /usr/local/share/man/man1 sudo cp rclone.1 /usr/local/share/man/man1/ sudo mandb Copiamos el manual y actualizamos la base de datos de los manuales para que podamos invocar el \"man page\" ejecutando man rclone","title":"Instalaci\u00f3n:"},{"location":"OpenMediaVault/Rclone/#configuracion","text":"La configuraci\u00f3n es muy sencilla ya que el propia sistema nos gu\u00eda una vez que ejecutamos rclone config . Cuando ejecutamos este comando los aparecer\u00e1 un peque\u00f1o men\u00fa desde donde crearemos los nuevos servicios remotos (por denominarlos de alg\u00fan modo). La opci\u00f3n para crear es la \" n \", que una vez seleccionada esta opci\u00f3n nos aparecer\u00e1 en el prompt para asignarle un nombre, y a continuaci\u00f3n debemos elegir que servicio queremos configurar. En mi caso he seleccionado Google Drive que es la opci\u00f3n n\u00famero 12 (quiz\u00e1 pueda variar de el n\u00famero si la versi\u00f3n de Rclone es diferente). Nos aparecer\u00e1n una serie de par\u00e1metros para ir configurando, \u00fanicamente mostrar\u00e9 los que he necesitado configurar, puesto que el resto los he dejado por defecto ya que no necesitaba configurarlos. En uno de los pasos de la configuraci\u00f3n debemos establecer los permisos que le otorgamos, he seleccionado la opci\u00f3n n\u00famero \"1\" que es la m\u00e1s permisiva, ya que tenemos acceso total a todos los contenidos. Otra de las preguntas que nos aparecer\u00e1n a continuaci\u00f3n es si deseamos editar la configuraci\u00f3n avanzada, para nuestro supuesto no es necesario, por lo que seleccionaremos \" n \". La siguiente cuesti\u00f3n a tener en cuenta es si deseamos utilizar la configuraci\u00f3n autom\u00e1tica. Como podemos ver en la explicaci\u00f3n, en el segundo punto nos indica que s\u00ed estamos trabajando en una m\u00e1quina remota (por ejemplo contra nuestro servidor v\u00eda ssh) debemos seleccionar la opci\u00f3n \" n \", que ser\u00e1 la opci\u00f3n que seleccionaremos. Al haber pulsado la opci\u00f3n \" n \" nos mostrar\u00e1 una direcci\u00f3n que debemos copiar y pegar en nuestro navegador. Esta direcci\u00f3n nos solicitar\u00e1 autenticarnos con la cuenta de Google Drive que queremos vincular con Rclone. Una vez que nos autentiquemos nos aparecer\u00e1 un c\u00f3digo que copiaremos y pegaremos en la l\u00ednea que nos solicita Rclone. Antes de finalizar, nos preguntar\u00e1 si deseamos configurar como un Team Drive 1 , no es nuestro caso por lo tanto seleccionaremos \" n \". Nos mostrar\u00e1 un peque\u00f1o resumen con el \" remote \" que hemos configurado. Para finalizar debemos seleccionar con la letra \" q \" (Quit config).","title":"Configuraci\u00f3n:"},{"location":"OpenMediaVault/Rclone/#opciones-utilizadas","text":"En la creaci\u00f3n de los Remotes he creado dos id\u00e9nticos, es decir dos de cuentas Google Drive, uno para copiar el contenido, y el otro para sincronizarlo. La diferencia es que con la opci\u00f3n copy quiero evitar que si borro contenido no se elimine de mi servidor, en cambio con la opci\u00f3n sync quiero conseguir que tanto en GD como en mi servidor el contenido sea id\u00e9ntico. Los comandos a ejecutar se introducir\u00e1n en diferentes scripts, que a su vez se incorporar\u00e1n a otro script para que compruebe si el script de rclone sync y rclone copy se est\u00e1n ejecutando, para evitar una nueva ejecuci\u00f3n. Rclone sync (script): #!/bin/bash rclone sync ASIR: /sharedfolders/ASIRDrive -v --log-file = /home/Logs/rclonesync.txt -u --bwlimit 8650k --tpslimit 10 --transfers 15 --exclude Maquinas_Virtuales/ --exclude ISOS/ exit #!/bin/bash #Comprobamos que el script no se est\u00e1 ejecutando mediante pidof if pidof -o %PPID -x sh /home/Scripts/rclonesync.sh ; then exit 1 fi #Despu\u00e9s de comprobar, si no se est\u00e1 ejecutando pasar\u00e1 a ejecutar los siguientes comandos. echo \"Ejecutando rclonesync...\" #Puesto que la ruta de los scripts no se encuentra en la variable PATH es neceario indicarle la ruta completa /home/Scripts/rclonesync.sh echo \"\u00a1La ejecuci\u00f3n del script ha finalizado!\" exit Rclone copy (script): #!/bin/bash rclone copy TzinmDrive:General /sharedfolders/CursosDrive -v --log-file = /home/Logs/rclonecopy.txt -u --bwlimit 8650k --tpslimit 10 -transfers 15 exit #!/bin/bash #Comprobamos que el script no se est\u00e1 ejecutando mediante pidof if pidof -o %PPID -x /home/Scripts/rclonecopy.sh ; then exit 1 fi #Despu\u00e9s de comprobar, si no se est\u00e1 ejecutando pasar\u00e1 a ejecutar los siguientes comandos. echo \"Ejecutando rclonecopy...\" #Puesto que la ruta de los scripts no se encuentra en la variable PATH es neceario indicarle la ruta completa /home/Scripts/rclonecopy.sh echo \"\u00a1La ejecuci\u00f3n del script ha finalizado!\" exit La ruta que he establecido despu\u00e9s de sh puede diferir con la que utilic\u00e9is. Ten\u00e9is que indicar la ruta donde se encuentra vuestro script. Una vez que tenemos los script creados s\u00f3lo quedar\u00e1 a\u00f1adirlos al cron, que podemos aprovecharnos de la interfaz web de OpenMediaVault o a\u00f1adirlos mediante comandos, en ambos casos es muy sencillo. Una vez que hemos creado los Scripts en el directorio de Rclone que hayamos decidido, les daremos permiso de ejecuci\u00f3n para que no sea necesario llamar al comando sh y con poner la ruta completa del script sea suficiente. Esto nos evitar\u00e1 algunos problemas que he visto que surgen con el comando pidof. chmod a+x /home/Scripts/* a+x: otorgamos permisos ejecuci\u00f3n a todos los usuarios. /home/Scripts/*: a todo el contenido que se encuentra en esta ruta. Rclone sync: la siguiente configuraci\u00f3n es sincronizaci\u00f3n cada 30 minutos. Rclone copy: la siguiente configuraci\u00f3n es rclone copy los domingos a la 01:00. En la siguiente captura es como lo ver\u00edamos en nuestra terminal:","title":"Opciones utilizadas:"},{"location":"OpenMediaVault/Rclone/#ejecucion-cron-alternativa","text":"Por la web de Rclone no he visto como poder controlar el tama\u00f1o de los log que se van generando. Ser\u00eda interesante poder eliminar los datos antiguos, es decir establecer un l\u00edmite de por ejemplo 10MB y cuando llegue a ese l\u00edmite que vaya eliminando logs antiguos para poder introducir nuevos logs. Como digo, no he visto forma de hacerlo por lo tanto voy a a\u00f1adir al Cron un comando a ejecutar para que compruebe el tama\u00f1o de los logs y en caso de que supere el tama\u00f1o que nosotros le indiquemos (en mi caso ser\u00e1n 10MB) que realice una acci\u00f3n. find /home/Logs/ -type f -size +10M -exec rm -f {} \\; find: comando utilizado para realizar b\u00fasquedas. /home/Logs/: es la ruta en la que queremos buscar, podemos indicarle la que queramos. La ruta que he marcado es donde se encuentran los Logs de rclone. -type f: es el tipo de fichero que queremos buscar (en linux todo es un fichero), en nuestro caso ser\u00e1 un fichero de tipo file . -size +10M: buscamos fichero mayor de 10 Megabytes. Si delante del 10 indicamos un - buscar\u00e1 ficheros menores a 10 Megabytes. Se puede establecer otras unidades de medida que se encuentran explicadas en el manual de find. -exec: nos permite ejecutar una acci\u00f3n con todo aquello que ha encontrado (en funci\u00f3n de las condiciones que le hemos marcado). rm -f: rm = remove, es decir elimina lo que hemos encontrado, y como estamos seguros de que lo que ha encontrado lo queremos eliminar pasamos el par\u00e1metro -f para que no nos solicite confirmaci\u00f3n. {}: identifica a todo lo que ha encontrado el comando find. \\;: es la finalizaci\u00f3n del comando find cuando utilizamos la opci\u00f3n -excec . Man find Logging: Utilizaremos dos opciones para monitorizar rclone. -v, --verbose : rclone tiene 4 niveles de log, ERROR , AVISO , INFO Y DEBUG . Cuando utilizamos -v , rclone muestra los tres primeros niveles de error. --log-file=FILE : en combinaci\u00f3n con la anterior, todo el log monitorizado lo enviamos a un fichero, que ser\u00e1 el que establecemos despu\u00e9s del s\u00edmbolo = . Bwlimit: --bwlimit : con est\u00e1 opci\u00f3n limitamos el ancho de banda. En nuestro caso la utilizaremos para no ocupar todo el ancho de banda que nos proporciona nuestro ISP. Por la web se puede ver limitaciones de 8650k (Hace referencia a 8650 KBytes, que si hacemos la operaci\u00f3n matem\u00e1tica correspondiente son aproximadamente 750GB diarios, que es el limite para los Team Drive). Seg\u00fan lo que se puede leer por algunas consultas realizadas al soporte de Google, no hay limitaciones, salvo en lo que se refiere a contenido de video (Por ejemplo si queremos utilizar GD para almac\u00e9n del contenido de Plex) y de hosting. Limitaciones de Google: * Files you can store in Google Drive * Team Drive Limits ; After you've uploaded 750 GB to a Team Drive in 1 day, you'll be blocked from uploading additional files that day. However, file uploads already in progress will complete, up to a 5 TB maximum for a single file. Update: -u, --update : con esta opci\u00f3n obligamos a rclone que omita cualquier archivo que tenga una hora de modificaci\u00f3n m\u00e1s reciente en destino que en origen. Adem\u00e1s, si el archivo tiene la misma hora de modificaci\u00f3n en destino como en origen, s\u00f3lo se actualizar\u00e1 si el tama\u00f1o es diferente. Tpslimit: --tpslmit : debido a los baneos de las cuentas de google drive (los baneos son de 24 horas, que es el tiempo que tarde Google en refrescar las estad\u00edsticas , desconozco si los baneos son mayores si el baneo es reiterado). Seg\u00fan lo que he podido leer en varios grupos de telegram y por internet, la cifra m\u00e1s acertada es 8, que son el n\u00famero de peticiones m\u00e1ximas por segundo que har\u00edamos a la API de Google. Transfers : --transfers : es el n\u00famero de transferencias en paralelo que se realizan. Por defecto rclone establece 4 transferencias en paralelo. Puesto que me parece un n\u00famero excesivamente bajo, y aprovechando el ancho de banda que le hemos dados, vamos a elevar el n\u00famero a 15. Exclude: Vamos a utilizar reglas de filtrado, para evitar incluir varios directorios cuando utilicemos la sincronizaci\u00f3n de una de las cuentas. --exclude : podemos utilizarlo de dos modos. 1 2 1. -- exclude nombre_del_fichero 2. -- exclude - nombre_del_fichero \u00bfCu\u00e1l es la diferencia entre ambos? Con la primera opci\u00f3n enumeramos un fichero concreto, en cambio, con la segunda opci\u00f3n llamamos a un fichero que almacena diferente ficheros que queremos excluir. Evitamos tener que enumerar uno a uno los ficheros en el comando completo.","title":"Ejecuci\u00f3n cron alternativa:"},{"location":"OpenMediaVault/Rclone/#otros-comandos-utiles","text":"Listremotes: nos permite listar todos los remotes que hemos configurado. rclone listremotes List : nos permite listar el contenido. Hay varios comandos que podemos ejecutar que nos mostrar\u00e1n diferentes resultados. #Lista los objetos que se encuentran en REMOTO. rclone ls REMOTO: #Lista los directorios que se encuentra en REMOTO con fecha y hora de creaci\u00f3n. rclone lsd REMOTO: #Lista todo el contenido de la ruta que le indiques, tanto directorios como ficheros. rclone lsf REMOTO: #Lista todo el contenido (ficheros y directorios) incluido lo que se encuentra en todas las subcarpetas. rclone lsl REMOTO: Tree : nos muestra un lista de todo el contenido en forma de \u00e1rbol. (No lo recomiendo utilizar ya que tarda bastante en ejecutarse) . rclone tree REMOTO: Help: nos permite ver diferentes comandos o flags que podemos introducir. rclone --help rclone help flags rclone help backends Donde escribo **REMOTO* es necesario sustituirlo por el nombre de vuestra unidad configurada*","title":"Otros comandos \u00fatiles:"},{"location":"OpenMediaVault/Rclone/#referencias","text":"Funcionamiento de logging en rclone M\u00e1s filtros de Rclone Google OAuth \u201cinvalid_grant\u201d nightmare\u200a\u2014\u200aand how to fix it Rclone commands Rclone configure \u00bfQu\u00e9 son las unidades de equipos (Team Drive)? \u21a9","title":"Referencias:"}]}