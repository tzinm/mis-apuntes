{"config":{"lang":["es"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home # Este es m\u00ed rinconcito, el lugar donde ir\u00e9 dejando los apuntes sobre algunos de los temas que voy aprendiendo/descubriendo. Cualquier sugerencia es bienvenida , en la parte derecha de las notas de pie de p\u00e1gina se encuentran mis medios de contacto. Docker OpenMediaVault MacOS","title":"Home"},{"location":"#home","text":"Este es m\u00ed rinconcito, el lugar donde ir\u00e9 dejando los apuntes sobre algunos de los temas que voy aprendiendo/descubriendo. Cualquier sugerencia es bienvenida , en la parte derecha de las notas de pie de p\u00e1gina se encuentran mis medios de contacto. Docker OpenMediaVault MacOS","title":"Home"},{"location":"Asus/Custom-DDNS/","text":"Dinamyc DNS # Seg\u00fan la wikipedia, el DNS din\u00e1mico \" es un servicio que permite la actualizaci\u00f3n en tiempo real de la informaci\u00f3n sobre nombres de dominio situada en un servidor de nombres. El uso m\u00e1s com\u00fan que se le da es permitir la asignaci\u00f3n de un nombre de dominio de Internet a un dispositivo con direcci\u00f3n IP variable. \" Habitualmente, el proveedor de internet que tenemos contratado no nos ofrece una direcci\u00f3n ip p\u00fablica fija. Esto quiere decir, que la direcci\u00f3n ip de acceso desde el exterior a nuestra red es variable, y aunque es habitual que esta no var\u00ede en un largo periodo de tiempo, una alternativa es el uso de alg\u00fan servicio de DNS din\u00e1mico. Servicios DNS+ # Hay una larga lista de servicios, hasta hace poco he estado utilizando no-ip , el cual tiene un servicio gratuito de hasta tres nombres de dominio. El inconveniente que tiene es que hay que verificar cada dominio una vez al mes. Por este motivo he comenzado a utilizar Duck DNS , un servicio gratuito que una vez lo hayamos configurado no tenemos que realizar ninguna acci\u00f3n. La configuraci\u00f3n de DuckDNS en el firmware Merlin de Asus no es tan simple como si que lo es el servicio no-ip , es necesario realizar varios pasos que veremos a continuaci\u00f3n para tenerlo configurado correctamente. Habilitar scripts personalizados, esta opci\u00f3n se encuentra en Administraci\u00f3n > Sistema > Enable JFFS custom scripts and configs. Conectarnos v\u00eda ssh (debemos tener habilitada esta opci\u00f3n en el router) y en la ruta /jffs/scripts crear un fichero llamado ddns-start . Este fichero tendr\u00e1 el siguiente contenido: #!/bin/sh # register a subdomain at https://www.duckdns.org/ to get your token SUBDOMAIN = \"subdominio\" #Cambiar por el dominio elegido sin \"duckdns.org\" TOKEN = \"token_duckdns.org\" #Cambiar por el token que nos otorga duckdns # no modification below needed curl --silent \"https://www.duckdns.org/update?domains= $SUBDOMAIN &token= $TOKEN &ip= $1 \" >/dev/null 2 > & 1 if [ $? -eq 0 ] ; then /sbin/ddns_custom_updated 1 else /sbin/ddns_custom_updated 0 fi Cambiar los permisos del fichero para que este se pueda ejecutar chmod +x /jffs/scripts/ddns-start Establecer los par\u00e1metros adecuados en la pesta\u00f1a DDNS del men\u00fa WAN . Aqu\u00ed podemos ver una captura de ejemplo: En la parte inferior tendremos un bot\u00f3n para aplicar cambios . Con esto ya habr\u00edamos configurado duckdns como nuestro servicio de DNS din\u00e1mico. Informaci\u00f3n adicional # En la red disponemos de diversos scripts para utilizar como ddns-start . Dos de los scripts que he probado y funcionan correctamente son los siguientes: Wiki Asuswrt-Merlin - Es el que utilizo puesto que es el que se encuentra en la wiki oficial. Kevinxw","title":"Configurando DuckDNS"},{"location":"Asus/Custom-DDNS/#dinamyc-dns","text":"Seg\u00fan la wikipedia, el DNS din\u00e1mico \" es un servicio que permite la actualizaci\u00f3n en tiempo real de la informaci\u00f3n sobre nombres de dominio situada en un servidor de nombres. El uso m\u00e1s com\u00fan que se le da es permitir la asignaci\u00f3n de un nombre de dominio de Internet a un dispositivo con direcci\u00f3n IP variable. \" Habitualmente, el proveedor de internet que tenemos contratado no nos ofrece una direcci\u00f3n ip p\u00fablica fija. Esto quiere decir, que la direcci\u00f3n ip de acceso desde el exterior a nuestra red es variable, y aunque es habitual que esta no var\u00ede en un largo periodo de tiempo, una alternativa es el uso de alg\u00fan servicio de DNS din\u00e1mico.","title":"Dinamyc DNS"},{"location":"Asus/Custom-DDNS/#servicios-dns","text":"Hay una larga lista de servicios, hasta hace poco he estado utilizando no-ip , el cual tiene un servicio gratuito de hasta tres nombres de dominio. El inconveniente que tiene es que hay que verificar cada dominio una vez al mes. Por este motivo he comenzado a utilizar Duck DNS , un servicio gratuito que una vez lo hayamos configurado no tenemos que realizar ninguna acci\u00f3n. La configuraci\u00f3n de DuckDNS en el firmware Merlin de Asus no es tan simple como si que lo es el servicio no-ip , es necesario realizar varios pasos que veremos a continuaci\u00f3n para tenerlo configurado correctamente. Habilitar scripts personalizados, esta opci\u00f3n se encuentra en Administraci\u00f3n > Sistema > Enable JFFS custom scripts and configs. Conectarnos v\u00eda ssh (debemos tener habilitada esta opci\u00f3n en el router) y en la ruta /jffs/scripts crear un fichero llamado ddns-start . Este fichero tendr\u00e1 el siguiente contenido: #!/bin/sh # register a subdomain at https://www.duckdns.org/ to get your token SUBDOMAIN = \"subdominio\" #Cambiar por el dominio elegido sin \"duckdns.org\" TOKEN = \"token_duckdns.org\" #Cambiar por el token que nos otorga duckdns # no modification below needed curl --silent \"https://www.duckdns.org/update?domains= $SUBDOMAIN &token= $TOKEN &ip= $1 \" >/dev/null 2 > & 1 if [ $? -eq 0 ] ; then /sbin/ddns_custom_updated 1 else /sbin/ddns_custom_updated 0 fi Cambiar los permisos del fichero para que este se pueda ejecutar chmod +x /jffs/scripts/ddns-start Establecer los par\u00e1metros adecuados en la pesta\u00f1a DDNS del men\u00fa WAN . Aqu\u00ed podemos ver una captura de ejemplo: En la parte inferior tendremos un bot\u00f3n para aplicar cambios . Con esto ya habr\u00edamos configurado duckdns como nuestro servicio de DNS din\u00e1mico.","title":"Servicios DNS+"},{"location":"Asus/Custom-DDNS/#informacion-adicional","text":"En la red disponemos de diversos scripts para utilizar como ddns-start . Dos de los scripts que he probado y funcionan correctamente son los siguientes: Wiki Asuswrt-Merlin - Es el que utilizo puesto que es el que se encuentra en la wiki oficial. Kevinxw","title":"Informaci\u00f3n adicional"},{"location":"Docker/Contenedores/","text":"Introducci\u00f3n # En este apartado veremos diferentes im\u00e1genes con las que podremos poner en marcha diferentes contenedores. Docker nos ofrece un repositorio donde podemos encontrar una gran cantidad de imagenes, Docker Hub . Dentro de Docker Hub podemos encontrarnos con una comunidad ( Linuxserver )que se dedica a desarrollar diferentes im\u00e1genes de una gran variedad de servicios. El c\u00f3digo de sus imagenes podemos revisarlo en GitHub . Desde hace alg\u00fan tiempo, la comunidad de Linuxserver ha implementado una forma sencilla de realizar modificaciones a sus imagenes, sin que estas modificaciones alteren la imagen base. Esta funcionalidad la han denominado Docker Mod . En GitHub han dejado una peque\u00f1a gu\u00eda de como realizar dichos mods y adem\u00e1s varios ejemplos, desde una modificaci\u00f3n sencilla hasta modificaciones m\u00e1s complejas. He aprovechado esta nueva funcionalidad y he desarrollado un mod para transmission. https://github.com/tzinm/remove-finished https://hub.docker.com/r/tzinm/remove-finished Im\u00e1genes interesantes # Watchtower # El objetivo de este contenedor es mantener los contenedores actualizados (incluido \u00e9l mismo). Autom\u00e1ticamente ejecutar\u00e1 docker pull para la descarga de la imagen m\u00e1s actual, parar\u00e1 el contenedor en ejecuci\u00f3n y lo iniciar\u00e1 de nuevo con las mismas opciones con las que se hab\u00eda creado inicialmente. Algunas de las opciones que podemos utilizar: Notificaciones: este contenedor permite el env\u00edo de notificaciones a trav\u00e9s de slack y v\u00eda email . He seleccionado el env\u00edo de notificaciones a trav\u00e9s de email, para ello es necesario a\u00f1adir una serie de variables que veremos en el ejemplo m\u00e1s adelante. Respecto a las notificaciones, el nivel de notificaciones por defecto es info , en caso de querer modificarlo es necesario a\u00f1adir la variable WATCHTOWER_NOTIFICATIONS_LEVEL . Contenedores: si no indicamos lo contrario se comprobar\u00e1 y actualizar\u00e1n todos los contenedores. Puesto que mi inter\u00e9s es actualizar \u00fanicamente una serie de contenedores, es necesario indicarle el nombre estos (importante escribirlo correctamente, teniendo en cuenta may\u00fasculas y min\u00fasculas) como argumentos. Programaci\u00f3n: para programar las actualizaciones tenemos dos opciones --interval y --schedule . Interval: se establece un valor en segundos (por defecto son 300 segundos). Schedule: es similar a las expresiones de cron pero con un 6 campos. Por ejemplo --schedule \"0 0 5 * * *\" ejecutar\u00eda las comprobaciones todos los d\u00edas a las 5 de la ma\u00f1ana. Debug mode: estableciendo esta opci\u00f3n el log recoge m\u00e1s informaci\u00f3n. Cleanup : elimina las imagenes antiguas. Ejemplo # docker run -d \\ --name watchtower \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -e WATCHTOWER_NOTIFICATIONS = email \\ -e WATCHTOWER_NOTIFICATION_EMAIL_FROM = fromaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_TO = toaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER = smtp.gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT = 587 \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER = fromaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD = app_password \\ v2tec/watchtower tautulli plex transmission heimdall syncthing watchtower --schedule \"0 0 5 * * *\" --cleanup --debug * P.D.: muchos de los usuarios que utilizamos Docker, utilizamos los contenedores desarrollado por la comunidad LinuxServer. Estos no recomiendan el uso de watchtower par actualizar los contenedores (al menos los desarrollado por ellos), sino que recomiendan varios scripts que podemos encontrar aqu\u00ed para actualizar y realizar backups del estado de los contenedores.","title":"Contenedores de ejemplo"},{"location":"Docker/Contenedores/#introduccion","text":"En este apartado veremos diferentes im\u00e1genes con las que podremos poner en marcha diferentes contenedores. Docker nos ofrece un repositorio donde podemos encontrar una gran cantidad de imagenes, Docker Hub . Dentro de Docker Hub podemos encontrarnos con una comunidad ( Linuxserver )que se dedica a desarrollar diferentes im\u00e1genes de una gran variedad de servicios. El c\u00f3digo de sus imagenes podemos revisarlo en GitHub . Desde hace alg\u00fan tiempo, la comunidad de Linuxserver ha implementado una forma sencilla de realizar modificaciones a sus imagenes, sin que estas modificaciones alteren la imagen base. Esta funcionalidad la han denominado Docker Mod . En GitHub han dejado una peque\u00f1a gu\u00eda de como realizar dichos mods y adem\u00e1s varios ejemplos, desde una modificaci\u00f3n sencilla hasta modificaciones m\u00e1s complejas. He aprovechado esta nueva funcionalidad y he desarrollado un mod para transmission. https://github.com/tzinm/remove-finished https://hub.docker.com/r/tzinm/remove-finished","title":"Introducci\u00f3n"},{"location":"Docker/Contenedores/#imagenes-interesantes","text":"","title":"Im\u00e1genes interesantes"},{"location":"Docker/Contenedores/#watchtower","text":"El objetivo de este contenedor es mantener los contenedores actualizados (incluido \u00e9l mismo). Autom\u00e1ticamente ejecutar\u00e1 docker pull para la descarga de la imagen m\u00e1s actual, parar\u00e1 el contenedor en ejecuci\u00f3n y lo iniciar\u00e1 de nuevo con las mismas opciones con las que se hab\u00eda creado inicialmente. Algunas de las opciones que podemos utilizar: Notificaciones: este contenedor permite el env\u00edo de notificaciones a trav\u00e9s de slack y v\u00eda email . He seleccionado el env\u00edo de notificaciones a trav\u00e9s de email, para ello es necesario a\u00f1adir una serie de variables que veremos en el ejemplo m\u00e1s adelante. Respecto a las notificaciones, el nivel de notificaciones por defecto es info , en caso de querer modificarlo es necesario a\u00f1adir la variable WATCHTOWER_NOTIFICATIONS_LEVEL . Contenedores: si no indicamos lo contrario se comprobar\u00e1 y actualizar\u00e1n todos los contenedores. Puesto que mi inter\u00e9s es actualizar \u00fanicamente una serie de contenedores, es necesario indicarle el nombre estos (importante escribirlo correctamente, teniendo en cuenta may\u00fasculas y min\u00fasculas) como argumentos. Programaci\u00f3n: para programar las actualizaciones tenemos dos opciones --interval y --schedule . Interval: se establece un valor en segundos (por defecto son 300 segundos). Schedule: es similar a las expresiones de cron pero con un 6 campos. Por ejemplo --schedule \"0 0 5 * * *\" ejecutar\u00eda las comprobaciones todos los d\u00edas a las 5 de la ma\u00f1ana. Debug mode: estableciendo esta opci\u00f3n el log recoge m\u00e1s informaci\u00f3n. Cleanup : elimina las imagenes antiguas.","title":"Watchtower"},{"location":"Docker/Contenedores/#ejemplo","text":"docker run -d \\ --name watchtower \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -e WATCHTOWER_NOTIFICATIONS = email \\ -e WATCHTOWER_NOTIFICATION_EMAIL_FROM = fromaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_TO = toaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER = smtp.gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT = 587 \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER = fromaddress@gmail.com \\ -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD = app_password \\ v2tec/watchtower tautulli plex transmission heimdall syncthing watchtower --schedule \"0 0 5 * * *\" --cleanup --debug * P.D.: muchos de los usuarios que utilizamos Docker, utilizamos los contenedores desarrollado por la comunidad LinuxServer. Estos no recomiendan el uso de watchtower par actualizar los contenedores (al menos los desarrollado por ellos), sino que recomiendan varios scripts que podemos encontrar aqu\u00ed para actualizar y realizar backups del estado de los contenedores.","title":"Ejemplo"},{"location":"Docker/Docker/","text":"\u00bfQu\u00e9 es Docker? # Es una herramienta que permite desplegar aplicaciones en contenedores de forma r\u00e1pida y portable. Los t\u00e9rminos que m\u00e1s escucharemos cuando hablamos de Docker ser\u00e1n \" contenedores \" e \" im\u00e1genes \". Docker se encuentra disponible para las principales plataformas, como Windows, Linux o MacOS. La m\u00e1quina que aloja el servicio \" Docker \" se denomina Docker Host . Dentro de Docker podemos destacar tres conceptos. Docker Daemon: representa el servidor de Docker. Rest API: utilizado para la comunicaci\u00f3n bidireccional entre cliente y servidor. Docker CLI (Command Line Interface): representa el cliente de Docker. * A pesar de que se haya mencionado la l\u00ednea de comandos como cliente Docker, tambi\u00e9n existe entorno gr\u00e1fico para interactuar con el servidor Docker. Cuando interactuamos con contenedores o im\u00e1genes, lo hacemos a trav\u00e9s del cliente de Docker, con lo cual nos interesa saber que es lo que podemos gestionar. Im\u00e1genes Contenedores Vol\u00famenes Redes Docker-Compose Seguridad Comandos Otros conceptos Fuentes \u00bfQu\u00e9 es una imagen? # Una imagen en Docker es una especie de instant\u00e1nea de un contenedor. Para entenderlo de una forma m\u00e1s sencilla, desglosaremos una imagen en diferentes capas. Primera capa (FROM): se define el sistema operativo (Alpine, CentOS, Ubuntu), de aqu\u00ed partir\u00e1 el tama\u00f1o m\u00ednimo de nuestra imagen. Segunda capa (RUN): se ejecutan diferentes comandos, habitualmente para la instalaci\u00f3n de paquetes necesarios para nuestra aplicaci\u00f3n. Tercera capa (CMD): es la parte que mantendr\u00e1 en ejecuci\u00f3n el contenedor. Estas capas se definen en el fichero Dockerfile **y son de s\u00f3lo lectura (RO - Read Only). Aqu\u00ed podemos ver un ejemplo de un **Dockerfile . FROM centos:7 RUN yum -y install httpd CMD [ \"apachectl\" , \"-DFOREGROUND\" ] El par\u00e1metro CMD es el que mantiene \" vivo \" el contenedor, en el ejemplo anterior es necesario utilizar como par\u00e1metro -DFOREGROUND del comando apachectl para que el contenedor se mantenga en ejecuci\u00f3n. Note \u00danicamente podemos encontrar una instrucci\u00f3n CMD en un Dockerfile , en caso de que haya m\u00e1s de una, s\u00f3lo se tendr\u00e1 en cuenta la \u00faltima Podemos definir la instrucci\u00f3n CMD de tres modos diferentes: Execform , es la forma m\u00e1s adecuada. CMD [ \"ejecutable\" , \"par\u00e1metro1\" , \"par\u00e1metro2\" ] #Ruta completa al ejecutable. CMD [ \"/bin/echo\" , \"Hola mundo\" ] #Bash como ejecutable, pasando el par\u00e1metro \"-c\" podemos ejecutar comandos como si estuviesemos en la terminal. CMD [ \"/bin/bash\" , \"-c\" , \"echo Hola mundo\" ] Como par\u00e1metros que acompa\u00f1an a la instrucci\u00f3n ENTRYPOINT . CMD [ \"par\u00e1metro1\" , \"par\u00e1metro2\" ] En formato shell , por debajo ejecuta /bin/sh -c . CMD comando par\u00e1metro1 par\u00e1metro2 La diferencia fundamental entre CMD y ENTRYPOINT se basa en que con el primero de ellos, cuando ejecutamos docker run con un comando espec\u00edfico, este comando sobrescribir\u00e1 el comando definido en el fichero Dockerfile . CMD ser\u00e1 el que utilizaremos habitualmente porque nos permite pasar par\u00e1metros cuando iniciemos el contenedor. ENTRYPOINT en caso de querer tener un contenedor como ejecutable, sin intenci\u00f3n de pasar ning\u00fan par\u00e1metro adicional. Descargando im\u00e1genes # Para la descarga de im\u00e1genes utilizaremos el comando docker pull . Es posible pasar diferentes par\u00e1metros, uno de los m\u00e1s habituales es el tag o etiqueta . Esta etiqueta nos permite elegir entre diferentes versiones del mismo contenedor, una imagen compatible con la arquitectura de nuestro procesador o una versi\u00f3n, de la aplicaci\u00f3n empaquetada en la imagen, particular que necesitemos. Ejemplo: #Descarga la versi\u00f3n 3.6.5 de mongo docker pull mongo:3.6.5-jessie En el ejemplo anterior hemos descargado una versi\u00f3n espec\u00edfica indic\u00e1ndole el tag despu\u00e9s de los dos puntos. \u00bfQu\u00e9 es una etiqueta (tag)? # Una etiqueta o tag identifica la imagen que vamos a descargarnos. Es una forma sencilla de versionar las im\u00e1genes. Si no establecemos este par\u00e1metro, la etiqueta por defecto que utilizar\u00e1 Docker es latest . Las etiquetas disponibles por cada imagen se encuentran enumeradas en el propio repositorio, adem\u00e1s en la documentaci\u00f3n se encuentran instrucciones que facilitan la elecci\u00f3n del tag de la imagen. A continuaci\u00f3n se encuentran dos enlaces que explican de forma extendida las etiquetas de las im\u00e1genes de Docker y que formas sencillas hay para versionar una imagen. The misunderstood Docker tag: latest Using Semver for Docker Image Tags Desarrollando im\u00e1genes # La forma sencilla para comenzar ha realizar pruebas es crear un directorio de trabajo que utilizaremos para desarrollar las primeras im\u00e1genes. En este directorio es necesario contar con un fichero Dockerfile (lo podemos crear ejecutando touch Dockerfile ), el cual contendr\u00e1 las capas que hemos visto m\u00e1s arriba. Este fichero es el utilizado por el comando docker build para crear las im\u00e1genes. Note Podemos llamar al fichero Dockerfile de cualquier otro modo, pero cuando creemos el contenedor ( docker build ) deberemos indicarle con el par\u00e1metro -f el nombre del fichero. Dockerfile # \u00bfQu\u00e9 instrucciones nos podemos encontrar dentro de este fichero? COPY : permite copiar un fichero o directorio del host a la imagen. ADD : adem\u00e1s de lo que nos permite realizar la instrucci\u00f3n COPY , esta nos permite pasar una URL para que descargue el contenido en la ruta que indiquemos dentro de la imagen. ENV : se utiliza para a\u00f1adir variables de entorno. La variable se establece sin el signo = , la variable y el valor se define con un espacio entre ambos. Ejemplo: ENV nombre juan WORKDIR : define el directorio de trabajo dentro del contenedor. Si no definimos este par\u00e1metro, por defecto nos encontramos en el directorio ra\u00edz / . EXPOSE : permite exponer puertos. Realmente esta instrucci\u00f3n no realizar ninguna exposici\u00f3n, simplemente informa a la persona que va a utilizar la imagen para crear el contenedor que puertos debe configurar. Estos puertos se expondr\u00e1n utilizando la opci\u00f3n -p del comando docker run . LABEL : hace referencia a una etiqueta, que se utiliza habitualmente para a\u00f1adir metadatos (informaci\u00f3n sobre la imagen como versi\u00f3n, creador, etc.). USER : identifica al usuario que ejecuta las instrucciones definidas en el fichero Dockerfile (las instrucciones que se establezcan a partir de la instrucci\u00f3n user ). Por defecto el usuario que ejecuta las instrucciones es el usuario root . VOLUME : permite que los datos que se encuentran en estos \"vol\u00famenes\" sean persistentes, ya que despu\u00e9s de eliminar el contenedor asociado a este volumen los datos no se perder\u00e1n. CMD : se entiende como la instrucci\u00f3n que mantiene vivo el contenedor. A continuaci\u00f3n veremos un Dockerfile con todas las instrucciones vistas hasta el momento: FROM nginx LABEL version = 1 .0 RUN useradd prueba USER prueba WORKDIR /usr/share/nginx/html COPY web /usr/share/nginx/html ENV variable1 tzinm EXPOSE 90 VOLUME /var/log/nginx CMD nginx -g 'daemon off;' Las instrucciones que definimos dentro de este fichero deben ser lo m\u00e1s estrictas posibles para evitar errores, por ello es importante tener en cuenta lo siguiente: Un servicio por contenedor. Utilizar la capa Labels para a\u00f1adir metadatos. Agrupar los argumentos, evitando crear una capa por cada argumento. Forma correcta RUN \\ python3 -m pip install telegram --upgrade && \\ python3 -m pip install python-telegram-bot --upgrade && \\ chown root:root AddToQbitTorrentFolder.py && \\ chmod 644 AddToQbitTorrentFolder.py Forma incorrecta RUN python3 -m pip install telegram --upgrade RUN python3 -m pip install python-telegram-bot --upgrade RUN chown root:root AddToQbitTorrentFolder.py RUN chmod 644 AddToQbitTorrentFolder.py Evitar la instalaci\u00f3n de paquetes innecesarios, de ese modo crearemos im\u00e1genes m\u00e1s ligeras. Adem\u00e1s del fichero Dockerfile hay otro fichero importante llamado .dockerignore . El funcionamiento de este es similar al fichero .gitignore , es un fichero oculto en el que definimos que contenido del directorio no queremos que sea tenido en cuenta. Docker Build # Una vez que tenemos nuestro Dockerfile terminado debemos ejecutar el comando docker build para crear nuestra imagen. docker build -t tzinm/test . En el comando ejecutado se ha denominado a la imagen tzinm/test , al no haber especificado ning\u00fan tag ser\u00e1 el tag latest el que se haya establecido. Otro dato importante es el punto del final, que hace referencia al contexto , es decir el directorio en el cual Docker buscar\u00e1 los ficheros necesarios para crear la imagen. Multi-Stage Builds # Esta nueva funcionalidad que nos ofrece Docker se encuentra disponible a partir de la versi\u00f3n 17.05. Es una utilidad interesante ya que nos permite crear En ocasiones, algunas im\u00e1genes necesitan cierto contenido que es generado mediante la compilaci\u00f3n o ejecuci\u00f3n de una serie de instrucciones que hace que el peso de una imagen crezca y su rendimiento no est\u00e9 lo m\u00e1s optimizado posible. Es aqu\u00ed cuando esta herramienta ( multi-stage builds ) es \u00fatil, ya que nos permite en una primera instancia crear una imagen \"al vuelo\" en la que generaremos esos ficheros mediante las instrucciones que necesitemos. Despu\u00e9s esos ficheros ser\u00e1n enviados (veremos luego en un ejemplo como se realiza esto) a la segunda imagen, exclusivamente esos ficheros, desprendi\u00e9ndonos de la primera imagen y todo lo que ello conlleva. Recordamos que para hacer un uso adecuado de Docker es necesario optimizar al m\u00e1ximo las im\u00e1genes, es la base de las buenas pr\u00e1cticas. A la hora de crear el fichero Dockerfile es muy similar al que utilizamos construyendo una \u00fanica imagen, salvo que en esta ocasi\u00f3n nos encontramos con la construcci\u00f3n de dos im\u00e1genes - por lo tanto dos FROM - y en la segunda imagen a\u00f1adimos una capa - COPY - con el flag --from=primar-imagen que se encargar\u00e1 de pasar el contenido generado en la primera imagen ( primer FROM ). Se puede ver un poco m\u00e1s claro en el siguiente ejemplo. FROM centos as test RUN fallocate -l 10M /tmp/file1 && \\ fallocate -l 40M /tmp/file2 FROM alpine COPY --from = test /tmp/file1 /tmp/test1 Dangling images # Este concepto hace referencia a im\u00e1genes hu\u00e9rfanas, que no son m\u00e1s que aquellas im\u00e1genes que se encuentran sin referenciar . \u00bfCuando sucede esto? Cuando una imagen es construida utilizando el mismo nombre y tag que otra creada anteriormente. La nueva imagen creada ser\u00e1 v\u00e1lida, en cambio las im\u00e1genes anteriores que existiesen no ser\u00e1n v\u00e1lidas y pasar\u00e1n a tener como nombre y tag el valor \\<none> . A pesar de que estas im\u00e1genes no son v\u00e1lidas, seguir\u00e1n estando en nuestro sistema y ocupando espacio, por ello es recomendable eliminarlas. El modo m\u00e1s r\u00e1pido de eliminar todas estas im\u00e1genes es mediante el siguiente comando: docker rmi $( docker images -f \"dangling=true\" -q ) En el comando anterior hemos utilizado el flag -f , que permite el filtrado de las im\u00e1genes siguiendo una serie de patrones . Contenedores # Un contenedor se entiende como una capa adicional que mantiene en ejecuci\u00f3n las capas que se han definido en el fichero Dockerfile, por este motivo es posible crear tantos contenedores como se deseen a partir de la misma imagen. A diferencia del resto de capas, esta capa es de lectura y escritura ( rw ), por lo tanto nos permite realizar modificaciones sobre las capas anteriores cuando el contenedor se encuentra en ejecuci\u00f3n. Todas estas modificaciones son temporales puesto que no sobrescriben el fichero Dockerfile, por lo tanto una vez que eliminemos el contenedor esas modificaciones se perder\u00e1n (algunas modificaciones pueden ser persistentes mediante el uso de vol\u00famenes que veremos m\u00e1s adelante). \u00bfQu\u00e9 nos encontramos dentro de un contenedor? # Imagen Vol\u00famenes (se utilizan para mantener persistente cierto contenido) Redes (\u00fatil para comunicar contenedores entre s\u00ed) Contenedor VS M\u00e1quina Virtual # El contenedor es un proceso aislado m\u00e1s del sistema, por lo tanto compartir\u00e1 el mismo hardware que est\u00e9 utilizando el sistema operativo anfitri\u00f3n, es decir, no necesitamos asignarle recursos espec\u00edficamente (aunque es posible limitar los recursos utilizados por un contenedor). En cambio, cuando creamos una m\u00e1quina virtual debemos asignarle una serie de recursos, como pueden ser el n\u00famero de nucleos, la memoria ram o el espacio en disco duro. En este caso obtenemos una m\u00e1quina completa dentro del propio sistema anfitri\u00f3n. La principal diferencia que nos podemos encontrar es la ligereza, un contenedor est\u00e1 destinado a ser much\u00edsimo m\u00e1s ligero que una m\u00e1quina virtual, habitualmente un contenedor se utiliza para ejecutar una \u00fanica aplicaci\u00f3n concreta. Docker run # Este comando se utiliza para iniciar los contenedores. Aunque parece evidente, no puede haber dos contenedores con el mismo nombre, aunque uno de ellos se encuentre parado. docker run -d jenkins -p 80 :8080 -d : permite correr un contenedor en segundo plano. jenkins : es el nombre de la imagen utilizada. -p : permite mapear los puertos. El puerto que se encuentra en el lado izquierdo es el que utilizar\u00e1 el sistema anfitri\u00f3n, el puerto de la derecha es el interno del contenedor. -e: asignaci\u00f3n de variables de entorno. En algunas ocasiones si no definimos la capa CMD es posible que el contenedor se muera. Si queremos evitar que esto sucede podemos utilizar los par\u00e1metros -i y -t para interactuar con el contenedor. Limitando recursos # Por defecto Docker utiliza los recursos de la m\u00e1quina anfitriona sin l\u00edmite alguno, a pesar de ello los contenedores consumen muy pocos recursos. Podemos limitar tanto el uso de CPU como de RAM . #Limitando la memoria RAM docker run -d --memory \"100mb\" --name recursos-limitados centos Cuando se muestran las estad\u00edsticas con el comando docker stats ya no mostrar\u00e1 la RAM limite de nuestra m\u00e1quina, sino que los que hayamos establecido, en este caso ser\u00e1n 100MB. Podemos pasar la limitaci\u00f3n en bytes (b), kilobytes (k), megabytes (m) o gigabytes (g). #Limitando el n\u00famero de cores de la CPU docker run -d --cpuset-cpus 0 -3 --name reclimited2 centos Los n\u00facleos (o cores) se pueden definir mediante un rango (como hemos hecho en el ejemplo anterior) o numer\u00e1ndolos y como separaci\u00f3n una coma. 0-2 \u2192 utilizar\u00edamos los n\u00facleos 0, 1 y 2. 0,2 \u2192 utilizar\u00edamos los n\u00facleos 0 y 2. Pol\u00edticas de reinicio # Establecemos que sucede cuando un contenedor se \"apaga\" de forma inesperada. Disponemos de las siguientes opciones: No (es la pol\u00edtica por defecto): el contenedor no se reiniciar\u00e1 autom\u00e1ticamente. Si hacemos una prueba deteniendo cualquier contenedor que tengamos en funcionamiento, veremos que este se detiene y ejecutando el comando docker ps no aparece. Always : con esta opci\u00f3n el contenedor siempre se reiniciar\u00e1. Unless-stopped: se reiniciar\u00e1 siempre, salvo que sea detenido manualmente. On-failure : se reiniciar\u00e1 en caso de que el contenedor se haya detenido por alg\u00fan fallo. La pol\u00edtica de reinicios se establece ejecutando el par\u00e1metro --restart . docker run --restart unless-stopped Vol\u00famenes # Como ya sabemos, si eliminamos un contenedor todos sus datos se eliminar\u00e1n con \u00e9l. Para evitar esto tenemos los vol\u00famenes que nos permiten hacer persistentes algunos datos de nuestros contenedores. Estos datos se almacenan en un directorio de la m\u00e1quina anfitriona. Docker cuenta con tres tipos de vol\u00famenes. Vol\u00famenes Host # En este tipo de vol\u00famenes definimos el directorio donde queremos que se almacene la informaci\u00f3n que debe ser persistente. Es el tipo de vol\u00famenes que m\u00e1s utilizaremos: docker run -v /midirectorio:/directorio-docker Vol\u00famenes Anonymous # Seguimos haciendo persistentes los datos, pero en este caso no definimos donde queremos que se almacene la informaci\u00f3n, sino que Docker genera un directorio aleatorio. docker run -v /directorio-docker Estos directorios se encuentran en una ruta espec\u00edfica bajo el directorio \" ra\u00edz \" del servicio Docker. Para conocer dicho directorio es necesario ejecutar la siguiente instrucci\u00f3n: docker info | grep -i root Entre los diferentes directorio bajo el directorio ra\u00edz de Docker, tenemos un directorio denominado vol\u00famenes, que es el directorio donde se almacenaran estos directorios llamados anonymous . Los directorios anonymous tambi\u00e9n aparecen cuando en un fichero Dockerfile definimos la capa VOLUME pero a la hora de ejecutar el contenedor no definimos ning\u00fan volumen. Esta forma de crear vol\u00famenes no es aconsejable por varios motivos. El nombre que otorga al directorio es aleatorio (habitualmente conformado por n\u00fameros), por lo tanto no ser\u00e1 sencillo saber que volumen se encuentra asociado a cada contenedor. A la hora de eliminar el contenedor si pasamos la opci\u00f3n -v eliminaremos tambi\u00e9n el volumen asociado a este contenedor. Vol\u00famenes Nombrados # Es una mezcla de los dos anteriores. El volumen se almacena en el mismo lugar que los vol\u00famenes anonymous, pero en este caso somos nosotros quienes elegimos un nombre para estos vol\u00famenes en vez de ser un nombre aleatorio. Los siguientes comandos se utilizan para la gesti\u00f3n de vol\u00famenes: Creando un volumen docker volume create nombre_del_volumen Listar los vol\u00famenes docker volume ls Eliminar un volumen docker volume rm nombre_del_volumen Utilizar un volumen nombrado docker run -v nombre_del_volumen:/dockercontainer A diferencia de los vol\u00famenes host, donde debemos indicar la ruta completa del directorio, solo es necesario indicar el nombre del volumen que hayamos creado. Dangling Volumes # Este concepto que hemos visto con los contenedores tambi\u00e9n existe con los vol\u00famenes. Estos aparecen cuando hemos eliminado un contenedor y el volumen asociado a este (volumen anonymous) no se ha eliminado. Para eliminar estos vol\u00famenes podemos hacerlo con la siguiente l\u00ednea de terminal: docker volume ls -f \"dangling=true\" -q | xargs docker volume rm -f / --filtering : flag utilizado para filtrar los vol\u00famenes. dangling : es un filtro booleano que \u00fanicamente permite true o false . **-q **(quiet): imprime el ID que identifica a cada volumen. Con xargs pasamos el resultado a un segundo comando, de ese modo conseguimos eliminar con una \u00fanica l\u00ednea todos los vol\u00famenes. Note Los vol\u00famenes se pueden compartir entre varios contenedores, simplemente es indicar el volumen en el par\u00e1metro correspondiente cuando creemos los contenedores. Puede ser \u00fatil cuando necesitamos que dos contenedores accedan a la informaci\u00f3n que se encuentra en un directorio de nuestra m\u00e1quina. Redes # Cuando levantamos por primera vez el servicio Docker se crea una interfaz virtual llamada docker0 a la cual se le asigna una direcci\u00f3n ip en una subred diferente a la de nuestra red local. Cuando creamos un contenedor nuevo sin pasarle el par\u00e1metro referente a la red , este le asigna una direcci\u00f3n ip correspondiente al rango que nos proporciona la interfaz virtual docker0 . Algunos de los comandos referentes a la red de Docker: Ver la redes disponibles docker network ls Obtener informaci\u00f3n sobre una red docker network inspect nombre_de_red Note Los contenedores que se encuentran en la misma red pueden hacerse ping entre ellos. Creaci\u00f3n de redes # Cuando creamos una red nueva, esta utilizar\u00e1 los drivers bridge (esto se puede cambiar pasando el par\u00e1metro --driver string cuando creamos la nueva red). El comando para la creaci\u00f3n de nuevas redes es el siguiente: docker network create nombre_de_red Docker nos permite especificar ciertas configuraciones a la hora de crear la red como puede ser la direcci\u00f3n de red o la puerta de enlace. Para ver que opciones tenemos podemos ejecutar docker network create --help . docker network create --driver bridge --subnet 172 .16.16.0/24 --gateway 172 .16.16.254 red-prueba Tambi\u00e9n existe la posibilidad de establecer una direcci\u00f3n ip espec\u00edfica a un contenedor, para ello se utiliza el flag --ip . docker run --network nombre_red --ip 192 .168.50.2 -dti --name nombre_contenedor ubuntu Conectando un contenedor a una red diferente # Sabemos que Docker asigna como red por defecto bridge , por lo que si queremos elegir otra red deberemos hacerlo manualmente. La instrucci\u00f3n necesaria para elegir una red diferente a la red por defecto es la siguiente: docker run --network nombre_de_red -dti --name prueba-red ubuntu Note Podemos ejecutar docker inspecto prueba-red para ver las propiedades del contenedor, en las que aparecer\u00e1 la secci\u00f3n NetworkSetting y se podr\u00e1 ver la red asignada a este contenedor. Conectar contenedores a la misma red # En la red por defecto de Docker ( red bridge ) no podemos reconocer a los contenedores por su hostname . En cambio, cuando creamos una red (aunque utilice el driver bridge) es posible la comunicaci\u00f3n entre contenedores a trav\u00e9s de su hostname, esto se debe a que son redes definidas como \" user define network \". Para realizar una prueba de comunicaci\u00f3n entre dos contenedores podemos utilizar el comando ping . Podemos hacer la prueba mediante la direcci\u00f3n ip o mediante el nombre del contenedor. #Direcci\u00f3n ip docker exec nombre_contenedor bash -c \"ping -c 3 ip_contenedor2\" #Hostname docker exec nombre_contenedor bash -c \"ping -c 3 nombre_contenedor2\" Contenedores en m\u00e1s de una red # Los contenedores ya existentes pueden tener configurado m\u00e1s de una red diferente. docker network connect nombre_red nombre_contenedor El comando docker inspect nos permite inspeccionar un contenedor, lo cual permite verificar las diferentes redes configuradas en dicho contenedor, de ese modo podr\u00edamos verificar si se ha a\u00f1adido la nueva red. Al igual que se puede configurar varias redes en un contenedor, tambi\u00e9n podemos eliminar varias redes de los contenedores. docker network disconnect nombre_red nombre_contenedor Eliminar redes # Las redes creadas por un usuario se pueden eliminar, para ello es necesario que ning\u00fan contenedor se encuentre asociado a dicha red. docker network rm nombre_red Tipos de drivers de red # Bridge # En Docker es el driver de red por defecto, sino se espec\u00edfica uno diferente es el driver utilizado por defecto a la hora de crear nuevas redes. Host # Este tipo de driver de red elimina el aislamiento entre el contenedor y la m\u00e1quina anfitriona, por lo tanto utiliza la red que utiliza la m\u00e1quina anfitriona. Es decir, estos contenedores podr\u00e1n recibir una direcci\u00f3n ip de forma din\u00e1mica por parte del servidor DHCP que tengamos configurado en nuestra red local. Overlay # Permite la comunicaci\u00f3n entre diferentes servidores Docker (docker daemons), esto permite que diferentes servicios puedan comunicarse entre si. Macvlan # Permite asignar una direcci\u00f3n MAC a un contenedor, lo cual simula disponer de una tarjeta de red en dicho contenedor. None # Este tipo de driver permite deshabilitar la red en los contenedores. Docker Compose # Es una herramienta que nos ayuda a orquestar contenedores en Docker, gestionar los diferentes contenedores de los que depende una aplicaci\u00f3n. Existen aplicaciones que para su correcto funcionamiento dependen de varios servicios, para seguir con la simplicidad de \" un servicio = un contenedor \", Docker Compose nos permitir\u00e1 administrar los diferentes contenedores de forma grupal. Docker Compose trabaja con ficheros de tipo yaml , en los que se definen los contenedores, vol\u00famenes, redes, etc. Despu\u00e9s de completar el fichero, docker-compose como comando se encarga de la lectura del fichero y lanzar todos los contenedores definidos en dichero fichero. Durante la instalaci\u00f3n de Docker-CE esta herramienta no se instala, por lo que ser\u00e1 necesaria la instalaci\u00f3n de forma independiente. En la documentaci\u00f3n oficial se encuentran diferentes gu\u00edas para la instalaci\u00f3n en los diferentes Sistemas Operativos. En la m\u00e1quina actual, en la que estamos trabajando bajo Linux, la instalaci\u00f3n se har\u00eda del siguiente modo: Descargamos Docker-Compose. sudo curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose Aplicar permisos de ejecuci\u00f3n al ejecutable que hemos descargado. sudo chmod +x /usr/local/bin/docker-compose Comenzando con Docker Compose # El nombre del fichero que debemos utilizar es docker-compose.yml , donde definiremos los diferentes contenedores. Este fichero cuenta con cuatro grandes partes: Version (obligatorio): para saber que n\u00famero de versi\u00f3n (Docker-Compose) debemos establecer, buscamos en la documentaci\u00f3n cual es la \u00faltima versi\u00f3n, suele ser la que se recomienda utilizar. Services (obligatorio): los servicios hacen referencia a los contenedores. En primera instancia definimos los nombres de cada servicio (podemos elegir el que queramos), y debajo de ellos ir\u00e1n los par\u00e1metros que hacen referencia al propio contenedor, como el nombre del contenedor, la imagen a la que hace referencia, puertos, variables de entorno, etc. Volumes (opcional): - Vol\u00famenes nombrados: funcionan del mismo modo que ejecutando docker run . Lo que hacemos es definir en primer lugar el volumen que crear\u00edamos con la instrucci\u00f3n docker volume create en \"volumes\" con el nombre que queramos. A continuaci\u00f3n lo definimos dentro del servicio. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"html:/usr/share/nginx/html\" volumes : html : - Vol\u00famenes host: no necesitamos la parte volumes dentro del fichero docker-compose.yml sino que directamente en el contenedorlo podemos parametrizar. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"/home/miusuario/html:/usr/share/nginx/html\" Networks (opcional): - Red Host: es importante establecer la versi\u00f3n 3.4 para que funcione correctamente . Para que funcione es necesario a\u00f1adir build , y adem\u00e1s a\u00f1adir el contexto , que hace referencia a un directorio que contenga un Dockerfile o una url a un repositorio git. Si establecemos la ruta relativa hace referencia a la ubicaci\u00f3n del archivo de composici\u00f3n. version : '3.4' services : web : build : context : . network : host image : nginx container_name : nginx-prueba ports : - \"8181:80\" - Creaci\u00f3n de una nueva red con subnet. A\u00fan no se permite establecer gateway . version : '3' services : web : image : nginx container_name : nginx-prueba ports : - \"8181:80\" networks : red-prueba : - ipv4_address : 192.168.50.10 networks : red-prueba : ipam : driver : default config : - subnet : \"192.168.50.0/24\" En cuanto a las redes, cuando ejecutamos el comando docker-compose up -d se genera una red espec\u00edfica para docker-compose . Si no definimos una red, la red utilizada ser\u00e1 la red por defecto (docker-compose_default). Cuando se crea la red, el nombre que es otorgado \" directorioactual_nombredelared \". Es posible modificar la parte del nombre que hace referencia al \"directorioactual\", pasando el par\u00e1metro -p . Por lo tanto si nuestro directorio actual se denomina docker-compose y queremos que el prefijo sea por ejemplo dcprueba ejecutar\u00edamos el siguiente comando: #Modificar el nombre de red a \"dcprueba_default\" docker-compose -p dcprueba up -d Por otro lado, tenemos dos partes importantes que se utilizan a la hora de crear contenedores. Variables de entorno: estas se pueden definir de dos modos. Fichero docker-compose.yml environment : - \"VARIABLES1=docker\" Fichero con extensi\u00f3n .env. environment : - variables.env Command: se utiliza para establecer un CMD al contenedor. commmand : mkdir /bin/bash El comando docker-compose se encarga de realizar un proceso similar que el comando docker run , pero en este caso los diferentes par\u00e1metros se encuentran definidos en un fichero. Por lo tanto, las pol\u00edticas de reinicio o la limitaci\u00f3n de recursos tambi\u00e9n se pueden definir. Pol\u00edticas de reinicio: #Reinicio siempre restart : always #Reinicio hasta que lo detengamos de forma manual restart : unless-stopped #\u00danicamente se reinicia el contenedor en caso de que haya habido un fallo restart : on-failure Limitar recursos: #Limitar memoria mem_limit : 20m #Cpu cpuset : \"0\" Otras de las directivas relevantes de este fichero es depends_on , la cual hace referencia a las dependencias que tiene se contenedor respecto a los que se incluyan en esta directiva. version : '3' services : web : image : nginx container_name : nginx-prueba depends_on : db db : image : postgres container_name : nginx-database El \u00faltimo paso ser\u00e1 conocer como podemos eliminar un contenedor creado con la herramienta Docker-Compose. Para ello debemos ejecutar el siguiente comando, situados en el directorio donde se encuentra el fichero yaml . docker-compose down El comando anterior sigue el siguiente proceso: Detiene el contenedor. Elimina el contenedor. Elimina la red que ha creado por defecto. Docker-compose build # Ya conocemos el comando docker build , es el encargado de crear im\u00e1genes. El comando docker-compose build tiene un funcionamiento similar, se encarga de generar una imagen a partir de la definici\u00f3n de build en el fichero yaml . Esta imagen ser\u00e1 utilizada como imagen base en la creaci\u00f3n del contenedor. Para que se construya una imagen, sabemos que necesitamos un fichero Dockerfile , en el cual se encuentran las capas para la construcci\u00f3n de una imagen. En la sentencia build nos encontramos con dos par\u00e1metros importantes. Context: se indica la ruta donde se encuentra el Dockerfile que utilizaremos para crear la imagen. Si se encuentra en el mismo directorio se utilizar\u00e1 el punto ( . ). Dockerfile: el nombre del fichero si este es diferente al nombre por defecto (Dockerfile). version : '3' services : web : container_name : web image : web-test build : context : . dockerfile : Dockerfile1 *Si el nombre que hace referencia al Dockerfile no se ha modificado, podemos obviar estos dos par\u00e1metros. version : '3' services : web : container_name : web image : web-test build : . Seguridad # Este apartado lo he denominado \"seguridad\" porque creo que es donde mejor encajala gesti\u00f3n de los usuarios en Docker. Para profundizar en el tema de seguridad es conveniente revisar la documentaci\u00f3n oficial . Simplificando mucho, sabemos que los contenedores de Docker son procesos para el sistema anfitri\u00f3n, por lo tanto el kernel del sistema es compartido entre todos los contenedores y el propio sistema. Es importante tener en cuenta esto ya que el kernel de Linux es el encargado de gestionar el uid y el gid de los diferentes usuarios, por lo tanto, estos ser\u00e1n compartidos con los contenedores de Docker. Cuando ejecutamos un contenedor, si no se especifica un usuario en la creaci\u00f3n del propio contenedor o en la imagen base del mismo, el uid y gid por defecto ser\u00e1 0 . Este id corresponde al usuario root , el usuario administrador de nuestro sistema. Una buena pr\u00e1ctica para controlar este comportamiento es contar con un usuario espec\u00edfico para Docker, al que se le otorgar\u00e1n los permisos exclusivamente necesarios para que el contenedor que hayamos creado pueda \u00fanicamente realizar la tarea para la que se ha creado. Despu\u00e9s de que hayamos creado el usuario que utilizaremos en los contenedores Docker, podemos obtener los ids que necestiamos (uid y gid) ejecutando el siguiente comando: id usuario-docker Para indicar al contenedor que usuario ser\u00e1 el que ejecute el CMD , se lo indicaremos con el flag -u . docker run -u = \"uid:gid\" Para verlo de una forma m\u00e1s clara, lo trataremos con un ejemplo . Imaginemos que queremos montar una biblioteca multimedia al estilo \"Netflix\" a partir de las pel\u00edculas y series digitales que tenemos en nuestros equipos. Hay diversas herramientas que nos facilitan esto, como por ejemplo Plex , que es una de las m\u00e1s conocidas. Esta biblioteca podemos ponerla en marcha a trav\u00e9s de un contenedor Docker, pero para que funcione correctamente este contenedor necesita acceso a las carpetas donde se encuentra todo nuestro contenido multimedia. Bien, si el usuario del contenedor no es el adecuado el contenedor no ser\u00e1 capaz de leer los directorios donde se encuentra todo el contenido multimedia, y por lo tanto no podr\u00e1 realizar su trabajo y no tendremos nuestra ansiada biblioteca multimedia. Siguiendo con la premisa de un usuario exclusivo para Docker, este usuario deber\u00eda tener acceso a los directorios donde se encuentra todo el contenido multimedia y a su vez, ser el usuario que hemos pasado por par\u00e1metros al contenedor de Plex. Otros conceptos # Docker Registry # Es un servicio donde se alojan las im\u00e1genes que utilizar\u00e1 Docker. A este servicio se realizan peticiones mediante los comandos docker pull (descargar im\u00e1genes) y docker push (subir im\u00e1genes). El registry que utilizamos habitualmente es el propio de Docker, conocido como Docker Hub , del que nos descargamos las im\u00e1genes desarrolladas por la comunidad. Existe la posibilidad de mantener un registry local, podemos seguir la documentaci\u00f3n oficial para tenerlo en funcionamiento. Los siguientes comandos muestran un ejemplo utilizando un registry local. #Renombramos la imagen para que coincida con el nombre del registry, como lo har\u00edamos en docker hub. docker tag hello-world:lastest localhost:5000/hello-world #Subimos la imagen. docker push localhost:5000/hello-world #Descargar la imagen. docker pull localhost:5000/hellos-world Comandos # Comandos m\u00e1s utilizados # Comando Descripci\u00f3n docker images lista las im\u00e1genes que se encuentran descargadas docker build construir una imagen a partir de un fichero Dockerfile docker history listar las capas generadas en una imagen concreta docker run crear un contenedor a partir de una imagen docker rm eliminar un contenedor docker rmi eliminar una o m\u00e1s im\u00e1genes docker ps listar los contenedores docker ps -a listar todos los contenedores docker rename cambiar el nombre de un contenedor (renombrar) docker stop detener un contenedor (se puede utilizar el id o el nombre del contenedor) docker start iniciar un contenedor (se puede utilizar el id o el nombre del contenedor) docker restart reiniciar un contenedor (se puede utilizar el id o el nombre del contenedor) docker logs para mostrar los logs de un contenedor. Con el par\u00e1metro \"-f\" se actualizan los logs en tiempo real docker inspect muestra informaci\u00f3n detallada de como ha sido construido un contenedor docker stats pasando el contenedor a este comando nos muestra cuantos recursos consume dicho contenedor docker system df --verbose muestra informaci\u00f3n detallada sobre el tama\u00f1o de todo el contenido de docker docker volume ls lista los vol\u00famenes de Docker. \u00danicamente lista los que se encuentran bajo el directorio root de Docker docker exec permite ejecutar comandos dentro de un contenedor que est\u00e9 activo docker history imagen muestra como ha sido creado una imagen docker cp copiar archivos entre la m\u00e1quina anfitri\u00f3n y el contenedor, y viceversa docker prune elimina todos los contenedores que se encuentran parados. Antes de eliminarlos se muestra un aviso . Otros comandos # Docker build #Construir una imagen con un nombre de Dockerfile diferente al utilizado por defecto. Para ello se utiliza el par\u00e1metro \"-f\". docker build -t test -f pruebadockerfile . Docker exec #Entrar en la terminal de un contenedor. docker exec -ti nombre_del_contenedor bash #exec: ejecutar #-t: terminal #-i: interactivo #bash: la terminal seleccionada #Se puede establecer el par\u00e1metro \"-u\" para seleccionar un usuario espec\u00edfico. Docker ps #Eliminar todos los contenedores a trav\u00e9s de sus IDs. docker ps -q | xargs docker rm -f #Eliminar todos los contenedores con estados \"exited\". docker ps -a | grep Exit | cut -d ' ' -f 1 | xargs sudo docker rm Docker cp #Copiar ficheros de mi m\u00e1quina a un contenedor y viceversa. docker cp mimaquina.txt test:/home docker cp test:/home/mimaquina.txt . Docker run #Creaci\u00f3n de un contenedor con el par\u00e1metro --rm para que se autoelimine una vez que haya salido de la sesi\u00f3n del contenedor. docker run --rm -ti -name test ubuntu:latest bash Docker rmi #Eliminar imagenes hu\u00e9rfanas docker rmi $( docker images -f \"dangling=true\" -q ) #Eliminar imagenes por fecha. Since (imagenes creadas posteriormente a la imagen pasada en el filtro), Before (imagenes creadas anteriormente a la imagen pasada en el filtro). docker rmi $( docker images -f since = \"images\" -q ) Docker commit #Crear una imagen a partir de un contenedor docker commit nombre-contenedor imagen-nueva Docker history #Visualizar el CMD del contenedor docker history -h nombre-contenedor Fuentes # Docker bases # Docker, de principiante a experto Docker for beginners Cap\u00edtulos Docker atareao.es Docker Tips Docker desde las bases: Comprendiendo imagenes Docker espa\u00f1ol GitHub Docker en profundidad # Docker CMD vs ENTRYPOINT Understanding how uid and gid work in Docker containers Buenas pr\u00e1cticas construyendo im\u00e1genes Docker Eliminar vol\u00famenes hu\u00e9rfanos Dopcker Hub Automated Build Tagging Using Semver for Docker Image Tags Comando para saber los dockers corriendo y sus puertos","title":"Conociendo Docker"},{"location":"Docker/Docker/#que-es-docker","text":"Es una herramienta que permite desplegar aplicaciones en contenedores de forma r\u00e1pida y portable. Los t\u00e9rminos que m\u00e1s escucharemos cuando hablamos de Docker ser\u00e1n \" contenedores \" e \" im\u00e1genes \". Docker se encuentra disponible para las principales plataformas, como Windows, Linux o MacOS. La m\u00e1quina que aloja el servicio \" Docker \" se denomina Docker Host . Dentro de Docker podemos destacar tres conceptos. Docker Daemon: representa el servidor de Docker. Rest API: utilizado para la comunicaci\u00f3n bidireccional entre cliente y servidor. Docker CLI (Command Line Interface): representa el cliente de Docker. * A pesar de que se haya mencionado la l\u00ednea de comandos como cliente Docker, tambi\u00e9n existe entorno gr\u00e1fico para interactuar con el servidor Docker. Cuando interactuamos con contenedores o im\u00e1genes, lo hacemos a trav\u00e9s del cliente de Docker, con lo cual nos interesa saber que es lo que podemos gestionar. Im\u00e1genes Contenedores Vol\u00famenes Redes Docker-Compose Seguridad Comandos Otros conceptos Fuentes","title":"\u00bfQu\u00e9 es Docker?"},{"location":"Docker/Docker/#que-es-una-imagen","text":"Una imagen en Docker es una especie de instant\u00e1nea de un contenedor. Para entenderlo de una forma m\u00e1s sencilla, desglosaremos una imagen en diferentes capas. Primera capa (FROM): se define el sistema operativo (Alpine, CentOS, Ubuntu), de aqu\u00ed partir\u00e1 el tama\u00f1o m\u00ednimo de nuestra imagen. Segunda capa (RUN): se ejecutan diferentes comandos, habitualmente para la instalaci\u00f3n de paquetes necesarios para nuestra aplicaci\u00f3n. Tercera capa (CMD): es la parte que mantendr\u00e1 en ejecuci\u00f3n el contenedor. Estas capas se definen en el fichero Dockerfile **y son de s\u00f3lo lectura (RO - Read Only). Aqu\u00ed podemos ver un ejemplo de un **Dockerfile . FROM centos:7 RUN yum -y install httpd CMD [ \"apachectl\" , \"-DFOREGROUND\" ] El par\u00e1metro CMD es el que mantiene \" vivo \" el contenedor, en el ejemplo anterior es necesario utilizar como par\u00e1metro -DFOREGROUND del comando apachectl para que el contenedor se mantenga en ejecuci\u00f3n. Note \u00danicamente podemos encontrar una instrucci\u00f3n CMD en un Dockerfile , en caso de que haya m\u00e1s de una, s\u00f3lo se tendr\u00e1 en cuenta la \u00faltima Podemos definir la instrucci\u00f3n CMD de tres modos diferentes: Execform , es la forma m\u00e1s adecuada. CMD [ \"ejecutable\" , \"par\u00e1metro1\" , \"par\u00e1metro2\" ] #Ruta completa al ejecutable. CMD [ \"/bin/echo\" , \"Hola mundo\" ] #Bash como ejecutable, pasando el par\u00e1metro \"-c\" podemos ejecutar comandos como si estuviesemos en la terminal. CMD [ \"/bin/bash\" , \"-c\" , \"echo Hola mundo\" ] Como par\u00e1metros que acompa\u00f1an a la instrucci\u00f3n ENTRYPOINT . CMD [ \"par\u00e1metro1\" , \"par\u00e1metro2\" ] En formato shell , por debajo ejecuta /bin/sh -c . CMD comando par\u00e1metro1 par\u00e1metro2 La diferencia fundamental entre CMD y ENTRYPOINT se basa en que con el primero de ellos, cuando ejecutamos docker run con un comando espec\u00edfico, este comando sobrescribir\u00e1 el comando definido en el fichero Dockerfile . CMD ser\u00e1 el que utilizaremos habitualmente porque nos permite pasar par\u00e1metros cuando iniciemos el contenedor. ENTRYPOINT en caso de querer tener un contenedor como ejecutable, sin intenci\u00f3n de pasar ning\u00fan par\u00e1metro adicional.","title":"\u00bfQu\u00e9 es una imagen?"},{"location":"Docker/Docker/#descargando-imagenes","text":"Para la descarga de im\u00e1genes utilizaremos el comando docker pull . Es posible pasar diferentes par\u00e1metros, uno de los m\u00e1s habituales es el tag o etiqueta . Esta etiqueta nos permite elegir entre diferentes versiones del mismo contenedor, una imagen compatible con la arquitectura de nuestro procesador o una versi\u00f3n, de la aplicaci\u00f3n empaquetada en la imagen, particular que necesitemos. Ejemplo: #Descarga la versi\u00f3n 3.6.5 de mongo docker pull mongo:3.6.5-jessie En el ejemplo anterior hemos descargado una versi\u00f3n espec\u00edfica indic\u00e1ndole el tag despu\u00e9s de los dos puntos.","title":"Descargando im\u00e1genes"},{"location":"Docker/Docker/#que-es-una-etiqueta-tag","text":"Una etiqueta o tag identifica la imagen que vamos a descargarnos. Es una forma sencilla de versionar las im\u00e1genes. Si no establecemos este par\u00e1metro, la etiqueta por defecto que utilizar\u00e1 Docker es latest . Las etiquetas disponibles por cada imagen se encuentran enumeradas en el propio repositorio, adem\u00e1s en la documentaci\u00f3n se encuentran instrucciones que facilitan la elecci\u00f3n del tag de la imagen. A continuaci\u00f3n se encuentran dos enlaces que explican de forma extendida las etiquetas de las im\u00e1genes de Docker y que formas sencillas hay para versionar una imagen. The misunderstood Docker tag: latest Using Semver for Docker Image Tags","title":"\u00bfQu\u00e9 es una etiqueta (tag)?"},{"location":"Docker/Docker/#desarrollando-imagenes","text":"La forma sencilla para comenzar ha realizar pruebas es crear un directorio de trabajo que utilizaremos para desarrollar las primeras im\u00e1genes. En este directorio es necesario contar con un fichero Dockerfile (lo podemos crear ejecutando touch Dockerfile ), el cual contendr\u00e1 las capas que hemos visto m\u00e1s arriba. Este fichero es el utilizado por el comando docker build para crear las im\u00e1genes. Note Podemos llamar al fichero Dockerfile de cualquier otro modo, pero cuando creemos el contenedor ( docker build ) deberemos indicarle con el par\u00e1metro -f el nombre del fichero.","title":"Desarrollando im\u00e1genes"},{"location":"Docker/Docker/#dockerfile","text":"\u00bfQu\u00e9 instrucciones nos podemos encontrar dentro de este fichero? COPY : permite copiar un fichero o directorio del host a la imagen. ADD : adem\u00e1s de lo que nos permite realizar la instrucci\u00f3n COPY , esta nos permite pasar una URL para que descargue el contenido en la ruta que indiquemos dentro de la imagen. ENV : se utiliza para a\u00f1adir variables de entorno. La variable se establece sin el signo = , la variable y el valor se define con un espacio entre ambos. Ejemplo: ENV nombre juan WORKDIR : define el directorio de trabajo dentro del contenedor. Si no definimos este par\u00e1metro, por defecto nos encontramos en el directorio ra\u00edz / . EXPOSE : permite exponer puertos. Realmente esta instrucci\u00f3n no realizar ninguna exposici\u00f3n, simplemente informa a la persona que va a utilizar la imagen para crear el contenedor que puertos debe configurar. Estos puertos se expondr\u00e1n utilizando la opci\u00f3n -p del comando docker run . LABEL : hace referencia a una etiqueta, que se utiliza habitualmente para a\u00f1adir metadatos (informaci\u00f3n sobre la imagen como versi\u00f3n, creador, etc.). USER : identifica al usuario que ejecuta las instrucciones definidas en el fichero Dockerfile (las instrucciones que se establezcan a partir de la instrucci\u00f3n user ). Por defecto el usuario que ejecuta las instrucciones es el usuario root . VOLUME : permite que los datos que se encuentran en estos \"vol\u00famenes\" sean persistentes, ya que despu\u00e9s de eliminar el contenedor asociado a este volumen los datos no se perder\u00e1n. CMD : se entiende como la instrucci\u00f3n que mantiene vivo el contenedor. A continuaci\u00f3n veremos un Dockerfile con todas las instrucciones vistas hasta el momento: FROM nginx LABEL version = 1 .0 RUN useradd prueba USER prueba WORKDIR /usr/share/nginx/html COPY web /usr/share/nginx/html ENV variable1 tzinm EXPOSE 90 VOLUME /var/log/nginx CMD nginx -g 'daemon off;' Las instrucciones que definimos dentro de este fichero deben ser lo m\u00e1s estrictas posibles para evitar errores, por ello es importante tener en cuenta lo siguiente: Un servicio por contenedor. Utilizar la capa Labels para a\u00f1adir metadatos. Agrupar los argumentos, evitando crear una capa por cada argumento. Forma correcta RUN \\ python3 -m pip install telegram --upgrade && \\ python3 -m pip install python-telegram-bot --upgrade && \\ chown root:root AddToQbitTorrentFolder.py && \\ chmod 644 AddToQbitTorrentFolder.py Forma incorrecta RUN python3 -m pip install telegram --upgrade RUN python3 -m pip install python-telegram-bot --upgrade RUN chown root:root AddToQbitTorrentFolder.py RUN chmod 644 AddToQbitTorrentFolder.py Evitar la instalaci\u00f3n de paquetes innecesarios, de ese modo crearemos im\u00e1genes m\u00e1s ligeras. Adem\u00e1s del fichero Dockerfile hay otro fichero importante llamado .dockerignore . El funcionamiento de este es similar al fichero .gitignore , es un fichero oculto en el que definimos que contenido del directorio no queremos que sea tenido en cuenta.","title":"Dockerfile"},{"location":"Docker/Docker/#docker-build","text":"Una vez que tenemos nuestro Dockerfile terminado debemos ejecutar el comando docker build para crear nuestra imagen. docker build -t tzinm/test . En el comando ejecutado se ha denominado a la imagen tzinm/test , al no haber especificado ning\u00fan tag ser\u00e1 el tag latest el que se haya establecido. Otro dato importante es el punto del final, que hace referencia al contexto , es decir el directorio en el cual Docker buscar\u00e1 los ficheros necesarios para crear la imagen.","title":"Docker Build"},{"location":"Docker/Docker/#multi-stage-builds","text":"Esta nueva funcionalidad que nos ofrece Docker se encuentra disponible a partir de la versi\u00f3n 17.05. Es una utilidad interesante ya que nos permite crear En ocasiones, algunas im\u00e1genes necesitan cierto contenido que es generado mediante la compilaci\u00f3n o ejecuci\u00f3n de una serie de instrucciones que hace que el peso de una imagen crezca y su rendimiento no est\u00e9 lo m\u00e1s optimizado posible. Es aqu\u00ed cuando esta herramienta ( multi-stage builds ) es \u00fatil, ya que nos permite en una primera instancia crear una imagen \"al vuelo\" en la que generaremos esos ficheros mediante las instrucciones que necesitemos. Despu\u00e9s esos ficheros ser\u00e1n enviados (veremos luego en un ejemplo como se realiza esto) a la segunda imagen, exclusivamente esos ficheros, desprendi\u00e9ndonos de la primera imagen y todo lo que ello conlleva. Recordamos que para hacer un uso adecuado de Docker es necesario optimizar al m\u00e1ximo las im\u00e1genes, es la base de las buenas pr\u00e1cticas. A la hora de crear el fichero Dockerfile es muy similar al que utilizamos construyendo una \u00fanica imagen, salvo que en esta ocasi\u00f3n nos encontramos con la construcci\u00f3n de dos im\u00e1genes - por lo tanto dos FROM - y en la segunda imagen a\u00f1adimos una capa - COPY - con el flag --from=primar-imagen que se encargar\u00e1 de pasar el contenido generado en la primera imagen ( primer FROM ). Se puede ver un poco m\u00e1s claro en el siguiente ejemplo. FROM centos as test RUN fallocate -l 10M /tmp/file1 && \\ fallocate -l 40M /tmp/file2 FROM alpine COPY --from = test /tmp/file1 /tmp/test1","title":"Multi-Stage Builds"},{"location":"Docker/Docker/#dangling-images","text":"Este concepto hace referencia a im\u00e1genes hu\u00e9rfanas, que no son m\u00e1s que aquellas im\u00e1genes que se encuentran sin referenciar . \u00bfCuando sucede esto? Cuando una imagen es construida utilizando el mismo nombre y tag que otra creada anteriormente. La nueva imagen creada ser\u00e1 v\u00e1lida, en cambio las im\u00e1genes anteriores que existiesen no ser\u00e1n v\u00e1lidas y pasar\u00e1n a tener como nombre y tag el valor \\<none> . A pesar de que estas im\u00e1genes no son v\u00e1lidas, seguir\u00e1n estando en nuestro sistema y ocupando espacio, por ello es recomendable eliminarlas. El modo m\u00e1s r\u00e1pido de eliminar todas estas im\u00e1genes es mediante el siguiente comando: docker rmi $( docker images -f \"dangling=true\" -q ) En el comando anterior hemos utilizado el flag -f , que permite el filtrado de las im\u00e1genes siguiendo una serie de patrones .","title":"Dangling images"},{"location":"Docker/Docker/#contenedores","text":"Un contenedor se entiende como una capa adicional que mantiene en ejecuci\u00f3n las capas que se han definido en el fichero Dockerfile, por este motivo es posible crear tantos contenedores como se deseen a partir de la misma imagen. A diferencia del resto de capas, esta capa es de lectura y escritura ( rw ), por lo tanto nos permite realizar modificaciones sobre las capas anteriores cuando el contenedor se encuentra en ejecuci\u00f3n. Todas estas modificaciones son temporales puesto que no sobrescriben el fichero Dockerfile, por lo tanto una vez que eliminemos el contenedor esas modificaciones se perder\u00e1n (algunas modificaciones pueden ser persistentes mediante el uso de vol\u00famenes que veremos m\u00e1s adelante).","title":"Contenedores"},{"location":"Docker/Docker/#que-nos-encontramos-dentro-de-un-contenedor","text":"Imagen Vol\u00famenes (se utilizan para mantener persistente cierto contenido) Redes (\u00fatil para comunicar contenedores entre s\u00ed)","title":"\u00bfQu\u00e9 nos encontramos dentro de un contenedor?"},{"location":"Docker/Docker/#contenedor-vs-maquina-virtual","text":"El contenedor es un proceso aislado m\u00e1s del sistema, por lo tanto compartir\u00e1 el mismo hardware que est\u00e9 utilizando el sistema operativo anfitri\u00f3n, es decir, no necesitamos asignarle recursos espec\u00edficamente (aunque es posible limitar los recursos utilizados por un contenedor). En cambio, cuando creamos una m\u00e1quina virtual debemos asignarle una serie de recursos, como pueden ser el n\u00famero de nucleos, la memoria ram o el espacio en disco duro. En este caso obtenemos una m\u00e1quina completa dentro del propio sistema anfitri\u00f3n. La principal diferencia que nos podemos encontrar es la ligereza, un contenedor est\u00e1 destinado a ser much\u00edsimo m\u00e1s ligero que una m\u00e1quina virtual, habitualmente un contenedor se utiliza para ejecutar una \u00fanica aplicaci\u00f3n concreta.","title":"Contenedor VS M\u00e1quina Virtual"},{"location":"Docker/Docker/#docker-run","text":"Este comando se utiliza para iniciar los contenedores. Aunque parece evidente, no puede haber dos contenedores con el mismo nombre, aunque uno de ellos se encuentre parado. docker run -d jenkins -p 80 :8080 -d : permite correr un contenedor en segundo plano. jenkins : es el nombre de la imagen utilizada. -p : permite mapear los puertos. El puerto que se encuentra en el lado izquierdo es el que utilizar\u00e1 el sistema anfitri\u00f3n, el puerto de la derecha es el interno del contenedor. -e: asignaci\u00f3n de variables de entorno. En algunas ocasiones si no definimos la capa CMD es posible que el contenedor se muera. Si queremos evitar que esto sucede podemos utilizar los par\u00e1metros -i y -t para interactuar con el contenedor.","title":"Docker run"},{"location":"Docker/Docker/#limitando-recursos","text":"Por defecto Docker utiliza los recursos de la m\u00e1quina anfitriona sin l\u00edmite alguno, a pesar de ello los contenedores consumen muy pocos recursos. Podemos limitar tanto el uso de CPU como de RAM . #Limitando la memoria RAM docker run -d --memory \"100mb\" --name recursos-limitados centos Cuando se muestran las estad\u00edsticas con el comando docker stats ya no mostrar\u00e1 la RAM limite de nuestra m\u00e1quina, sino que los que hayamos establecido, en este caso ser\u00e1n 100MB. Podemos pasar la limitaci\u00f3n en bytes (b), kilobytes (k), megabytes (m) o gigabytes (g). #Limitando el n\u00famero de cores de la CPU docker run -d --cpuset-cpus 0 -3 --name reclimited2 centos Los n\u00facleos (o cores) se pueden definir mediante un rango (como hemos hecho en el ejemplo anterior) o numer\u00e1ndolos y como separaci\u00f3n una coma. 0-2 \u2192 utilizar\u00edamos los n\u00facleos 0, 1 y 2. 0,2 \u2192 utilizar\u00edamos los n\u00facleos 0 y 2.","title":"Limitando recursos"},{"location":"Docker/Docker/#politicas-de-reinicio","text":"Establecemos que sucede cuando un contenedor se \"apaga\" de forma inesperada. Disponemos de las siguientes opciones: No (es la pol\u00edtica por defecto): el contenedor no se reiniciar\u00e1 autom\u00e1ticamente. Si hacemos una prueba deteniendo cualquier contenedor que tengamos en funcionamiento, veremos que este se detiene y ejecutando el comando docker ps no aparece. Always : con esta opci\u00f3n el contenedor siempre se reiniciar\u00e1. Unless-stopped: se reiniciar\u00e1 siempre, salvo que sea detenido manualmente. On-failure : se reiniciar\u00e1 en caso de que el contenedor se haya detenido por alg\u00fan fallo. La pol\u00edtica de reinicios se establece ejecutando el par\u00e1metro --restart . docker run --restart unless-stopped","title":"Pol\u00edticas de reinicio"},{"location":"Docker/Docker/#volumenes","text":"Como ya sabemos, si eliminamos un contenedor todos sus datos se eliminar\u00e1n con \u00e9l. Para evitar esto tenemos los vol\u00famenes que nos permiten hacer persistentes algunos datos de nuestros contenedores. Estos datos se almacenan en un directorio de la m\u00e1quina anfitriona. Docker cuenta con tres tipos de vol\u00famenes.","title":"Vol\u00famenes"},{"location":"Docker/Docker/#volumenes-host","text":"En este tipo de vol\u00famenes definimos el directorio donde queremos que se almacene la informaci\u00f3n que debe ser persistente. Es el tipo de vol\u00famenes que m\u00e1s utilizaremos: docker run -v /midirectorio:/directorio-docker","title":"Vol\u00famenes Host"},{"location":"Docker/Docker/#volumenes-anonymous","text":"Seguimos haciendo persistentes los datos, pero en este caso no definimos donde queremos que se almacene la informaci\u00f3n, sino que Docker genera un directorio aleatorio. docker run -v /directorio-docker Estos directorios se encuentran en una ruta espec\u00edfica bajo el directorio \" ra\u00edz \" del servicio Docker. Para conocer dicho directorio es necesario ejecutar la siguiente instrucci\u00f3n: docker info | grep -i root Entre los diferentes directorio bajo el directorio ra\u00edz de Docker, tenemos un directorio denominado vol\u00famenes, que es el directorio donde se almacenaran estos directorios llamados anonymous . Los directorios anonymous tambi\u00e9n aparecen cuando en un fichero Dockerfile definimos la capa VOLUME pero a la hora de ejecutar el contenedor no definimos ning\u00fan volumen. Esta forma de crear vol\u00famenes no es aconsejable por varios motivos. El nombre que otorga al directorio es aleatorio (habitualmente conformado por n\u00fameros), por lo tanto no ser\u00e1 sencillo saber que volumen se encuentra asociado a cada contenedor. A la hora de eliminar el contenedor si pasamos la opci\u00f3n -v eliminaremos tambi\u00e9n el volumen asociado a este contenedor.","title":"Vol\u00famenes Anonymous"},{"location":"Docker/Docker/#volumenes-nombrados","text":"Es una mezcla de los dos anteriores. El volumen se almacena en el mismo lugar que los vol\u00famenes anonymous, pero en este caso somos nosotros quienes elegimos un nombre para estos vol\u00famenes en vez de ser un nombre aleatorio. Los siguientes comandos se utilizan para la gesti\u00f3n de vol\u00famenes: Creando un volumen docker volume create nombre_del_volumen Listar los vol\u00famenes docker volume ls Eliminar un volumen docker volume rm nombre_del_volumen Utilizar un volumen nombrado docker run -v nombre_del_volumen:/dockercontainer A diferencia de los vol\u00famenes host, donde debemos indicar la ruta completa del directorio, solo es necesario indicar el nombre del volumen que hayamos creado.","title":"Vol\u00famenes Nombrados"},{"location":"Docker/Docker/#dangling-volumes","text":"Este concepto que hemos visto con los contenedores tambi\u00e9n existe con los vol\u00famenes. Estos aparecen cuando hemos eliminado un contenedor y el volumen asociado a este (volumen anonymous) no se ha eliminado. Para eliminar estos vol\u00famenes podemos hacerlo con la siguiente l\u00ednea de terminal: docker volume ls -f \"dangling=true\" -q | xargs docker volume rm -f / --filtering : flag utilizado para filtrar los vol\u00famenes. dangling : es un filtro booleano que \u00fanicamente permite true o false . **-q **(quiet): imprime el ID que identifica a cada volumen. Con xargs pasamos el resultado a un segundo comando, de ese modo conseguimos eliminar con una \u00fanica l\u00ednea todos los vol\u00famenes. Note Los vol\u00famenes se pueden compartir entre varios contenedores, simplemente es indicar el volumen en el par\u00e1metro correspondiente cuando creemos los contenedores. Puede ser \u00fatil cuando necesitamos que dos contenedores accedan a la informaci\u00f3n que se encuentra en un directorio de nuestra m\u00e1quina.","title":"Dangling Volumes"},{"location":"Docker/Docker/#redes","text":"Cuando levantamos por primera vez el servicio Docker se crea una interfaz virtual llamada docker0 a la cual se le asigna una direcci\u00f3n ip en una subred diferente a la de nuestra red local. Cuando creamos un contenedor nuevo sin pasarle el par\u00e1metro referente a la red , este le asigna una direcci\u00f3n ip correspondiente al rango que nos proporciona la interfaz virtual docker0 . Algunos de los comandos referentes a la red de Docker: Ver la redes disponibles docker network ls Obtener informaci\u00f3n sobre una red docker network inspect nombre_de_red Note Los contenedores que se encuentran en la misma red pueden hacerse ping entre ellos.","title":"Redes"},{"location":"Docker/Docker/#creacion-de-redes","text":"Cuando creamos una red nueva, esta utilizar\u00e1 los drivers bridge (esto se puede cambiar pasando el par\u00e1metro --driver string cuando creamos la nueva red). El comando para la creaci\u00f3n de nuevas redes es el siguiente: docker network create nombre_de_red Docker nos permite especificar ciertas configuraciones a la hora de crear la red como puede ser la direcci\u00f3n de red o la puerta de enlace. Para ver que opciones tenemos podemos ejecutar docker network create --help . docker network create --driver bridge --subnet 172 .16.16.0/24 --gateway 172 .16.16.254 red-prueba Tambi\u00e9n existe la posibilidad de establecer una direcci\u00f3n ip espec\u00edfica a un contenedor, para ello se utiliza el flag --ip . docker run --network nombre_red --ip 192 .168.50.2 -dti --name nombre_contenedor ubuntu","title":"Creaci\u00f3n de redes"},{"location":"Docker/Docker/#conectando-un-contenedor-a-una-red-diferente","text":"Sabemos que Docker asigna como red por defecto bridge , por lo que si queremos elegir otra red deberemos hacerlo manualmente. La instrucci\u00f3n necesaria para elegir una red diferente a la red por defecto es la siguiente: docker run --network nombre_de_red -dti --name prueba-red ubuntu Note Podemos ejecutar docker inspecto prueba-red para ver las propiedades del contenedor, en las que aparecer\u00e1 la secci\u00f3n NetworkSetting y se podr\u00e1 ver la red asignada a este contenedor.","title":"Conectando un contenedor a una red diferente"},{"location":"Docker/Docker/#conectar-contenedores-a-la-misma-red","text":"En la red por defecto de Docker ( red bridge ) no podemos reconocer a los contenedores por su hostname . En cambio, cuando creamos una red (aunque utilice el driver bridge) es posible la comunicaci\u00f3n entre contenedores a trav\u00e9s de su hostname, esto se debe a que son redes definidas como \" user define network \". Para realizar una prueba de comunicaci\u00f3n entre dos contenedores podemos utilizar el comando ping . Podemos hacer la prueba mediante la direcci\u00f3n ip o mediante el nombre del contenedor. #Direcci\u00f3n ip docker exec nombre_contenedor bash -c \"ping -c 3 ip_contenedor2\" #Hostname docker exec nombre_contenedor bash -c \"ping -c 3 nombre_contenedor2\"","title":"Conectar contenedores a la misma red"},{"location":"Docker/Docker/#contenedores-en-mas-de-una-red","text":"Los contenedores ya existentes pueden tener configurado m\u00e1s de una red diferente. docker network connect nombre_red nombre_contenedor El comando docker inspect nos permite inspeccionar un contenedor, lo cual permite verificar las diferentes redes configuradas en dicho contenedor, de ese modo podr\u00edamos verificar si se ha a\u00f1adido la nueva red. Al igual que se puede configurar varias redes en un contenedor, tambi\u00e9n podemos eliminar varias redes de los contenedores. docker network disconnect nombre_red nombre_contenedor","title":"Contenedores en m\u00e1s de una red"},{"location":"Docker/Docker/#eliminar-redes","text":"Las redes creadas por un usuario se pueden eliminar, para ello es necesario que ning\u00fan contenedor se encuentre asociado a dicha red. docker network rm nombre_red","title":"Eliminar redes"},{"location":"Docker/Docker/#tipos-de-drivers-de-red","text":"","title":"Tipos de drivers de red"},{"location":"Docker/Docker/#bridge","text":"En Docker es el driver de red por defecto, sino se espec\u00edfica uno diferente es el driver utilizado por defecto a la hora de crear nuevas redes.","title":"Bridge"},{"location":"Docker/Docker/#host","text":"Este tipo de driver de red elimina el aislamiento entre el contenedor y la m\u00e1quina anfitriona, por lo tanto utiliza la red que utiliza la m\u00e1quina anfitriona. Es decir, estos contenedores podr\u00e1n recibir una direcci\u00f3n ip de forma din\u00e1mica por parte del servidor DHCP que tengamos configurado en nuestra red local.","title":"Host"},{"location":"Docker/Docker/#overlay","text":"Permite la comunicaci\u00f3n entre diferentes servidores Docker (docker daemons), esto permite que diferentes servicios puedan comunicarse entre si.","title":"Overlay"},{"location":"Docker/Docker/#macvlan","text":"Permite asignar una direcci\u00f3n MAC a un contenedor, lo cual simula disponer de una tarjeta de red en dicho contenedor.","title":"Macvlan"},{"location":"Docker/Docker/#none","text":"Este tipo de driver permite deshabilitar la red en los contenedores.","title":"None"},{"location":"Docker/Docker/#docker-compose","text":"Es una herramienta que nos ayuda a orquestar contenedores en Docker, gestionar los diferentes contenedores de los que depende una aplicaci\u00f3n. Existen aplicaciones que para su correcto funcionamiento dependen de varios servicios, para seguir con la simplicidad de \" un servicio = un contenedor \", Docker Compose nos permitir\u00e1 administrar los diferentes contenedores de forma grupal. Docker Compose trabaja con ficheros de tipo yaml , en los que se definen los contenedores, vol\u00famenes, redes, etc. Despu\u00e9s de completar el fichero, docker-compose como comando se encarga de la lectura del fichero y lanzar todos los contenedores definidos en dichero fichero. Durante la instalaci\u00f3n de Docker-CE esta herramienta no se instala, por lo que ser\u00e1 necesaria la instalaci\u00f3n de forma independiente. En la documentaci\u00f3n oficial se encuentran diferentes gu\u00edas para la instalaci\u00f3n en los diferentes Sistemas Operativos. En la m\u00e1quina actual, en la que estamos trabajando bajo Linux, la instalaci\u00f3n se har\u00eda del siguiente modo: Descargamos Docker-Compose. sudo curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose Aplicar permisos de ejecuci\u00f3n al ejecutable que hemos descargado. sudo chmod +x /usr/local/bin/docker-compose","title":"Docker Compose"},{"location":"Docker/Docker/#comenzando-con-docker-compose","text":"El nombre del fichero que debemos utilizar es docker-compose.yml , donde definiremos los diferentes contenedores. Este fichero cuenta con cuatro grandes partes: Version (obligatorio): para saber que n\u00famero de versi\u00f3n (Docker-Compose) debemos establecer, buscamos en la documentaci\u00f3n cual es la \u00faltima versi\u00f3n, suele ser la que se recomienda utilizar. Services (obligatorio): los servicios hacen referencia a los contenedores. En primera instancia definimos los nombres de cada servicio (podemos elegir el que queramos), y debajo de ellos ir\u00e1n los par\u00e1metros que hacen referencia al propio contenedor, como el nombre del contenedor, la imagen a la que hace referencia, puertos, variables de entorno, etc. Volumes (opcional): - Vol\u00famenes nombrados: funcionan del mismo modo que ejecutando docker run . Lo que hacemos es definir en primer lugar el volumen que crear\u00edamos con la instrucci\u00f3n docker volume create en \"volumes\" con el nombre que queramos. A continuaci\u00f3n lo definimos dentro del servicio. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"html:/usr/share/nginx/html\" volumes : html : - Vol\u00famenes host: no necesitamos la parte volumes dentro del fichero docker-compose.yml sino que directamente en el contenedorlo podemos parametrizar. version : '3' services : web : image : nginx container_name : nginx-prueba volumes : - \"/home/miusuario/html:/usr/share/nginx/html\" Networks (opcional): - Red Host: es importante establecer la versi\u00f3n 3.4 para que funcione correctamente . Para que funcione es necesario a\u00f1adir build , y adem\u00e1s a\u00f1adir el contexto , que hace referencia a un directorio que contenga un Dockerfile o una url a un repositorio git. Si establecemos la ruta relativa hace referencia a la ubicaci\u00f3n del archivo de composici\u00f3n. version : '3.4' services : web : build : context : . network : host image : nginx container_name : nginx-prueba ports : - \"8181:80\" - Creaci\u00f3n de una nueva red con subnet. A\u00fan no se permite establecer gateway . version : '3' services : web : image : nginx container_name : nginx-prueba ports : - \"8181:80\" networks : red-prueba : - ipv4_address : 192.168.50.10 networks : red-prueba : ipam : driver : default config : - subnet : \"192.168.50.0/24\" En cuanto a las redes, cuando ejecutamos el comando docker-compose up -d se genera una red espec\u00edfica para docker-compose . Si no definimos una red, la red utilizada ser\u00e1 la red por defecto (docker-compose_default). Cuando se crea la red, el nombre que es otorgado \" directorioactual_nombredelared \". Es posible modificar la parte del nombre que hace referencia al \"directorioactual\", pasando el par\u00e1metro -p . Por lo tanto si nuestro directorio actual se denomina docker-compose y queremos que el prefijo sea por ejemplo dcprueba ejecutar\u00edamos el siguiente comando: #Modificar el nombre de red a \"dcprueba_default\" docker-compose -p dcprueba up -d Por otro lado, tenemos dos partes importantes que se utilizan a la hora de crear contenedores. Variables de entorno: estas se pueden definir de dos modos. Fichero docker-compose.yml environment : - \"VARIABLES1=docker\" Fichero con extensi\u00f3n .env. environment : - variables.env Command: se utiliza para establecer un CMD al contenedor. commmand : mkdir /bin/bash El comando docker-compose se encarga de realizar un proceso similar que el comando docker run , pero en este caso los diferentes par\u00e1metros se encuentran definidos en un fichero. Por lo tanto, las pol\u00edticas de reinicio o la limitaci\u00f3n de recursos tambi\u00e9n se pueden definir. Pol\u00edticas de reinicio: #Reinicio siempre restart : always #Reinicio hasta que lo detengamos de forma manual restart : unless-stopped #\u00danicamente se reinicia el contenedor en caso de que haya habido un fallo restart : on-failure Limitar recursos: #Limitar memoria mem_limit : 20m #Cpu cpuset : \"0\" Otras de las directivas relevantes de este fichero es depends_on , la cual hace referencia a las dependencias que tiene se contenedor respecto a los que se incluyan en esta directiva. version : '3' services : web : image : nginx container_name : nginx-prueba depends_on : db db : image : postgres container_name : nginx-database El \u00faltimo paso ser\u00e1 conocer como podemos eliminar un contenedor creado con la herramienta Docker-Compose. Para ello debemos ejecutar el siguiente comando, situados en el directorio donde se encuentra el fichero yaml . docker-compose down El comando anterior sigue el siguiente proceso: Detiene el contenedor. Elimina el contenedor. Elimina la red que ha creado por defecto.","title":"Comenzando con Docker Compose"},{"location":"Docker/Docker/#docker-compose-build","text":"Ya conocemos el comando docker build , es el encargado de crear im\u00e1genes. El comando docker-compose build tiene un funcionamiento similar, se encarga de generar una imagen a partir de la definici\u00f3n de build en el fichero yaml . Esta imagen ser\u00e1 utilizada como imagen base en la creaci\u00f3n del contenedor. Para que se construya una imagen, sabemos que necesitamos un fichero Dockerfile , en el cual se encuentran las capas para la construcci\u00f3n de una imagen. En la sentencia build nos encontramos con dos par\u00e1metros importantes. Context: se indica la ruta donde se encuentra el Dockerfile que utilizaremos para crear la imagen. Si se encuentra en el mismo directorio se utilizar\u00e1 el punto ( . ). Dockerfile: el nombre del fichero si este es diferente al nombre por defecto (Dockerfile). version : '3' services : web : container_name : web image : web-test build : context : . dockerfile : Dockerfile1 *Si el nombre que hace referencia al Dockerfile no se ha modificado, podemos obviar estos dos par\u00e1metros. version : '3' services : web : container_name : web image : web-test build : .","title":"Docker-compose build"},{"location":"Docker/Docker/#seguridad","text":"Este apartado lo he denominado \"seguridad\" porque creo que es donde mejor encajala gesti\u00f3n de los usuarios en Docker. Para profundizar en el tema de seguridad es conveniente revisar la documentaci\u00f3n oficial . Simplificando mucho, sabemos que los contenedores de Docker son procesos para el sistema anfitri\u00f3n, por lo tanto el kernel del sistema es compartido entre todos los contenedores y el propio sistema. Es importante tener en cuenta esto ya que el kernel de Linux es el encargado de gestionar el uid y el gid de los diferentes usuarios, por lo tanto, estos ser\u00e1n compartidos con los contenedores de Docker. Cuando ejecutamos un contenedor, si no se especifica un usuario en la creaci\u00f3n del propio contenedor o en la imagen base del mismo, el uid y gid por defecto ser\u00e1 0 . Este id corresponde al usuario root , el usuario administrador de nuestro sistema. Una buena pr\u00e1ctica para controlar este comportamiento es contar con un usuario espec\u00edfico para Docker, al que se le otorgar\u00e1n los permisos exclusivamente necesarios para que el contenedor que hayamos creado pueda \u00fanicamente realizar la tarea para la que se ha creado. Despu\u00e9s de que hayamos creado el usuario que utilizaremos en los contenedores Docker, podemos obtener los ids que necestiamos (uid y gid) ejecutando el siguiente comando: id usuario-docker Para indicar al contenedor que usuario ser\u00e1 el que ejecute el CMD , se lo indicaremos con el flag -u . docker run -u = \"uid:gid\" Para verlo de una forma m\u00e1s clara, lo trataremos con un ejemplo . Imaginemos que queremos montar una biblioteca multimedia al estilo \"Netflix\" a partir de las pel\u00edculas y series digitales que tenemos en nuestros equipos. Hay diversas herramientas que nos facilitan esto, como por ejemplo Plex , que es una de las m\u00e1s conocidas. Esta biblioteca podemos ponerla en marcha a trav\u00e9s de un contenedor Docker, pero para que funcione correctamente este contenedor necesita acceso a las carpetas donde se encuentra todo nuestro contenido multimedia. Bien, si el usuario del contenedor no es el adecuado el contenedor no ser\u00e1 capaz de leer los directorios donde se encuentra todo el contenido multimedia, y por lo tanto no podr\u00e1 realizar su trabajo y no tendremos nuestra ansiada biblioteca multimedia. Siguiendo con la premisa de un usuario exclusivo para Docker, este usuario deber\u00eda tener acceso a los directorios donde se encuentra todo el contenido multimedia y a su vez, ser el usuario que hemos pasado por par\u00e1metros al contenedor de Plex.","title":"Seguridad"},{"location":"Docker/Docker/#otros-conceptos","text":"","title":"Otros conceptos"},{"location":"Docker/Docker/#docker-registry","text":"Es un servicio donde se alojan las im\u00e1genes que utilizar\u00e1 Docker. A este servicio se realizan peticiones mediante los comandos docker pull (descargar im\u00e1genes) y docker push (subir im\u00e1genes). El registry que utilizamos habitualmente es el propio de Docker, conocido como Docker Hub , del que nos descargamos las im\u00e1genes desarrolladas por la comunidad. Existe la posibilidad de mantener un registry local, podemos seguir la documentaci\u00f3n oficial para tenerlo en funcionamiento. Los siguientes comandos muestran un ejemplo utilizando un registry local. #Renombramos la imagen para que coincida con el nombre del registry, como lo har\u00edamos en docker hub. docker tag hello-world:lastest localhost:5000/hello-world #Subimos la imagen. docker push localhost:5000/hello-world #Descargar la imagen. docker pull localhost:5000/hellos-world","title":"Docker Registry"},{"location":"Docker/Docker/#comandos","text":"","title":"Comandos"},{"location":"Docker/Docker/#comandos-mas-utilizados","text":"Comando Descripci\u00f3n docker images lista las im\u00e1genes que se encuentran descargadas docker build construir una imagen a partir de un fichero Dockerfile docker history listar las capas generadas en una imagen concreta docker run crear un contenedor a partir de una imagen docker rm eliminar un contenedor docker rmi eliminar una o m\u00e1s im\u00e1genes docker ps listar los contenedores docker ps -a listar todos los contenedores docker rename cambiar el nombre de un contenedor (renombrar) docker stop detener un contenedor (se puede utilizar el id o el nombre del contenedor) docker start iniciar un contenedor (se puede utilizar el id o el nombre del contenedor) docker restart reiniciar un contenedor (se puede utilizar el id o el nombre del contenedor) docker logs para mostrar los logs de un contenedor. Con el par\u00e1metro \"-f\" se actualizan los logs en tiempo real docker inspect muestra informaci\u00f3n detallada de como ha sido construido un contenedor docker stats pasando el contenedor a este comando nos muestra cuantos recursos consume dicho contenedor docker system df --verbose muestra informaci\u00f3n detallada sobre el tama\u00f1o de todo el contenido de docker docker volume ls lista los vol\u00famenes de Docker. \u00danicamente lista los que se encuentran bajo el directorio root de Docker docker exec permite ejecutar comandos dentro de un contenedor que est\u00e9 activo docker history imagen muestra como ha sido creado una imagen docker cp copiar archivos entre la m\u00e1quina anfitri\u00f3n y el contenedor, y viceversa docker prune elimina todos los contenedores que se encuentran parados. Antes de eliminarlos se muestra un aviso .","title":"Comandos m\u00e1s utilizados"},{"location":"Docker/Docker/#otros-comandos","text":"Docker build #Construir una imagen con un nombre de Dockerfile diferente al utilizado por defecto. Para ello se utiliza el par\u00e1metro \"-f\". docker build -t test -f pruebadockerfile . Docker exec #Entrar en la terminal de un contenedor. docker exec -ti nombre_del_contenedor bash #exec: ejecutar #-t: terminal #-i: interactivo #bash: la terminal seleccionada #Se puede establecer el par\u00e1metro \"-u\" para seleccionar un usuario espec\u00edfico. Docker ps #Eliminar todos los contenedores a trav\u00e9s de sus IDs. docker ps -q | xargs docker rm -f #Eliminar todos los contenedores con estados \"exited\". docker ps -a | grep Exit | cut -d ' ' -f 1 | xargs sudo docker rm Docker cp #Copiar ficheros de mi m\u00e1quina a un contenedor y viceversa. docker cp mimaquina.txt test:/home docker cp test:/home/mimaquina.txt . Docker run #Creaci\u00f3n de un contenedor con el par\u00e1metro --rm para que se autoelimine una vez que haya salido de la sesi\u00f3n del contenedor. docker run --rm -ti -name test ubuntu:latest bash Docker rmi #Eliminar imagenes hu\u00e9rfanas docker rmi $( docker images -f \"dangling=true\" -q ) #Eliminar imagenes por fecha. Since (imagenes creadas posteriormente a la imagen pasada en el filtro), Before (imagenes creadas anteriormente a la imagen pasada en el filtro). docker rmi $( docker images -f since = \"images\" -q ) Docker commit #Crear una imagen a partir de un contenedor docker commit nombre-contenedor imagen-nueva Docker history #Visualizar el CMD del contenedor docker history -h nombre-contenedor","title":"Otros comandos"},{"location":"Docker/Docker/#fuentes","text":"","title":"Fuentes"},{"location":"Docker/Docker/#docker-bases","text":"Docker, de principiante a experto Docker for beginners Cap\u00edtulos Docker atareao.es Docker Tips Docker desde las bases: Comprendiendo imagenes Docker espa\u00f1ol GitHub","title":"Docker bases"},{"location":"Docker/Docker/#docker-en-profundidad","text":"Docker CMD vs ENTRYPOINT Understanding how uid and gid work in Docker containers Buenas pr\u00e1cticas construyendo im\u00e1genes Docker Eliminar vol\u00famenes hu\u00e9rfanos Dopcker Hub Automated Build Tagging Using Semver for Docker Image Tags Comando para saber los dockers corriendo y sus puertos","title":"Docker en profundidad"},{"location":"MacOS/personalizando-terminal/","text":"Personalizando el terminal # Powerline es una utilizar que nos permite personalizar nuestra terminal. Las instalaci\u00f3n de esta herramienta es sencilla, aunque necesitaremos el gestor de paquetes pip proporcionado por Python . Instalando python a trav\u00e9s del gestor de paquetes Homebrew brew install python Instalando powerline pip3 install --user powerline-status Para comprobar la ruta donde se ha instalado esta utilidad ejecutaremos el siguiente comando: pip3 show powerline-status Aparecer\u00e1 una serie de informaci\u00f3n, entre ellas una l\u00ednea que comienza por \"Location\" , la cual nos informa de la ruta. Es importante tenerla en cuenta ya que ser\u00e1 necesario para las siguientes configuraciones. Lo siguiente que haremos ser\u00e1 introducirlo en el fichero .bash_profile (es uno de los ficheros utilizados por bash para configurar el etorno del sistema) de nuestro usuario. En caso de que este fichero no se encuentre en nuestro sistema podemos crearlo ejecutando vim .bash_profile . A este archivo le a\u00f1adiremos lo siguiente: #A\u00f1adimos python a la variable PATH export PATH = $PATH : $HOME /Librar/Python/3.7/bin #Habilitamos powerline powerline-daemon -q POWERLINE_BASH_CONTINUATION = 1 POWERLINE_BASH_SELECT = 1 source $HOME /Library/Python/3.7/lib/python/site-packages/powerline/bindings/bash/powerline.sh Copiando la configuraci\u00f3n # Para una edici\u00f3n posterior de los ficheros de configuraci\u00f3n que nos permitir\u00e1n personalizar powerline al extremo, es necesario copiar el directorio config_flies a nuestro $HOME. Para ello ejecutaremos los siguiente comandos: #Creamos el directorio en nuestro $HOME mkdir ~/.config/powerline #Copiamos los ficheros de configuraci\u00f3n cp -R $HOME //Library/Python/3.7/lib/python/site-packages/powerline/config_files/* ~/.config/powerline Instalando las fuentes # # Clonaci\u00f3n del repositorio git clone https://github.com/powerline/fonts.git --depth = 1 # Instalaci\u00f3n de las fuentes cd fonts ./install.sh # Eliminamos el repositorio descargado cd .. rm -rf fonts Como se puede observar en el script de instalaci\u00f3n ( install.sh ), al realizar la instalaci\u00f3n en MacOS las fuentes se almacenan en la ruta $HOME/Library/Fonts . Problemas a solucionar # Para que la terminal muestre correctamente los iconos es necesario cambiar la fuente en la configuraci\u00f3n del terminal, a una de las descargadas compatibles con powerline. En caso de que nos encontremos trabajando con git y queramos que muestra la rama de trabajo es necesario realizar una peque\u00f1a modificaci\u00f3n en el fichero de configuraci\u00f3n config.json . En el bloque shell debemos establecer como \"theme\", default_leftonly , tal que as\u00ed: \"shell\" : { \"colorscheme\" : \"default\" , \"theme\" : \"default_leftonly\" , \"local_themes\" : { \"continuation\" : \"continuation\" , \"select\" : \"select\" } \u200b Despu\u00e9s debemos ejecutar el siguiente comando: powerline-daemon --replace Referencias # Documentaci\u00f3n Powerline Shell configuration How to install Powerline to pimp you Bash prompt (for Mac)","title":"Terminal"},{"location":"MacOS/personalizando-terminal/#personalizando-el-terminal","text":"Powerline es una utilizar que nos permite personalizar nuestra terminal. Las instalaci\u00f3n de esta herramienta es sencilla, aunque necesitaremos el gestor de paquetes pip proporcionado por Python . Instalando python a trav\u00e9s del gestor de paquetes Homebrew brew install python Instalando powerline pip3 install --user powerline-status Para comprobar la ruta donde se ha instalado esta utilidad ejecutaremos el siguiente comando: pip3 show powerline-status Aparecer\u00e1 una serie de informaci\u00f3n, entre ellas una l\u00ednea que comienza por \"Location\" , la cual nos informa de la ruta. Es importante tenerla en cuenta ya que ser\u00e1 necesario para las siguientes configuraciones. Lo siguiente que haremos ser\u00e1 introducirlo en el fichero .bash_profile (es uno de los ficheros utilizados por bash para configurar el etorno del sistema) de nuestro usuario. En caso de que este fichero no se encuentre en nuestro sistema podemos crearlo ejecutando vim .bash_profile . A este archivo le a\u00f1adiremos lo siguiente: #A\u00f1adimos python a la variable PATH export PATH = $PATH : $HOME /Librar/Python/3.7/bin #Habilitamos powerline powerline-daemon -q POWERLINE_BASH_CONTINUATION = 1 POWERLINE_BASH_SELECT = 1 source $HOME /Library/Python/3.7/lib/python/site-packages/powerline/bindings/bash/powerline.sh","title":"Personalizando el terminal"},{"location":"MacOS/personalizando-terminal/#copiando-la-configuracion","text":"Para una edici\u00f3n posterior de los ficheros de configuraci\u00f3n que nos permitir\u00e1n personalizar powerline al extremo, es necesario copiar el directorio config_flies a nuestro $HOME. Para ello ejecutaremos los siguiente comandos: #Creamos el directorio en nuestro $HOME mkdir ~/.config/powerline #Copiamos los ficheros de configuraci\u00f3n cp -R $HOME //Library/Python/3.7/lib/python/site-packages/powerline/config_files/* ~/.config/powerline","title":"Copiando la configuraci\u00f3n"},{"location":"MacOS/personalizando-terminal/#instalando-las-fuentes","text":"# Clonaci\u00f3n del repositorio git clone https://github.com/powerline/fonts.git --depth = 1 # Instalaci\u00f3n de las fuentes cd fonts ./install.sh # Eliminamos el repositorio descargado cd .. rm -rf fonts Como se puede observar en el script de instalaci\u00f3n ( install.sh ), al realizar la instalaci\u00f3n en MacOS las fuentes se almacenan en la ruta $HOME/Library/Fonts .","title":"Instalando las fuentes"},{"location":"MacOS/personalizando-terminal/#problemas-a-solucionar","text":"Para que la terminal muestre correctamente los iconos es necesario cambiar la fuente en la configuraci\u00f3n del terminal, a una de las descargadas compatibles con powerline. En caso de que nos encontremos trabajando con git y queramos que muestra la rama de trabajo es necesario realizar una peque\u00f1a modificaci\u00f3n en el fichero de configuraci\u00f3n config.json . En el bloque shell debemos establecer como \"theme\", default_leftonly , tal que as\u00ed: \"shell\" : { \"colorscheme\" : \"default\" , \"theme\" : \"default_leftonly\" , \"local_themes\" : { \"continuation\" : \"continuation\" , \"select\" : \"select\" } \u200b Despu\u00e9s debemos ejecutar el siguiente comando: powerline-daemon --replace","title":"Problemas a solucionar"},{"location":"MacOS/personalizando-terminal/#referencias","text":"Documentaci\u00f3n Powerline Shell configuration How to install Powerline to pimp you Bash prompt (for Mac)","title":"Referencias"},{"location":"OpenMediaVault/LVM/","text":"Logical Volume Management # LVM es un gestor de vol\u00famenes l\u00f3gicos (Logical Volume Manager) utilizado en Linux. Este sistema de almacenamiento permite establecer una capa l\u00f3gica entre el sistema de archivos y las particiones de los diferentes dispositivos de almacenamiento. Gracias a este sistema se puede combinar diferentes tipos de almacenamiento, como pueden ser particiones, RAID, etc. PV - Volumen f\u00edsico: # Hace referencia al dispositivo de almacenamiento, pudiendo ser un disco duro, una partici\u00f3n, un RAID, es decir, cualquier dispositivo de bloque. Comandos a utilizar: * A\u00f1adiendo un disco completo al volumen f\u00edsico pvcreate /dev/sdX - X ser\u00e1 la letra del disco que queramos a\u00f1adir Mostrando informaci\u00f3n de los vol\u00famenes f\u00edsicos: pvs pvdisplay /dev/sdX - X ser\u00e1 la letra del disco sobre el que queremos obtener la informaci\u00f3n VG - Grupo de vol\u00famenes: # Podr\u00eda considerarse como un disco duro virtual, donde agruparemos los vol\u00famenes f\u00edsicos que consideremos oportunos. Un grupo de vol\u00famenes puede contener un \u00fanico volumen f\u00edsico, pero siempre disponemos la posibilidad de aumentar el tama\u00f1o de un vg a\u00f1adiendo m\u00e1s vol\u00famenes f\u00edsicos a dicho grupo de vol\u00famenes. Comandos a utilizar: Al igual que con los comandos de los vol\u00famenes f\u00edsicos, veremos dos grupos de comandos, uno para crear los grupos de vol\u00famenes y otros para mostrar la informaci\u00f3n. Creando un grupo de vol\u00famenes: vgcreate nombre_del_grupo /dev/sdX Nombre_del_grupo \u2192 podemos establecer el nombre que queramos, aprovecharemos para darle un nombre que le identifique y sea f\u00e1cil reconocer que tipo de datos introduciremos en \u00e9l. /dev/sdX \u2192 ser\u00e1 el dispositivos que identifica al volumen f\u00edsico. Obteniendo informaci\u00f3n de los vol\u00famenes f\u00edsicos: vgs \u200b vgdisplay LV - Volumen l\u00f3gico: # Aqu\u00ed es donde se crearan los sistemas de ficheros, para hacer la analog\u00eda a los discos duros tradicionales, ser\u00eda como una partici\u00f3n. Un volumen l\u00f3gico puede crecer siempre y cuando el grupo de vol\u00famenes al que pertenece disponga de espacio disponible para asign\u00e1rselo. Comandos a utilizar: Al igual que los anteriores veremos comandos que id\u00e9nticas funcionalidades. Creaci\u00f3n de vol\u00famenes l\u00f3gicos: lvcreate -L 500G -n nombre_del_lv nombre_del_vg_perteneciente 1 * -L --> indicamos el tama\u00f1o en Megabytes (M), en Gigabytes (G), Terabytes (T), etc. En la siguiente fotograf\u00eda se puede ver de todas las opciones que disponemos. nombre_del_lv \u2192 elegimos un nombre que identifique al volumen l\u00f3gico. nombre_del_vg_perteneciente \u2192 debemos establecer el nombre del grupo de vol\u00famenes al que va a pertenecer. Obteniendo informaci\u00f3n de los vol\u00famenes l\u00f3gicos: lvdisplay Si queremos saber que vol\u00famenes f\u00edsicos est\u00e1 utilizando nuestro volumen l\u00f3gico debemos ejecutar lvdisplay -m . Una vez llegados hasta aqu\u00ed, tenemos los vol\u00famenes l\u00f3gico en crudo , es decir, nuestro siguiente paso ser\u00e1 crear el sistema de fichero (le otorgaremos ext4) mediante comandos con make file system ( mkfs ) o a trav\u00e9s de la interfaz web de OMV (as\u00ed lo realizaremos). En el panel lateral de OMV seleccionaremos Sistema de Archivos y deberemos pulsar el bot\u00f3n crear que vemos en la siguiente captura. Se abrir\u00e1 una peque\u00f1a ventana donde deeberemos elegir el dispositivo (en este caso ser\u00e1 el volumen l\u00f3gico que hayamos creado), podemos asignarle una etiqueta para identificarlo en la interfaz web de OMV y por \u00faltimo seleccionar el Sistema de Archivo (ext4 como hab\u00edamos comentado). Nos mostrar\u00e1 el proceso, no suele tardar demasiado tiempo. Una vez que termine cerramos la venta y debemos montar la unidad para que este disponible y podamos utilizarla como almacenamiento. Esto tambi\u00e9n lo podemos realizar desde la interfaz web. Debemos seleccionar la unidad que deseamos montar y pulsar el bot\u00f3n de montar tal y como se ve en la siguiente captura. Referencias: LVM para torpes I LVM para torpes II LVM para topres III","title":"Logical Volume Management"},{"location":"OpenMediaVault/LVM/#logical-volume-management","text":"LVM es un gestor de vol\u00famenes l\u00f3gicos (Logical Volume Manager) utilizado en Linux. Este sistema de almacenamiento permite establecer una capa l\u00f3gica entre el sistema de archivos y las particiones de los diferentes dispositivos de almacenamiento. Gracias a este sistema se puede combinar diferentes tipos de almacenamiento, como pueden ser particiones, RAID, etc.","title":"Logical Volume Management"},{"location":"OpenMediaVault/LVM/#pv-volumen-fisico","text":"Hace referencia al dispositivo de almacenamiento, pudiendo ser un disco duro, una partici\u00f3n, un RAID, es decir, cualquier dispositivo de bloque. Comandos a utilizar: * A\u00f1adiendo un disco completo al volumen f\u00edsico pvcreate /dev/sdX - X ser\u00e1 la letra del disco que queramos a\u00f1adir Mostrando informaci\u00f3n de los vol\u00famenes f\u00edsicos: pvs pvdisplay /dev/sdX - X ser\u00e1 la letra del disco sobre el que queremos obtener la informaci\u00f3n","title":"PV - Volumen f\u00edsico:"},{"location":"OpenMediaVault/LVM/#vg-grupo-de-volumenes","text":"Podr\u00eda considerarse como un disco duro virtual, donde agruparemos los vol\u00famenes f\u00edsicos que consideremos oportunos. Un grupo de vol\u00famenes puede contener un \u00fanico volumen f\u00edsico, pero siempre disponemos la posibilidad de aumentar el tama\u00f1o de un vg a\u00f1adiendo m\u00e1s vol\u00famenes f\u00edsicos a dicho grupo de vol\u00famenes. Comandos a utilizar: Al igual que con los comandos de los vol\u00famenes f\u00edsicos, veremos dos grupos de comandos, uno para crear los grupos de vol\u00famenes y otros para mostrar la informaci\u00f3n. Creando un grupo de vol\u00famenes: vgcreate nombre_del_grupo /dev/sdX Nombre_del_grupo \u2192 podemos establecer el nombre que queramos, aprovecharemos para darle un nombre que le identifique y sea f\u00e1cil reconocer que tipo de datos introduciremos en \u00e9l. /dev/sdX \u2192 ser\u00e1 el dispositivos que identifica al volumen f\u00edsico. Obteniendo informaci\u00f3n de los vol\u00famenes f\u00edsicos: vgs \u200b vgdisplay","title":"VG - Grupo de vol\u00famenes:"},{"location":"OpenMediaVault/LVM/#lv-volumen-logico","text":"Aqu\u00ed es donde se crearan los sistemas de ficheros, para hacer la analog\u00eda a los discos duros tradicionales, ser\u00eda como una partici\u00f3n. Un volumen l\u00f3gico puede crecer siempre y cuando el grupo de vol\u00famenes al que pertenece disponga de espacio disponible para asign\u00e1rselo. Comandos a utilizar: Al igual que los anteriores veremos comandos que id\u00e9nticas funcionalidades. Creaci\u00f3n de vol\u00famenes l\u00f3gicos: lvcreate -L 500G -n nombre_del_lv nombre_del_vg_perteneciente 1 * -L --> indicamos el tama\u00f1o en Megabytes (M), en Gigabytes (G), Terabytes (T), etc. En la siguiente fotograf\u00eda se puede ver de todas las opciones que disponemos. nombre_del_lv \u2192 elegimos un nombre que identifique al volumen l\u00f3gico. nombre_del_vg_perteneciente \u2192 debemos establecer el nombre del grupo de vol\u00famenes al que va a pertenecer. Obteniendo informaci\u00f3n de los vol\u00famenes l\u00f3gicos: lvdisplay Si queremos saber que vol\u00famenes f\u00edsicos est\u00e1 utilizando nuestro volumen l\u00f3gico debemos ejecutar lvdisplay -m . Una vez llegados hasta aqu\u00ed, tenemos los vol\u00famenes l\u00f3gico en crudo , es decir, nuestro siguiente paso ser\u00e1 crear el sistema de fichero (le otorgaremos ext4) mediante comandos con make file system ( mkfs ) o a trav\u00e9s de la interfaz web de OMV (as\u00ed lo realizaremos). En el panel lateral de OMV seleccionaremos Sistema de Archivos y deberemos pulsar el bot\u00f3n crear que vemos en la siguiente captura. Se abrir\u00e1 una peque\u00f1a ventana donde deeberemos elegir el dispositivo (en este caso ser\u00e1 el volumen l\u00f3gico que hayamos creado), podemos asignarle una etiqueta para identificarlo en la interfaz web de OMV y por \u00faltimo seleccionar el Sistema de Archivo (ext4 como hab\u00edamos comentado). Nos mostrar\u00e1 el proceso, no suele tardar demasiado tiempo. Una vez que termine cerramos la venta y debemos montar la unidad para que este disponible y podamos utilizarla como almacenamiento. Esto tambi\u00e9n lo podemos realizar desde la interfaz web. Debemos seleccionar la unidad que deseamos montar y pulsar el bot\u00f3n de montar tal y como se ve en la siguiente captura. Referencias: LVM para torpes I LVM para torpes II LVM para topres III","title":"LV - Volumen l\u00f3gico:"},{"location":"OpenMediaVault/Politica-actualizaciones/","text":"Cron-apt # Es el gestor que se encuentra en OMV para la gesti\u00f3n de paquetes y actualizaciones del sistema. Esta herramienta permite automatizar la ejecuci\u00f3n de varios comandos de apt-get para mantener elsistema actualizado. Una vez descargado el programa ejecutando apt-get install cron-apt (para otras distribuciones consultar la gu\u00eda de instalaci\u00f3n) hay varios ficheros a tener en cuenta. En el directorio /etc/cron-apt/config.d/ no se encuentra ning\u00fan fichero por defecto. Fichero config que se encuentra en la ruta /etc/cron-apt/ # When to send email about the cron-apt results. # Value: error (send mail on error runs) # upgrade (when packages are upgraded) # changes (mail when change in output from an action) # output (send mail when output is generated) # always (always send mail) # (else never send mail) MAILON = \"upgrade\" # Value: error (syslog on error runs) # upgrade (when packages is upgraded) # changes (syslog when change in output from an action) # output (syslog when output is generated) # always (always syslog) # (else never syslog) SYSLOGON = \"always\" OPTIONS = \"-o Acquire::http::Dl-Limit=25\" Dos ficheros que se encuentran en el directorio /etc/cron-apt/action.d/ . Los dos ficheros son los siguientes: 0-update: 3-download: Con las l\u00edneas que se encuentran en estos dos ficheros se realizar\u00e1 una actualizaci\u00f3n de la lista local de paquetes, descargar\u00e1 los paquetes para los que se encuentre una versi\u00f3n m\u00e1s actual, pero no realizar\u00e1 la instalaci\u00f3n de estos. Respondiendo al fichero de configuraci\u00f3n, enviar\u00e1 un email a la cuenta configurada para la recepci\u00f3n de estos. Cuando instalamos esta herramienta se a\u00f1ade autom\u00e1ticamente un fichero al directorio /etc/cron.d/ llamada cron-apt que contiene los comandos que ejecutar\u00e1 cron. Como veremos en el script, cron-apt se ejecuta todas las noches a las 4 de la ma\u00f1ana. # Regular cron jobs for the cron-apt package # # Every night at 4 o'clock. 0 4 * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt # Every hour. # 0 * * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt /etc/cron-apt/config2 # Every five minutes. # */5 * * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt /etc/cron-apt/config2 En Openmediavault cuando generamos una tarea desde la interfaz web, este es a\u00f1adido en la ruta /etc/cron.d/openmediavault-userdefined . El contenido de este fichero se muestra del siguiente modo: SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin # m h dom mon dow user command @daily root /var/lib/openmediavault/cron.d/userdefined-e68e3a58-58b9-49e4-92c4-aed639dbe2c1 | mail -E -s \"Cron - Rclone copy\" -a \"From: Cron Daemon <root>\" root >/dev/null 2 > & 1 Adem\u00e1s del directorio cron.d , podemos encontrarnos los directorios cron.daily , cron.hourly , cron.monthly y cron.weekly , que almacena los scripts en funci\u00f3n de la frecuencia con la que se ejecutar\u00e1n. El fichero /etc/crontab contiene las referencias a los directiorios mencionado en el p\u00e1rrafo anterior. Este fichero contiene las siguientes l\u00edneas: # /etc/crontab: system-wide crontab # Unlike any other crontab you don't have to run the `crontab' # command to install the new version when you edit this file # and files in /etc/cron.d. These files also have username fields, # that none of the other crontabs do. SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin # m h dom mon dow user command 17 * * * * root cd / && run-parts --report /etc/cron.hourly 25 6 * * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily ) 47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly ) 52 6 1 * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly ) \u00bfCu\u00e1l es su funcionamiento? # Este fichero env\u00eda una orden con el comando run-parts para que los scripts que se encuentren en el directorio hourly se ejecuten en el minuto 17 de cada hora. A su vez, con el resto de directorios, antes de enviar la orden con run-parts comprueba si anacron tiene permisos de ejecuci\u00f3n. Para ello utiliza el operador l\u00f3gico OR ( || ). Puesto que en el sistema anacron se encuentra con los permisos de ejecuci\u00f3n, cron no realizar\u00e1 ninguna tarea con los scripts que se encuentren en los directorios daily , weekly y monthly . Esta tarea la realizar\u00e1 anacron como veremos explicado en el pr\u00f3ximo apartado ( Anacron ). Es necesario que el servicio crond se encargue del directorio hourly ya que anacron s\u00f3lo puede ejecutar como m\u00e1ximo una tarea diaria. Anacron # Este servicio es ejecutado al inicio del sistema. Es un complemento a cron ya que permite comprobar si alguna tarea que se le haya especificado no ha sido ejecutado, y en tal caso la ejecutar\u00e1. El fichero anacrontab que nos encontramos en OpenMediaVault es el siguiente: # /etc/anacrontab: configuration file for anacron # See anacron(8) and anacrontab(5) for details. SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin HOME = /root LOGNAME = root # These replace cron's entries 1 5 cron.daily run-parts --report /etc/cron.daily 7 10 cron.weekly run-parts --report /etc/cron.weekly @monthly 15 cron.monthly run-parts --report /etc/cron.monthly Este fichero ejecutar\u00e1 todos los scripts que se encuentren en los directorios cron.daily , cron.weekly y cron.monthly . Los valores que vemos en cada l\u00ednea expresan lo siguiente: Primera columna: period in days \u2014 frequency of job execution in days The property value can be defined as an integer or a macro ( @daily , @weekly , @monthly ), where @daily denotes the same value as integer 1, @weekly the same as 7, and @monthly specifies that the job is run once a month regarless of the length of the month. Segunda columna: delay in minutes , n\u00famero de minutos que anacron espera hasta ejecutar el comando. Tercera columna: job identifier es un nombre que identifica a la tarea que se est\u00e1 ejecutando, es \u00fatil para cuando se analicen logs. Cuarta columna: el comando a ejecutar. Anacron se basa en el timestamp para saber si la tarea no ha sido ejecutada y en tal caso ejecutarla. De ah\u00ed que en los directorios daily , monthly y weekly haya un fichero llamado 0anacron , siendo el script que actualizar\u00e1 las marcas de tiempo ( timestamp ). Script timestamp: # #!/bin/sh # # anacron's cron script # # This script updates anacron time stamps. It is called through run-parts # either by anacron itself or by cron. # # The script is called \"0anacron\" to assure that it will be executed # _before_ all other scripts. test -x /usr/sbin/anacron || exit 0 anacron -u cron.daily","title":"Pol\u00edticas de actualizaciones"},{"location":"OpenMediaVault/Politica-actualizaciones/#cron-apt","text":"Es el gestor que se encuentra en OMV para la gesti\u00f3n de paquetes y actualizaciones del sistema. Esta herramienta permite automatizar la ejecuci\u00f3n de varios comandos de apt-get para mantener elsistema actualizado. Una vez descargado el programa ejecutando apt-get install cron-apt (para otras distribuciones consultar la gu\u00eda de instalaci\u00f3n) hay varios ficheros a tener en cuenta. En el directorio /etc/cron-apt/config.d/ no se encuentra ning\u00fan fichero por defecto. Fichero config que se encuentra en la ruta /etc/cron-apt/ # When to send email about the cron-apt results. # Value: error (send mail on error runs) # upgrade (when packages are upgraded) # changes (mail when change in output from an action) # output (send mail when output is generated) # always (always send mail) # (else never send mail) MAILON = \"upgrade\" # Value: error (syslog on error runs) # upgrade (when packages is upgraded) # changes (syslog when change in output from an action) # output (syslog when output is generated) # always (always syslog) # (else never syslog) SYSLOGON = \"always\" OPTIONS = \"-o Acquire::http::Dl-Limit=25\" Dos ficheros que se encuentran en el directorio /etc/cron-apt/action.d/ . Los dos ficheros son los siguientes: 0-update: 3-download: Con las l\u00edneas que se encuentran en estos dos ficheros se realizar\u00e1 una actualizaci\u00f3n de la lista local de paquetes, descargar\u00e1 los paquetes para los que se encuentre una versi\u00f3n m\u00e1s actual, pero no realizar\u00e1 la instalaci\u00f3n de estos. Respondiendo al fichero de configuraci\u00f3n, enviar\u00e1 un email a la cuenta configurada para la recepci\u00f3n de estos. Cuando instalamos esta herramienta se a\u00f1ade autom\u00e1ticamente un fichero al directorio /etc/cron.d/ llamada cron-apt que contiene los comandos que ejecutar\u00e1 cron. Como veremos en el script, cron-apt se ejecuta todas las noches a las 4 de la ma\u00f1ana. # Regular cron jobs for the cron-apt package # # Every night at 4 o'clock. 0 4 * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt # Every hour. # 0 * * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt /etc/cron-apt/config2 # Every five minutes. # */5 * * * * root test -x /usr/sbin/cron-apt && /usr/sbin/cron-apt /etc/cron-apt/config2 En Openmediavault cuando generamos una tarea desde la interfaz web, este es a\u00f1adido en la ruta /etc/cron.d/openmediavault-userdefined . El contenido de este fichero se muestra del siguiente modo: SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin # m h dom mon dow user command @daily root /var/lib/openmediavault/cron.d/userdefined-e68e3a58-58b9-49e4-92c4-aed639dbe2c1 | mail -E -s \"Cron - Rclone copy\" -a \"From: Cron Daemon <root>\" root >/dev/null 2 > & 1 Adem\u00e1s del directorio cron.d , podemos encontrarnos los directorios cron.daily , cron.hourly , cron.monthly y cron.weekly , que almacena los scripts en funci\u00f3n de la frecuencia con la que se ejecutar\u00e1n. El fichero /etc/crontab contiene las referencias a los directiorios mencionado en el p\u00e1rrafo anterior. Este fichero contiene las siguientes l\u00edneas: # /etc/crontab: system-wide crontab # Unlike any other crontab you don't have to run the `crontab' # command to install the new version when you edit this file # and files in /etc/cron.d. These files also have username fields, # that none of the other crontabs do. SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin # m h dom mon dow user command 17 * * * * root cd / && run-parts --report /etc/cron.hourly 25 6 * * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily ) 47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly ) 52 6 1 * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )","title":"Cron-apt"},{"location":"OpenMediaVault/Politica-actualizaciones/#cual-es-su-funcionamiento","text":"Este fichero env\u00eda una orden con el comando run-parts para que los scripts que se encuentren en el directorio hourly se ejecuten en el minuto 17 de cada hora. A su vez, con el resto de directorios, antes de enviar la orden con run-parts comprueba si anacron tiene permisos de ejecuci\u00f3n. Para ello utiliza el operador l\u00f3gico OR ( || ). Puesto que en el sistema anacron se encuentra con los permisos de ejecuci\u00f3n, cron no realizar\u00e1 ninguna tarea con los scripts que se encuentren en los directorios daily , weekly y monthly . Esta tarea la realizar\u00e1 anacron como veremos explicado en el pr\u00f3ximo apartado ( Anacron ). Es necesario que el servicio crond se encargue del directorio hourly ya que anacron s\u00f3lo puede ejecutar como m\u00e1ximo una tarea diaria.","title":"\u00bfCu\u00e1l es su funcionamiento?"},{"location":"OpenMediaVault/Politica-actualizaciones/#anacron","text":"Este servicio es ejecutado al inicio del sistema. Es un complemento a cron ya que permite comprobar si alguna tarea que se le haya especificado no ha sido ejecutado, y en tal caso la ejecutar\u00e1. El fichero anacrontab que nos encontramos en OpenMediaVault es el siguiente: # /etc/anacrontab: configuration file for anacron # See anacron(8) and anacrontab(5) for details. SHELL = /bin/sh PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin HOME = /root LOGNAME = root # These replace cron's entries 1 5 cron.daily run-parts --report /etc/cron.daily 7 10 cron.weekly run-parts --report /etc/cron.weekly @monthly 15 cron.monthly run-parts --report /etc/cron.monthly Este fichero ejecutar\u00e1 todos los scripts que se encuentren en los directorios cron.daily , cron.weekly y cron.monthly . Los valores que vemos en cada l\u00ednea expresan lo siguiente: Primera columna: period in days \u2014 frequency of job execution in days The property value can be defined as an integer or a macro ( @daily , @weekly , @monthly ), where @daily denotes the same value as integer 1, @weekly the same as 7, and @monthly specifies that the job is run once a month regarless of the length of the month. Segunda columna: delay in minutes , n\u00famero de minutos que anacron espera hasta ejecutar el comando. Tercera columna: job identifier es un nombre que identifica a la tarea que se est\u00e1 ejecutando, es \u00fatil para cuando se analicen logs. Cuarta columna: el comando a ejecutar. Anacron se basa en el timestamp para saber si la tarea no ha sido ejecutada y en tal caso ejecutarla. De ah\u00ed que en los directorios daily , monthly y weekly haya un fichero llamado 0anacron , siendo el script que actualizar\u00e1 las marcas de tiempo ( timestamp ).","title":"Anacron"},{"location":"OpenMediaVault/Politica-actualizaciones/#script-timestamp","text":"#!/bin/sh # # anacron's cron script # # This script updates anacron time stamps. It is called through run-parts # either by anacron itself or by cron. # # The script is called \"0anacron\" to assure that it will be executed # _before_ all other scripts. test -x /usr/sbin/anacron || exit 0 anacron -u cron.daily","title":"Script timestamp:"},{"location":"OpenMediaVault/Rclone/","text":"Rclone in OMV # En esta peque\u00f1a gu\u00eda voy a mostrar la configuraci\u00f3n de Rclone con Google Drive. Se puede utilizar con muchos m\u00e1s servicios. Consultar aqu\u00ed La instalaci\u00f3n es muy sencilla, en esta web podemos ver la instalaci\u00f3n tanto para Linux como para MacOS. Podemos optar por llamar a un script que realizar\u00e1 todo el proceso de instalaci\u00f3n, o descargarnos un fichero .zip que descomprimiremos e instalaremos. Instalaci\u00f3n: # Me he percatado que siguiendo la gu\u00eda de instalaci\u00f3n sobre Linux, no descarga la \u00faltima versi\u00f3n. Para evitar esto, y descargar la \u00faltima versi\u00f3n, iremos a este enlace y copiaremos la direcci\u00f3n del fichero .zip que corresponde con nuestra m\u00e1quina. No s\u00e9 si ya lo he comentado, pero la instalaci\u00f3n que estoy realizando es sobre OpenMediaVault que es un sistema orientado a NAS. Tal y como dicen sus desarrolladores est\u00e1 orientado a utilizar la interfaz web y no la \"cli\" (Command line interface). Es por ello que ir\u00e9 comprobando que los binarios correspondientes a los comandos que debo ejecutar se encuentran instalados en el sistema. Para ello ejecutar\u00e9 apt list --installed | grep nombre_del_binario . A continuaci\u00f3n pegar\u00e9 de la web oficial los comandos necesarios para su instalaci\u00f3n: Descarga del fichero .zip y descompresi\u00f3n. curl -O https://downloads.rclone.org/v1.47.0/rclone-v1.47.0-linux-amd64.zip unzip rclone-v1.47.0-linux-amd64.zip cd rclone-v1.47.0-linux-amd64 Como comentaba, la ruta que debemos poner es la que corresponde a la \u00faltima versi\u00f3n de Rclone Trasladar el binario rclone . sudo cp rclone /usr/bin/ sudo chown root:root /usr/bin/rclone sudo chmod 755 /usr/bin/rclone La ruta /usr/bin se encuentra en el PATH, que es la variable que contiene las rutas a los directorios que contienen los ficheros ejecutables. De ese modo podremos ejecutar Rclone sin importar en que directorio del sistema nos encontremos. A\u00f1adiendo el manual de rclone a la base de datos de manuales. sudo mkdir -p /usr/local/share/man/man1 sudo cp rclone.1 /usr/local/share/man/man1/ sudo mandb Copiamos el manual y actualizamos la base de datos de los manuales para que podamos invocar el \"man page\" ejecutando man rclone Configuraci\u00f3n: # La configuraci\u00f3n es muy sencilla ya que el propia sistema nos gu\u00eda una vez que ejecutamos rclone config . Cuando ejecutamos este comando los aparecer\u00e1 un peque\u00f1o men\u00fa desde donde crearemos los nuevos servicios remotos (por denominarlos de alg\u00fan modo). La opci\u00f3n para crear es la \" n \", que una vez seleccionada esta opci\u00f3n nos aparecer\u00e1 en el prompt para asignarle un nombre, y a continuaci\u00f3n debemos elegir que servicio queremos configurar. En mi caso he seleccionado Google Drive que es la opci\u00f3n n\u00famero 12 (quiz\u00e1 pueda variar de el n\u00famero si la versi\u00f3n de Rclone es diferente). Nos aparecer\u00e1n una serie de par\u00e1metros para ir configurando, \u00fanicamente mostrar\u00e9 los que he necesitado configurar, puesto que el resto los he dejado por defecto ya que no necesitaba configurarlos. En uno de los pasos de la configuraci\u00f3n debemos establecer los permisos que le otorgamos, he seleccionado la opci\u00f3n n\u00famero \"1\" que es la m\u00e1s permisiva, ya que tenemos acceso total a todos los contenidos. Otra de las preguntas que nos aparecer\u00e1n a continuaci\u00f3n es si deseamos editar la configuraci\u00f3n avanzada, para nuestro supuesto no es necesario, por lo que seleccionaremos \" n \". La siguiente cuesti\u00f3n a tener en cuenta es si deseamos utilizar la configuraci\u00f3n autom\u00e1tica. Como podemos ver en la explicaci\u00f3n, en el segundo punto nos indica que s\u00ed estamos trabajando en una m\u00e1quina remota (por ejemplo contra nuestro servidor v\u00eda ssh) debemos seleccionar la opci\u00f3n \" n \", que ser\u00e1 la opci\u00f3n que seleccionaremos. Al haber pulsado la opci\u00f3n \" n \" nos mostrar\u00e1 una direcci\u00f3n que debemos copiar y pegar en nuestro navegador. Esta direcci\u00f3n nos solicitar\u00e1 autenticarnos con la cuenta de Google Drive que queremos vincular con Rclone. Una vez que nos autentiquemos nos aparecer\u00e1 un c\u00f3digo que copiaremos y pegaremos en la l\u00ednea que nos solicita Rclone. Antes de finalizar, nos preguntar\u00e1 si deseamos configurar como un Team Drive [^1], no es nuestro caso por lo tanto seleccionaremos \" n \". Nos mostrar\u00e1 un peque\u00f1o resumen con el \" remote \" que hemos configurado. Para finalizar debemos seleccionar con la letra \" q \" (Quit config). Opciones utilizadas: # En la creaci\u00f3n de los Remotes he creado dos id\u00e9nticos, es decir dos de cuentas Google Drive, uno para copiar el contenido, y el otro para sincronizarlo. La diferencia es que con la opci\u00f3n copy quiero evitar que si borro contenido no se elimine de mi servidor, en cambio con la opci\u00f3n sync quiero conseguir que tanto en GD como en mi servidor el contenido sea id\u00e9ntico. Los comandos a ejecutar se introducir\u00e1n en diferentes scripts, que a su vez se incorporar\u00e1n a otro script para que compruebe si el script de rclone sync y rclone copy se est\u00e1n ejecutando, para evitar una nueva ejecuci\u00f3n. Rclone sync (script): #!/bin/bash rclone sync ASIR: /sharedfolders/ASIRDrive -v --log-file = /home/Logs/rclonesync.txt -u --bwlimit 8650k --tpslimit 10 --transfers 15 --exclude Maquinas_Virtuales/ --exclude ISOS/ exit #!/bin/bash #Comprobamos que el script no se est\u00e1 ejecutando mediante pidof if pidof -o %PPID -x sh /home/Scripts/rclonesync.sh ; then exit 1 fi #Despu\u00e9s de comprobar, si no se est\u00e1 ejecutando pasar\u00e1 a ejecutar los siguientes comandos. echo \"Ejecutando rclonesync...\" #Puesto que la ruta de los scripts no se encuentra en la variable PATH es neceario indicarle la ruta completa /home/Scripts/rclonesync.sh echo \"\u00a1La ejecuci\u00f3n del script ha finalizado!\" exit Rclone copy (script): #!/bin/bash rclone copy TzinmDrive:General /sharedfolders/CursosDrive -v --log-file = /home/Logs/rclonecopy.txt -u --bwlimit 8650k --tpslimit 10 -transfers 15 exit #!/bin/bash #Comprobamos que el script no se est\u00e1 ejecutando mediante pidof if pidof -o %PPID -x /home/Scripts/rclonecopy.sh ; then exit 1 fi #Despu\u00e9s de comprobar, si no se est\u00e1 ejecutando pasar\u00e1 a ejecutar los siguientes comandos. echo \"Ejecutando rclonecopy...\" #Puesto que la ruta de los scripts no se encuentra en la variable PATH es neceario indicarle la ruta completa /home/Scripts/rclonecopy.sh echo \"\u00a1La ejecuci\u00f3n del script ha finalizado!\" exit La ruta que he establecido despu\u00e9s de sh puede diferir con la que utilic\u00e9is. Ten\u00e9is que indicar la ruta donde se encuentra vuestro script. Una vez que tenemos los script creados s\u00f3lo quedar\u00e1 a\u00f1adirlos al cron, que podemos aprovecharnos de la interfaz web de OpenMediaVault o a\u00f1adirlos mediante comandos, en ambos casos es muy sencillo. Una vez que hemos creado los Scripts en el directorio de Rclone que hayamos decidido, les daremos permiso de ejecuci\u00f3n para que no sea necesario llamar al comando sh y con poner la ruta completa del script sea suficiente. Esto nos evitar\u00e1 algunos problemas que he visto que surgen con el comando pidof. chmod a+x /home/Scripts/* a+x: otorgamos permisos ejecuci\u00f3n a todos los usuarios. /home/Scripts/*: a todo el contenido que se encuentra en esta ruta. Rclone sync: la siguiente configuraci\u00f3n es sincronizaci\u00f3n cada 30 minutos. Rclone copy: la siguiente configuraci\u00f3n es rclone copy los domingos a la 01:00. En la siguiente captura es como lo ver\u00edamos en nuestra terminal: Ejecuci\u00f3n cron alternativa: # Por la web de Rclone no he visto como poder controlar el tama\u00f1o de los log que se van generando. Ser\u00eda interesante poder eliminar los datos antiguos, es decir establecer un l\u00edmite de por ejemplo 10MB y cuando llegue a ese l\u00edmite que vaya eliminando logs antiguos para poder introducir nuevos logs. Como digo, no he visto forma de hacerlo por lo tanto voy a a\u00f1adir al Cron un comando a ejecutar para que compruebe el tama\u00f1o de los logs y en caso de que supere el tama\u00f1o que nosotros le indiquemos (en mi caso ser\u00e1n 10MB) que realice una acci\u00f3n. find /home/Logs/ -type f -size +10M -exec rm -f {} \\; find: comando utilizado para realizar b\u00fasquedas. /home/Logs/: es la ruta en la que queremos buscar, podemos indicarle la que queramos. La ruta que he marcado es donde se encuentran los Logs de rclone. -type f: es el tipo de fichero que queremos buscar (en linux todo es un fichero), en nuestro caso ser\u00e1 un fichero de tipo file . -size +10M: buscamos fichero mayor de 10 Megabytes. Si delante del 10 indicamos un - buscar\u00e1 ficheros menores a 10 Megabytes. Se puede establecer otras unidades de medida que se encuentran explicadas en el manual de find. -exec: nos permite ejecutar una acci\u00f3n con todo aquello que ha encontrado (en funci\u00f3n de las condiciones que le hemos marcado). rm -f: rm = remove, es decir elimina lo que hemos encontrado, y como estamos seguros de que lo que ha encontrado lo queremos eliminar pasamos el par\u00e1metro -f para que no nos solicite confirmaci\u00f3n. {}: identifica a todo lo que ha encontrado el comando find. \\;: es la finalizaci\u00f3n del comando find cuando utilizamos la opci\u00f3n -excec . Man find Logging: Utilizaremos dos opciones para monitorizar rclone. -v, --verbose : rclone tiene 4 niveles de log, ERROR , AVISO , INFO Y DEBUG . Cuando utilizamos -v , rclone muestra los tres primeros niveles de error. --log-file=FILE : en combinaci\u00f3n con la anterior, todo el log monitorizado lo enviamos a un fichero, que ser\u00e1 el que establecemos despu\u00e9s del s\u00edmbolo = . Bwlimit: --bwlimit : con est\u00e1 opci\u00f3n limitamos el ancho de banda. En nuestro caso la utilizaremos para no ocupar todo el ancho de banda que nos proporciona nuestro ISP. Por la web se puede ver limitaciones de 8650k (Hace referencia a 8650 KBytes, que si hacemos la operaci\u00f3n matem\u00e1tica correspondiente son aproximadamente 750GB diarios, que es el limite para los Team Drive). Seg\u00fan lo que se puede leer por algunas consultas realizadas al soporte de Google, no hay limitaciones, salvo en lo que se refiere a contenido de video (Por ejemplo si queremos utilizar GD para almac\u00e9n del contenido de Plex) y de hosting. Limitaciones de Google: * Files you can store in Google Drive * Team Drive Limits ; After you've uploaded 750 GB to a Team Drive in 1 day, you'll be blocked from uploading additional files that day. However, file uploads already in progress will complete, up to a 5 TB maximum for a single file. Update: -u, --update : con esta opci\u00f3n obligamos a rclone que omita cualquier archivo que tenga una hora de modificaci\u00f3n m\u00e1s reciente en destino que en origen. Adem\u00e1s, si el archivo tiene la misma hora de modificaci\u00f3n en destino como en origen, s\u00f3lo se actualizar\u00e1 si el tama\u00f1o es diferente. Tpslimit: --tpslmit : debido a los baneos de las cuentas de google drive (los baneos son de 24 horas, que es el tiempo que tarde Google en refrescar las estad\u00edsticas , desconozco si los baneos son mayores si el baneo es reiterado). Seg\u00fan lo que he podido leer en varios grupos de telegram y por internet, la cifra m\u00e1s acertada es 8, que son el n\u00famero de peticiones m\u00e1ximas por segundo que har\u00edamos a la API de Google. Transfers : --transfers : es el n\u00famero de transferencias en paralelo que se realizan. Por defecto rclone establece 4 transferencias en paralelo. Puesto que me parece un n\u00famero excesivamente bajo, y aprovechando el ancho de banda que le hemos dados, vamos a elevar el n\u00famero a 15. Exclude: Vamos a utilizar reglas de filtrado, para evitar incluir varios directorios cuando utilicemos la sincronizaci\u00f3n de una de las cuentas. --exclude : podemos utilizarlo de dos modos. 1 2 1. --exclude nombre_del_fichero 2. --exclude-nombre_del_fichero \u00bfCu\u00e1l es la diferencia entre ambos? Con la primera opci\u00f3n enumeramos un fichero concreto, en cambio, con la segunda opci\u00f3n llamamos a un fichero que almacena diferente ficheros que queremos excluir. Evitamos tener que enumerar uno a uno los ficheros en el comando completo. Otros comandos \u00fatiles: # Listremotes: nos permite listar todos los remotes que hemos configurado. rclone listremotes List : nos permite listar el contenido. Hay varios comandos que podemos ejecutar que nos mostrar\u00e1n diferentes resultados. #Lista los objetos que se encuentran en REMOTO. rclone ls REMOTO: #Lista los directorios que se encuentra en REMOTO con fecha y hora de creaci\u00f3n. rclone lsd REMOTO: #Lista todo el contenido de la ruta que le indiques, tanto directorios como ficheros. rclone lsf REMOTO: #Lista todo el contenido (ficheros y directorios) incluido lo que se encuentra en todas las subcarpetas. rclone lsl REMOTO: Tree : nos muestra un lista de todo el contenido en forma de \u00e1rbol. (No lo recomiendo utilizar ya que tarda bastante en ejecutarse) . rclone tree REMOTO: Help: nos permite ver diferentes comandos o flags que podemos introducir. rclone --help rclone help flags rclone help backends Donde escribo **REMOTO* es necesario sustituirlo por el nombre de vuestra unidad configurada* Referencias: # [^1]: \u00bfQu\u00e9 son las unidades de equipos (Team Drive)? Funcionamiento de logging en rclone M\u00e1s filtros de Rclone Google OAuth \u201cinvalid_grant\u201d nightmare\u200a\u2014\u200aand how to fix it Rclone commands Rclone configure","title":"Rclone in OMV"},{"location":"OpenMediaVault/Rclone/#rclone-in-omv","text":"En esta peque\u00f1a gu\u00eda voy a mostrar la configuraci\u00f3n de Rclone con Google Drive. Se puede utilizar con muchos m\u00e1s servicios. Consultar aqu\u00ed La instalaci\u00f3n es muy sencilla, en esta web podemos ver la instalaci\u00f3n tanto para Linux como para MacOS. Podemos optar por llamar a un script que realizar\u00e1 todo el proceso de instalaci\u00f3n, o descargarnos un fichero .zip que descomprimiremos e instalaremos.","title":"Rclone in OMV"},{"location":"OpenMediaVault/Rclone/#instalacion","text":"Me he percatado que siguiendo la gu\u00eda de instalaci\u00f3n sobre Linux, no descarga la \u00faltima versi\u00f3n. Para evitar esto, y descargar la \u00faltima versi\u00f3n, iremos a este enlace y copiaremos la direcci\u00f3n del fichero .zip que corresponde con nuestra m\u00e1quina. No s\u00e9 si ya lo he comentado, pero la instalaci\u00f3n que estoy realizando es sobre OpenMediaVault que es un sistema orientado a NAS. Tal y como dicen sus desarrolladores est\u00e1 orientado a utilizar la interfaz web y no la \"cli\" (Command line interface). Es por ello que ir\u00e9 comprobando que los binarios correspondientes a los comandos que debo ejecutar se encuentran instalados en el sistema. Para ello ejecutar\u00e9 apt list --installed | grep nombre_del_binario . A continuaci\u00f3n pegar\u00e9 de la web oficial los comandos necesarios para su instalaci\u00f3n: Descarga del fichero .zip y descompresi\u00f3n. curl -O https://downloads.rclone.org/v1.47.0/rclone-v1.47.0-linux-amd64.zip unzip rclone-v1.47.0-linux-amd64.zip cd rclone-v1.47.0-linux-amd64 Como comentaba, la ruta que debemos poner es la que corresponde a la \u00faltima versi\u00f3n de Rclone Trasladar el binario rclone . sudo cp rclone /usr/bin/ sudo chown root:root /usr/bin/rclone sudo chmod 755 /usr/bin/rclone La ruta /usr/bin se encuentra en el PATH, que es la variable que contiene las rutas a los directorios que contienen los ficheros ejecutables. De ese modo podremos ejecutar Rclone sin importar en que directorio del sistema nos encontremos. A\u00f1adiendo el manual de rclone a la base de datos de manuales. sudo mkdir -p /usr/local/share/man/man1 sudo cp rclone.1 /usr/local/share/man/man1/ sudo mandb Copiamos el manual y actualizamos la base de datos de los manuales para que podamos invocar el \"man page\" ejecutando man rclone","title":"Instalaci\u00f3n:"},{"location":"OpenMediaVault/Rclone/#configuracion","text":"La configuraci\u00f3n es muy sencilla ya que el propia sistema nos gu\u00eda una vez que ejecutamos rclone config . Cuando ejecutamos este comando los aparecer\u00e1 un peque\u00f1o men\u00fa desde donde crearemos los nuevos servicios remotos (por denominarlos de alg\u00fan modo). La opci\u00f3n para crear es la \" n \", que una vez seleccionada esta opci\u00f3n nos aparecer\u00e1 en el prompt para asignarle un nombre, y a continuaci\u00f3n debemos elegir que servicio queremos configurar. En mi caso he seleccionado Google Drive que es la opci\u00f3n n\u00famero 12 (quiz\u00e1 pueda variar de el n\u00famero si la versi\u00f3n de Rclone es diferente). Nos aparecer\u00e1n una serie de par\u00e1metros para ir configurando, \u00fanicamente mostrar\u00e9 los que he necesitado configurar, puesto que el resto los he dejado por defecto ya que no necesitaba configurarlos. En uno de los pasos de la configuraci\u00f3n debemos establecer los permisos que le otorgamos, he seleccionado la opci\u00f3n n\u00famero \"1\" que es la m\u00e1s permisiva, ya que tenemos acceso total a todos los contenidos. Otra de las preguntas que nos aparecer\u00e1n a continuaci\u00f3n es si deseamos editar la configuraci\u00f3n avanzada, para nuestro supuesto no es necesario, por lo que seleccionaremos \" n \". La siguiente cuesti\u00f3n a tener en cuenta es si deseamos utilizar la configuraci\u00f3n autom\u00e1tica. Como podemos ver en la explicaci\u00f3n, en el segundo punto nos indica que s\u00ed estamos trabajando en una m\u00e1quina remota (por ejemplo contra nuestro servidor v\u00eda ssh) debemos seleccionar la opci\u00f3n \" n \", que ser\u00e1 la opci\u00f3n que seleccionaremos. Al haber pulsado la opci\u00f3n \" n \" nos mostrar\u00e1 una direcci\u00f3n que debemos copiar y pegar en nuestro navegador. Esta direcci\u00f3n nos solicitar\u00e1 autenticarnos con la cuenta de Google Drive que queremos vincular con Rclone. Una vez que nos autentiquemos nos aparecer\u00e1 un c\u00f3digo que copiaremos y pegaremos en la l\u00ednea que nos solicita Rclone. Antes de finalizar, nos preguntar\u00e1 si deseamos configurar como un Team Drive [^1], no es nuestro caso por lo tanto seleccionaremos \" n \". Nos mostrar\u00e1 un peque\u00f1o resumen con el \" remote \" que hemos configurado. Para finalizar debemos seleccionar con la letra \" q \" (Quit config).","title":"Configuraci\u00f3n:"},{"location":"OpenMediaVault/Rclone/#opciones-utilizadas","text":"En la creaci\u00f3n de los Remotes he creado dos id\u00e9nticos, es decir dos de cuentas Google Drive, uno para copiar el contenido, y el otro para sincronizarlo. La diferencia es que con la opci\u00f3n copy quiero evitar que si borro contenido no se elimine de mi servidor, en cambio con la opci\u00f3n sync quiero conseguir que tanto en GD como en mi servidor el contenido sea id\u00e9ntico. Los comandos a ejecutar se introducir\u00e1n en diferentes scripts, que a su vez se incorporar\u00e1n a otro script para que compruebe si el script de rclone sync y rclone copy se est\u00e1n ejecutando, para evitar una nueva ejecuci\u00f3n. Rclone sync (script): #!/bin/bash rclone sync ASIR: /sharedfolders/ASIRDrive -v --log-file = /home/Logs/rclonesync.txt -u --bwlimit 8650k --tpslimit 10 --transfers 15 --exclude Maquinas_Virtuales/ --exclude ISOS/ exit #!/bin/bash #Comprobamos que el script no se est\u00e1 ejecutando mediante pidof if pidof -o %PPID -x sh /home/Scripts/rclonesync.sh ; then exit 1 fi #Despu\u00e9s de comprobar, si no se est\u00e1 ejecutando pasar\u00e1 a ejecutar los siguientes comandos. echo \"Ejecutando rclonesync...\" #Puesto que la ruta de los scripts no se encuentra en la variable PATH es neceario indicarle la ruta completa /home/Scripts/rclonesync.sh echo \"\u00a1La ejecuci\u00f3n del script ha finalizado!\" exit Rclone copy (script): #!/bin/bash rclone copy TzinmDrive:General /sharedfolders/CursosDrive -v --log-file = /home/Logs/rclonecopy.txt -u --bwlimit 8650k --tpslimit 10 -transfers 15 exit #!/bin/bash #Comprobamos que el script no se est\u00e1 ejecutando mediante pidof if pidof -o %PPID -x /home/Scripts/rclonecopy.sh ; then exit 1 fi #Despu\u00e9s de comprobar, si no se est\u00e1 ejecutando pasar\u00e1 a ejecutar los siguientes comandos. echo \"Ejecutando rclonecopy...\" #Puesto que la ruta de los scripts no se encuentra en la variable PATH es neceario indicarle la ruta completa /home/Scripts/rclonecopy.sh echo \"\u00a1La ejecuci\u00f3n del script ha finalizado!\" exit La ruta que he establecido despu\u00e9s de sh puede diferir con la que utilic\u00e9is. Ten\u00e9is que indicar la ruta donde se encuentra vuestro script. Una vez que tenemos los script creados s\u00f3lo quedar\u00e1 a\u00f1adirlos al cron, que podemos aprovecharnos de la interfaz web de OpenMediaVault o a\u00f1adirlos mediante comandos, en ambos casos es muy sencillo. Una vez que hemos creado los Scripts en el directorio de Rclone que hayamos decidido, les daremos permiso de ejecuci\u00f3n para que no sea necesario llamar al comando sh y con poner la ruta completa del script sea suficiente. Esto nos evitar\u00e1 algunos problemas que he visto que surgen con el comando pidof. chmod a+x /home/Scripts/* a+x: otorgamos permisos ejecuci\u00f3n a todos los usuarios. /home/Scripts/*: a todo el contenido que se encuentra en esta ruta. Rclone sync: la siguiente configuraci\u00f3n es sincronizaci\u00f3n cada 30 minutos. Rclone copy: la siguiente configuraci\u00f3n es rclone copy los domingos a la 01:00. En la siguiente captura es como lo ver\u00edamos en nuestra terminal:","title":"Opciones utilizadas:"},{"location":"OpenMediaVault/Rclone/#ejecucion-cron-alternativa","text":"Por la web de Rclone no he visto como poder controlar el tama\u00f1o de los log que se van generando. Ser\u00eda interesante poder eliminar los datos antiguos, es decir establecer un l\u00edmite de por ejemplo 10MB y cuando llegue a ese l\u00edmite que vaya eliminando logs antiguos para poder introducir nuevos logs. Como digo, no he visto forma de hacerlo por lo tanto voy a a\u00f1adir al Cron un comando a ejecutar para que compruebe el tama\u00f1o de los logs y en caso de que supere el tama\u00f1o que nosotros le indiquemos (en mi caso ser\u00e1n 10MB) que realice una acci\u00f3n. find /home/Logs/ -type f -size +10M -exec rm -f {} \\; find: comando utilizado para realizar b\u00fasquedas. /home/Logs/: es la ruta en la que queremos buscar, podemos indicarle la que queramos. La ruta que he marcado es donde se encuentran los Logs de rclone. -type f: es el tipo de fichero que queremos buscar (en linux todo es un fichero), en nuestro caso ser\u00e1 un fichero de tipo file . -size +10M: buscamos fichero mayor de 10 Megabytes. Si delante del 10 indicamos un - buscar\u00e1 ficheros menores a 10 Megabytes. Se puede establecer otras unidades de medida que se encuentran explicadas en el manual de find. -exec: nos permite ejecutar una acci\u00f3n con todo aquello que ha encontrado (en funci\u00f3n de las condiciones que le hemos marcado). rm -f: rm = remove, es decir elimina lo que hemos encontrado, y como estamos seguros de que lo que ha encontrado lo queremos eliminar pasamos el par\u00e1metro -f para que no nos solicite confirmaci\u00f3n. {}: identifica a todo lo que ha encontrado el comando find. \\;: es la finalizaci\u00f3n del comando find cuando utilizamos la opci\u00f3n -excec . Man find Logging: Utilizaremos dos opciones para monitorizar rclone. -v, --verbose : rclone tiene 4 niveles de log, ERROR , AVISO , INFO Y DEBUG . Cuando utilizamos -v , rclone muestra los tres primeros niveles de error. --log-file=FILE : en combinaci\u00f3n con la anterior, todo el log monitorizado lo enviamos a un fichero, que ser\u00e1 el que establecemos despu\u00e9s del s\u00edmbolo = . Bwlimit: --bwlimit : con est\u00e1 opci\u00f3n limitamos el ancho de banda. En nuestro caso la utilizaremos para no ocupar todo el ancho de banda que nos proporciona nuestro ISP. Por la web se puede ver limitaciones de 8650k (Hace referencia a 8650 KBytes, que si hacemos la operaci\u00f3n matem\u00e1tica correspondiente son aproximadamente 750GB diarios, que es el limite para los Team Drive). Seg\u00fan lo que se puede leer por algunas consultas realizadas al soporte de Google, no hay limitaciones, salvo en lo que se refiere a contenido de video (Por ejemplo si queremos utilizar GD para almac\u00e9n del contenido de Plex) y de hosting. Limitaciones de Google: * Files you can store in Google Drive * Team Drive Limits ; After you've uploaded 750 GB to a Team Drive in 1 day, you'll be blocked from uploading additional files that day. However, file uploads already in progress will complete, up to a 5 TB maximum for a single file. Update: -u, --update : con esta opci\u00f3n obligamos a rclone que omita cualquier archivo que tenga una hora de modificaci\u00f3n m\u00e1s reciente en destino que en origen. Adem\u00e1s, si el archivo tiene la misma hora de modificaci\u00f3n en destino como en origen, s\u00f3lo se actualizar\u00e1 si el tama\u00f1o es diferente. Tpslimit: --tpslmit : debido a los baneos de las cuentas de google drive (los baneos son de 24 horas, que es el tiempo que tarde Google en refrescar las estad\u00edsticas , desconozco si los baneos son mayores si el baneo es reiterado). Seg\u00fan lo que he podido leer en varios grupos de telegram y por internet, la cifra m\u00e1s acertada es 8, que son el n\u00famero de peticiones m\u00e1ximas por segundo que har\u00edamos a la API de Google. Transfers : --transfers : es el n\u00famero de transferencias en paralelo que se realizan. Por defecto rclone establece 4 transferencias en paralelo. Puesto que me parece un n\u00famero excesivamente bajo, y aprovechando el ancho de banda que le hemos dados, vamos a elevar el n\u00famero a 15. Exclude: Vamos a utilizar reglas de filtrado, para evitar incluir varios directorios cuando utilicemos la sincronizaci\u00f3n de una de las cuentas. --exclude : podemos utilizarlo de dos modos. 1 2 1. --exclude nombre_del_fichero 2. --exclude-nombre_del_fichero \u00bfCu\u00e1l es la diferencia entre ambos? Con la primera opci\u00f3n enumeramos un fichero concreto, en cambio, con la segunda opci\u00f3n llamamos a un fichero que almacena diferente ficheros que queremos excluir. Evitamos tener que enumerar uno a uno los ficheros en el comando completo.","title":"Ejecuci\u00f3n cron alternativa:"},{"location":"OpenMediaVault/Rclone/#otros-comandos-utiles","text":"Listremotes: nos permite listar todos los remotes que hemos configurado. rclone listremotes List : nos permite listar el contenido. Hay varios comandos que podemos ejecutar que nos mostrar\u00e1n diferentes resultados. #Lista los objetos que se encuentran en REMOTO. rclone ls REMOTO: #Lista los directorios que se encuentra en REMOTO con fecha y hora de creaci\u00f3n. rclone lsd REMOTO: #Lista todo el contenido de la ruta que le indiques, tanto directorios como ficheros. rclone lsf REMOTO: #Lista todo el contenido (ficheros y directorios) incluido lo que se encuentra en todas las subcarpetas. rclone lsl REMOTO: Tree : nos muestra un lista de todo el contenido en forma de \u00e1rbol. (No lo recomiendo utilizar ya que tarda bastante en ejecutarse) . rclone tree REMOTO: Help: nos permite ver diferentes comandos o flags que podemos introducir. rclone --help rclone help flags rclone help backends Donde escribo **REMOTO* es necesario sustituirlo por el nombre de vuestra unidad configurada*","title":"Otros comandos \u00fatiles:"},{"location":"OpenMediaVault/Rclone/#referencias","text":"[^1]: \u00bfQu\u00e9 son las unidades de equipos (Team Drive)? Funcionamiento de logging en rclone M\u00e1s filtros de Rclone Google OAuth \u201cinvalid_grant\u201d nightmare\u200a\u2014\u200aand how to fix it Rclone commands Rclone configure","title":"Referencias:"}]}